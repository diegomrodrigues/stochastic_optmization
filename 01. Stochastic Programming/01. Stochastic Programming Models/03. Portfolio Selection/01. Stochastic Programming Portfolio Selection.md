## Programação Estocástica Aplicada à Seleção de Portfólios

### Introdução

A seleção de portfólios é um problema central em finanças, consistindo na alocação de capital entre diferentes ativos de forma a otimizar objetivos específicos. Uma característica inescapável dos mercados financeiros é a **incerteza** associada aos retornos futuros dos ativos [^13]. A **programação estocástica** oferece um framework robusto para abordar explicitamente essa incerteza na tomada de decisão de investimento [^1]. O objetivo fundamental, conforme delineado no contexto de seleção de portfólios, é maximizar o retorno esperado do investimento, ao mesmo tempo em que se controla o risco associado [^13, ^14]. Este capítulo explora modelos e técnicas de programação estocástica aplicados a este domínio, detalhando abordagens para problemas de período único (estáticos) e múltiplos períodos (multistage), incorporando diferentes métricas de risco e preferências do investidor através de funções de utilidade. Construiremos sobre os conceitos gerais de otimização sob incerteza, como modelagem em múltiplos estágios e ações de *recourse*, introduzidos em contextos como gerenciamento de estoque [^2, ^6].

### Conceitos Fundamentais

#### Modelo Estático (Single-Period)

Consideremos inicialmente o problema de alocar um capital inicial $W_0$ entre $n$ ativos [^13]. Seja $x_i$ o montante investido no ativo $i$, e $R_i$ a sua taxa de retorno (incerta) no período considerado. Definindo $\\xi_i := 1 + R_i$, a riqueza total ao final do período é $W_1 = \\sum_{i=1}^{n} \\xi_i x_i$ [^13]. A restrição de balanço é $\\sum_{i=1}^{n} x_i = W_0$, assumindo que todo o capital é investido (a inclusão de um ativo sem risco, como caixa, permite a forma de igualdade) [^13].

Uma primeira abordagem, bastante simplista, visa maximizar o retorno esperado $E[W_1]$ [^13]. Dado que $E[W_1] = \\sum_{i=1}^{n} E[\\xi_i] x_i = \\sum_{i=1}^{n} \\mu_i x_i$, onde $\\mu_i = 1 + E[R_i]$ é o retorno bruto esperado do ativo $i$, a solução ótima consiste em investir todo o capital $W_0$ no ativo com o maior $\\mu_i$ [^14].

> Esta solução, embora maximize o retorno médio, concentra todo o risco em um único ativo, o que é geralmente indesejável na prática devido à possibilidade de perdas significativas [^14].

**Maximização da Utilidade Esperada**

Uma alternativa mais sofisticada é maximizar a utilidade esperada da riqueza final, $E[U(W_1)]$, onde $U(\\cdot)$ é uma função de utilidade côncava e não decrescente, refletindo a aversão ao risco do investidor [^14]. O problema torna-se:
$$ \\underset{x \\ge 0}{\\text{Max}} \\quad E[U(W_1)] \\quad \\text{s.t.} \\quad \\sum_{i=1}^{n} x_i = W_0 $$
A escolha da função $U(\\cdot)$ é crucial. Por exemplo, uma função de utilidade linear por partes, como $U(W) = (1+q)(W-a)$ se $W > a$ e $U(W) = (1+r)(W-a)$ se $W \\le a$ (com $r > q > 0$), pode modelar diferentes taxas de juros para empréstimo e investimento de excedentes, levando a um programa linear estocástico de dois estágios [^14]. O primeiro estágio é a decisão de alocação $x$, e o segundo estágio envolve variáveis $y, z$ que representam o excedente ou déficit em relação a um valor alvo $a$, com a otimização $ \\underset{y,z \\in \\mathbb{R}^+}{\\text{Max}} \\ (1+q)y - (1+r)z $ sujeito a $\\sum_{i=1}^{n} \\xi_i x_i = a + y - z$ [^14].

**Controle de Risco via Momentos**

Outra vertente importante foca no controle explícito do risco, frequentemente medido pela variância do retorno. A variância de $W_1$ é dada por $Var[W_1] = Var[\\sum \\xi_i x_i] = x^T \\Sigma x$, onde $\\Sigma = [\\sigma_{ij}]$ é a **covariance matrix** do vetor de retornos $\\xi = (\\xi_1, ..., \\xi_n)$ (que é idêntica à matriz de covariância dos $R_i$) [^14, ^15].

Podemos formular problemas do tipo Markowitz:
1.  Maximizar o retorno esperado sujeito a um limite na variância:
    $$ \\underset{x \\ge 0}{\\text{Max}} \\quad \\sum_{i=1}^{n} \\mu_i x_i \\quad \\text{s.t.} \\quad \\sum_{i=1}^{n} x_i = W_0, \\quad x^T \\Sigma x \\le v $$
    onde $v > 0$ é o nível máximo de variância tolerado [^15].
2.  Minimizar a variância sujeito a um nível mínimo de retorno esperado:
    $$ \\underset{x \\ge 0}{\\text{Min}} \\quad x^T \\Sigma x \\quad \\text{s.t.} \\quad \\sum_{i=1}^{n} x_i = W_0, \\quad \\sum_{i=1}^{n} \\mu_i x_i \\ge \\tau $$
    onde $\\tau$ é o retorno esperado mínimo desejado [^15].

Ambos são problemas de **programação quadrática convexa**, dado que $\\Sigma$ é positiva semi-definida [^15]. O problema (1.39) [^15] é convexo e, assumindo condições como a de Slater (facilmente satisfeita, por exemplo, investindo tudo em caixa se a variância for zero), não há *duality gap*. Existe um multiplicador de Lagrange $\\bar{\\lambda} \\ge 0$ tal que a solução ótima de (1.39) também resolve:
$$ \\underset{x \\ge 0}{\\text{Max}} \\quad \\sum_{i=1}^{n} \\mu_i x_i - \\bar{\\lambda} x^T \\Sigma x \\quad \\text{s.t.} \\quad \\sum_{i=1}^{n} x_i = W_0 $$
Esta formulação representa um compromisso (*trade-off*) entre retorno esperado e risco (variância) [^15]. Estes modelos dependem apenas dos primeiros e segundos momentos da distribuição dos retornos ($\\mu$ e $\\Sigma$) e não requerem o conhecimento completo da distribuição de probabilidade [^15].

**Controle de Risco via Chance Constraints e Value-at-Risk (VaR)**

Uma abordagem alternativa para controle de risco utiliza **chance constraints** (restrições probabilísticas). Impomos que a probabilidade da riqueza final $W_1$ cair abaixo de um certo nível $b$ não exceda $\\alpha$, ou equivalentemente, $Pr\\{W_1 \\ge b\\} \\ge 1 - \\alpha$, onde $\\alpha \\in (0, 1)$ é um nível de significância [^15]. O problema de otimização torna-se:
$$ \\underset{x \\ge 0}{\\text{Max}} \\quad \\sum_{i=1}^{n} \\mu_i x_i \\quad \\text{s.t.} \\quad \\sum_{i=1}^{n} x_i = W_0, \\quad Pr\\{\\sum_{i=1}^{n} \\xi_i x_i \\ge b\\} \\ge 1 - \\alpha $$
A tratabilidade desta restrição depende da distribuição de $\\xi$. Se assumirmos que $\\xi$ segue uma distribuição normal multivariada, $\\xi \\sim N(\\mu, \\Sigma)$, então $W_1 = \\xi^T x$ segue uma distribuição normal $N(\\mu^T x, x^T \\Sigma x)$ [^16]. A restrição de chance (1.43) [^15] pode ser reescrita usando a função de distribuição acumulada (cdf) $\\Phi(\\cdot)$ da normal padrão $Z \\sim N(0,1)$ como:
$$ Pr\\{Z \\ge \\frac{b - \\mu^T x}{\\sqrt{x^T \\Sigma x}}\\} \\ge 1 - \\alpha \\quad \\Leftrightarrow \\quad \\Phi(\\frac{\\mu^T x - b}{\\sqrt{x^T \\Sigma x}}) \\ge 1 - \\alpha $$
$$ \\Leftrightarrow \\quad \\frac{\\mu^T x - b}{\\sqrt{x^T \\Sigma x}} \\ge \\Phi^{-1}(1 - \\alpha) = z_\\alpha $$
$$ \\Leftrightarrow \\quad b - \\mu^T x + z_\\alpha \\sqrt{x^T \\Sigma x} \\le 0 $$
onde $z_\\alpha$ é o $(1-\\alpha)$-quantil da distribuição normal padrão [^16]. Se $\\alpha < 1/2$, então $z_\\alpha \\ge 0$, e como $\\sqrt{x^T \\Sigma x}$ é uma função convexa (semi-norma), a restrição (1.45) [^16] é **convexa**, tornando o problema tratável [^16].
A restrição de chance está intimamente ligada ao conceito de **Value-at-Risk (VaR)**. O VaR em nível $\\alpha$ de uma perda $Y$ (ou $-W_1$) é o $(1-\\alpha)$-quantil (pelo lado esquerdo) da distribuição de $Y$, $V@R_\\alpha(Y) := H_Y^{-1}(1-\\alpha)$, onde $H_Y(\\cdot)$ é a cdf de $Y$ [^16]. A restrição $Pr\\{W_1 \\ge b\\} \\ge 1 - \\alpha$ pode ser escrita como uma restrição de VaR sobre a perda $Y = b - W_1$: $V@R_\\alpha(b - \\sum \\xi_i x_i) \\le 0$ [^16].
É importante notar que a hipótese de normalidade para retornos de ativos ($\\xi_i \\ge 0$) pode não ser realista [^16].

#### Modelo Multistage (Multi-Period)

Em muitos cenários práticos, o investidor pode rebalancear o portfólio ao longo do tempo, digamos em períodos $t = 1, ..., T-1$ [^16]. A decisão de alocação $x_t = (x_{1t}, ..., x_{nt})$ no início do período $t+1$ (com base na riqueza $W_t$ ao final do período $t$) deve depender apenas da informação disponível até aquele momento, ou seja, das realizações passadas dos retornos $\\xi_{[t]} = (\\xi_1, ..., \\xi_t)$ [^17]. Esta é a restrição de **não-antecipatividade** [^7, ^17]. O objetivo usual é maximizar a utilidade esperada da riqueza terminal, $Max \\ E[U(W_T)]$ [^17]. A riqueza evolui como $W_{t+1} = \\sum_{i=1}^{n} \\xi_{i,t+1} x_{it}(\\xi_{[t]})$ com a restrição de balanço $\\sum_{i=1}^{n} x_{it}(\\xi_{[t]}) = W_t$ [^17].

Este é um problema de **programação estocástica multistage**, que pode ser formulado usando **programação dinâmica** [^17]. Definindo $Q_t(W_t, \\xi_{[t]})$ como o valor ótimo (utilidade esperada máxima de $W_T$) a partir do estágio $t$ com riqueza $W_t$ e histórico $\\xi_{[t]}$, temos as equações recursivas:
$$ Q_t(W_t, \\xi_{[t]}) = \\underset{x_t \\ge 0, \\sum x_{it}=W_t}{\\text{Max}} \\ E[Q_{t+1}(W_{t+1}, \\xi_{[t+1]}) | \\xi_{[t]}] $$
com $W_{t+1} = \\sum_{i=1}^{n} \\xi_{i,t+1} x_{it}$ e $Q_T(W_T, \\xi_{[T]}) = U(W_T)$. A otimização é realizada sobre todas as políticas implementáveis (não-antecipativas) e factíveis [^17, ^18].

**Simplificação por Independência Estagional (Stagewise Independence)**

A resolução das equações de programação dinâmica é geralmente complexa, sofrendo da "maldição da dimensionalidade" (mencionada em [^8]). Uma simplificação significativa ocorre se o processo de retornos $\\xi_t$ for **stagewise independent**, ou seja, $\\xi_{t+1}$ é independente de $\\xi_{[t]}$ para todo $t$ [^18]. Embora essa hipótese possa não ser realista em modelos financeiros [^18], ela é instrutiva. Nesse caso, as esperanças condicionais tornam-se esperanças não condicionais em relação a $\\xi_{t+1}$, e a função valor $Q_t(W_t)$ depende apenas da riqueza atual $W_t$, não do histórico $\\xi_{[t]}$ [^18]. As equações simplificam para:
$$ Q_t(W_t) = \\underset{x_t \\ge 0, \\sum x_{it}=W_t}{\\text{Max}} \\ E[Q_{t+1}(W_{t+1})] $$
com $W_{t+1} = \\sum_{i=1}^{n} \\xi_{i,t+1} x_{it}$ [^18].

**Casos Especiais: Políticas Miópicas**

Para certas funções de utilidade e sob a hipótese de independência estagional, a política ótima torna-se **miópica**, significando que a decisão em cada estágio $t$ pode ser tomada otimizando um problema de um único período, sem olhar explicitamente para os estágios futuros (embora a função valor $Q_{t+1}$ implicitamente carregue informação futura).
1.  **Logarithmic Utility:** Se $U(W) = \\ln W$ (definida para $W>0$), a relação $Q_t(aW_t) = Q_t(W_t) + \\ln a$ [^18] implica que $Q_t(W_t) = v_t + \\ln W_t$, onde $v_t$ é o valor ótimo do problema de um estágio:
    $$ v_t = \\underset{x_t \\ge 0, \\sum x_{it}=1}{\\text{Max}} \\ E[\\ln(\\sum_{i=1}^{n} \\xi_{i,t+1} x_{it})] $$
    A política ótima é $x_t(W_t) = W_t x_t^*$, onde $x_t^*$ é a solução do problema acima para $W_t=1$ [^19, ^20]. A decisão ótima da fração de riqueza a alocar em cada ativo é independente do nível de riqueza $W_t$ e do horizonte $T$.
2.  **Power Utility:** Se $U(W) = W^\\gamma$ com $1 > \\gamma > 0$ (definida para $W \\ge 0$), argumentos similares mostram que $Q_t(W_t) = \\eta_t W_t^\\gamma$, onde $\\eta_t$ é o valor ótimo do problema:
    $$ \\eta_t = \\underset{x_t \\ge 0, \\sum x_{it}=1}{\\text{Max}} \\ E[(\\sum_{i=1}^{n} \\xi_{i,t+1} x_{it})^\\gamma] $$
    A política ótima também é miópica e da forma $x_t(W_t) = W_t x_t^*$, onde $x_t^*$ resolve o problema acima para $W_t=1$ [^20].

É crucial notar que a introdução de custos de transação realistas geralmente destrói essa propriedade miópica das políticas ótimas [^20].

**Regras de Decisão (Decision Rules)**

Mesmo quando não ótimas, políticas mais simples podem ser usadas na prática. Uma delas é a política **fixed mix**, onde a fração da riqueza alocada a cada ativo é mantida constante ao longo do tempo: $x_t(W_t) = W_t x^*$, onde $x^*$ é um vetor fixo com $\\sum x_i^* = 1$ [^21]. Sob independência estagional, a riqueza evolui como $W_{t+1} = W_t (\\sum_{i=1}^{n} \\xi_{i,t+1} x_i^*)$. O valor esperado da riqueza cresce exponencialmente: $E[W_t] = W_0 \\prod_{\\tau=1}^{t} (\\mu_{\\tau}^T x^*)$, onde $\\mu_\\tau = E[\\xi_\\tau]$ [^21]. A variância pode ser analisada recursivamente usando a lei da variância total [^21]. A relação derivada em (1.67)-(1.68) [^21, ^22] mostra que, sob certas condições, o rácio do desvio padrão $\\sqrt{Var[W_T]}$ para a riqueza esperada $E[W_T]$ cresce na ordem de $O(\\sqrt{T})$ [^22].

### Conclusão

A programação estocástica fornece ferramentas poderosas para a otimização de portfólios sob incerteza. Vimos como formular problemas estáticos (single-period) e multistage, incorporando a aversão ao risco através de funções de utilidade ou restrições explícitas sobre medidas de risco como variância e Value-at-Risk (via chance constraints) [^13, ^14, ^15, ^16]. Os modelos multistage, embora mais realistas ao permitirem rebalanceamento, são computacionalmente mais desafiadores, mas podem ser simplificados sob hipóteses como independência estagional, levando a políticas ótimas miópicas para classes específicas de funções de utilidade (logarítmica e power utility) [^17, ^18, ^19, ^20]. A análise de regras de decisão, como a política *fixed mix*, oferece insights sobre o comportamento de longo prazo da riqueza e do risco [^21, ^22]. A escolha do modelo e da abordagem depende do trade-off entre realismo, complexidade computacional e disponibilidade de dados sobre as distribuições de probabilidade dos retornos.

### Referências

[^1]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 1.
[^2]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 2.
[^6]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 6.
[^7]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 7.
[^8]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 8.
[^13]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 13.
[^14]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 14.
[^15]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 15.
[^16]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 16.
[^17]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 17.
[^18]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 18.
[^19]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 19.
[^20]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 20.
[^21]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 21.
[^22]: Ruszczyński, A., & Shapiro, A. (2009). Stochastic Programming Models. Chapter 1, Page 22.

<!-- END -->