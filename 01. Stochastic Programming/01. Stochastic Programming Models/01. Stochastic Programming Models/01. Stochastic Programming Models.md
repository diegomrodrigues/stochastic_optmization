## Capítulo 1: Modelos de Programação Estocástica

### Introdução

Leitores familiarizados com a área de otimização podem facilmente nomear diversas classes de problemas de otimização, para os quais existem resultados teóricos avançados e métodos numéricos eficientes foram encontrados [^4]. Podemos mencionar **programação linear**, **programação quadrática**, **otimização convexa** e **otimização não linear** [^4]. A **programação estocástica** soa similar, mas nenhuma formulação específica desempenha o papel de problema genérico de programação estocástica [^2].

> A programação estocástica aborda problemas de otimização com parâmetros incertos modelados como variáveis aleatórias, distinguindo-a da otimização determinística onde os parâmetros são constantes conhecidas [^1].

Ao contrário da otimização determinística, não existe uma formulação genérica única devido à variedade de formas como a incerteza pode se manifestar em problemas aplicados [^2]. A presença de quantidades aleatórias no modelo em consideração abre a porta para uma riqueza de diferentes configurações de problemas, refletindo diferentes aspectos do problema aplicado em questão [^2]. Este capítulo ilustra as principais abordagens que podem ser seguidas ao desenvolver um modelo de otimização estocástica adequado [^3]. Para fins de apresentação, utilizaremos versões muito simplificadas de problemas encontrados na prática, mas esperamos que ajudem a transmitir nossa mensagem principal [^3].

### Conceitos Fundamentais e Abordagens Ilustrativas

A modelagem em programação estocástica requer uma consideração cuidadosa de como a incerteza afeta as decisões e os objetivos. Exploraremos várias abordagens através de exemplos canônicos.

#### O Problema do Vendedor de Jornais (News Vendor Problem) e Modelos de Dois Estágios

Considere um problema de estoque onde uma empresa deve decidir a quantidade de pedido `x` de um produto para satisfazer uma demanda `d` [^5]. Os custos envolvidos são: custo de pedido `c > 0` por unidade, custo de penalidade por falta `b ≥ 0` por unidade se `d > x`, e custo de manutenção `h ≥ 0` por unidade se `d < x` [^5]. Assume-se que `b > c` [^7]. A função de custo total é dada por `F(x, d) = cx + b[d − x]+ + h[x - d]+`, onde `[a]+ = max{a, 0}` [^6]. Esta função pode ser reescrita como `F(x, d) = max {(c – b)x + bd, (c + h)x – hd}` [^9]. Se a demanda `d` fosse conhecida (determinística), o problema seria `Min_{x≥0} F(x, d)` [^8], cuja solução ótima é trivialmente `x = d` [^10].

No cenário estocástico, a decisão `x` deve ser tomada *antes* que a realização da demanda seja conhecida [^11]. A demanda `D` é tratada como uma variável aleatória com distribuição de probabilidade conhecida, frequentemente estimada a partir de dados históricos [^11]. Uma abordagem comum é minimizar o custo total esperado:

$$ \text{Min}_{x \ge 0} \{ f(x) := \mathbb{E}[F(x, D)] \} $$ [^13]

A justificativa para otimizar o valor esperado reside na Lei dos Grandes Números: se o processo de pedido se repete muitas vezes, o custo médio total converge para `E[F(x, D)]`, tornando a solução de (1.4) ótima em média [^14].

Este problema é um exemplo simples de um **problema de dois estágios** ou um problema com **ação de recurso (recourse action)** [^15]. No primeiro estágio, a decisão `x` é tomada sob incerteza. No segundo estágio, após a realização `d` da demanda `D` ser conhecida, uma ação de recurso pode ser necessária (se `d > x`, pedir a quantidade faltante `d-x` ao custo mais elevado `b`) [^15].

A função de custo esperado `f(x) = E[F(x, D)]` é convexa [^17] e pode ser expressa como `E[F(x, D)] = b E[D] + (c – b)x + (b + h) ∫₀ˣ H(z)dz`, onde `H(z) = Pr(D ≤ z)` é a função de distribuição acumulada (cdf) da demanda [^16]. Assumindo que `H(·)` é contínua em `x`, a solução ótima `x̄` satisfaz `f'(x) = c - b + (b+h)H(x) = 0` [^18], [^19]. Isso leva à solução ótima como um quantil da distribuição da demanda:

$$ \bar{x} = H^{-1}(\kappa) \quad \text{com} \quad \kappa = \frac{b-c}{b+h} $$ [^20]

onde `H⁻¹(κ) := inf{t : H(t) ≥ κ}` é o **κ-quantil** esquerdo da cdf `H(·)` [^21]. Se os quantis esquerdo e direito coincidirem, a solução é única; caso contrário, o conjunto de soluções ótimas é um intervalo [^22]. É instrutivo comparar a solução de quantil `x̄` com a solução obtida usando a demanda média `d̄ = E[D]` (que seria `x = d̄`); essas soluções podem ser muito diferentes, e os quantis amostrais são tipicamente menos sensíveis a perturbações nos dados empíricos do que a média amostral [^26].

Quando a distribuição de `D` é discreta, assumindo valores `d₁, ..., dK` (cenários) com probabilidades `p₁, ..., pK` [^23], o valor esperado torna-se uma soma ponderada: `E[F(x, D)] = ∑_{k=1}^K pk F(x, dk)` [^28]. O problema de otimização (1.4) pode então ser formulado como um problema de programação linear de grande escala:

$$ \begin{aligned} \text{Min}_{x \ge 0, v_1, ..., v_K} \quad & \sum_{k=1}^K p_k v_k \\\\ \text{s.t.} \quad & v_k \ge (c - b)x + b d_k, \quad k = 1, ..., K \\\\ & v_k \ge (c + h)x - h d_k, \quad k = 1, ..., K \end{aligned} $$ [^30]

Este problema exibe uma **estrutura quase separável**, que é típica para problemas estocásticos de dois estágios [^31]. Para um `x` fixo, o problema se decompõe na soma dos valores ótimos de problemas da forma (1.7) para cada `d = dk` [^31]. Soluções de forma fechada, como (1.6), são raras em aplicações [^27].

#### Abordagens Alternativas: Pior Caso e Restrições de Chance

Uma alternativa à otimização do valor esperado é a **abordagem do pior caso (Worst-Case Approach)**. Supondo que a demanda `d` é desconhecida mas pertence a um intervalo `[l, u]` [^32], o objetivo é minimizar o custo máximo possível:

$$ \text{Min}_{x \ge 0} \max_{d \in [l, u]} F(x, d) $$ [^32]

Como `F(x, d)` é convexa em `d` para `x` fixo (pode ser verificado a partir de (1.3)), o máximo ocorre em `d=l` ou `d=u` [^33]. O problema se torna `Min_{x∈[l,u]} ψ(x) := max {F(x, l), F(x, u)}` [^34]. A função `ψ(x)` é convexa e linear por partes [^35]. Assumindo `b > c`, a solução ótima `x*` é `x* = (hl + bu)/(h+b)` [^36]. Esta solução `x*` pode ser bastante conservadora e diferente da solução ótima em média `x̄` [^37]. Por exemplo, se `h=0`, então `x* = u` [^37]. Uma variação considera informações adicionais, como a média conhecida `d̄ = E[D]`, levando a problemas minimax do tipo `Min sup_{H∈M} EH [F(x, D)]`, onde `M` é um conjunto de distribuições com suporte e média especificados [^38].

Outra abordagem para controlar o risco é usar **restrições de chance (Chance Constraints)** ou **restrições probabilísticas**. Em vez de exigir que uma restrição seja satisfeita para *todas* as realizações da incerteza (o que pode ser muito restritivo ou inviável [^42]), exige-se que ela seja satisfeita com uma certa probabilidade mínima [^43]. Por exemplo, podemos querer limitar a probabilidade de o custo exceder um limiar `τ`:

$$ Pr\{F(x, D) > \tau\} \le \alpha $$ [^43]

ou equivalentemente, `Pr\{F(x, D) ≤ τ\} ≥ 1 - α`, onde `α ∈ (0, 1)` é um nível de significância especificado [^43]. Esta restrição pode ser adicionada ao problema de minimização do custo esperado (1.4) [^44]. Para o problema do vendedor de jornais, a restrição `F(x, D) ≤ τ` é equivalente a `(c+h)x-τ)/h ≤ D ≤ (b−c)x+τ)/b` [^45]. A restrição de chance (1.13) torna-se então `H((b−c)x+τ)/b) - H((c+hx-τ)/h) ≥ 1-α` (para `x ≤ τ/c`) [^46]. Mesmo para valores pequenos de `α`, esta pode ser uma relaxação significativa da restrição robusta correspondente (1.11) [^47].

#### Modelos Multiestágio e Programação Dinâmica

Quando as decisões são tomadas sequencialmente ao longo do tempo e a incerteza se revela gradualmente, usamos **modelos multiestágio (Multistage Models)**. Considere o problema de estoque ao longo de `T` períodos, com demanda `Dt` sendo um processo estocástico [^48]. No período `t`, observa-se o nível de estoque `yt`, decide-se reabastecer até o nível `xt ≥ yt`, e então a demanda `dt` é realizada, levando ao nível de estoque `yt+1 = xt - dt` [^49]. O objetivo é minimizar o custo total esperado ao longo do horizonte de planejamento `T` [^50], [^51].

A formulação precisa requer a consideração da **não antecipatividade (nonanticipativity)**: a decisão no estágio `t`, `xt`, só pode depender da informação disponível até aquele momento, ou seja, da história das realizações da demanda `d[t-1] = (d1, ..., dt-1)` [^54]. Assumimos que a distribuição de probabilidade condicional de `Dt` dado `d[t-1]` é conhecida [^55]. A abordagem padrão para resolver esses problemas é a **programação dinâmica (Dynamic Programming - DP)**. Começando pelo último estágio `T`, calcula-se o valor ótimo `QT(yT, d[T-1])` como função do estado (`yT`) e da história (`d[T-1]`) [^56], [^57]. Então, trabalha-se para trás no tempo, resolvendo recursivamente as equações de DP:

$$ Q_t(y_t, d_{[t-1]}) = \min_{x_t \ge y_t} \left\{ c_t(x_t - y_t) + \mathbb{E} \left[ b_t[D_t - x_t]_+ + h_t[x_t - D_t]_+ + Q_{t+1}(x_t - D_t, D_{[t]}) \,|\, D_{[t-1]} = d_{[t-1]} \right] \right\} $$ [^59]

para `t = T-1, ..., 1`, com `Q_{T+1} = 0`. O problema inicial é resolver para `Q1(y1)` [^60].

Calcular as funções de valor `Qt(yt, d[t-1])` pode ser computacionalmente intratável, pois elas dependem da história `d[t-1]`, cuja dimensão cresce com `t` [^61], [^62]. Uma simplificação significativa ocorre sob a hipótese de **independência estagiária (stagewise independence)**, onde `Dt` é independente de `D[t-1]` para todo `t` [^63]. Neste caso, as esperanças condicionais tornam-se incondicionais, e as funções de valor `Qt(yt)` dependem apenas do estado atual `yt` [^64]. A DP pode então ser resolvida numericamente, por exemplo, por discretização do estado `yt` [^65].

A solução das equações de DP define uma **política implementável (implementable policy)** ótima `X̄t = X̄t(yt, d[t-1])` (ou `X̄t = X̄t(yt)` sob independência estagiária) [^66], [^69], [^70]. Uma política é uma regra que especifica a decisão para cada estado e história possíveis [^66]. Uma política é **factível (feasible)** se satisfaz as restrições (e.g., `xt ≥ yt`) com probabilidade 1 [^67]. Sob independência estagiária e certas condições de convexidade, a política ótima pode ter uma estrutura simples, como a **política de nível de estoque base (basestock policy)** `X̄t = max{yt, x*t}`, onde `x*t` é um nível crítico que minimiza uma função de custo esperada de um período mais o custo futuro [^71], [^72]. No entanto, a DP sofre da **maldição da dimensionalidade (curse of dimensionality)**: a complexidade computacional cresce exponencialmente com a dimensão do vetor de estado e/ou da história [^74]. A programação estocástica aborda isso explorando a estrutura (e.g., convexidade) e usando técnicas como discretização do processo aleatório na forma de uma árvore de cenários [^75].

#### Exemplos Adicionais: Montagem MultProduto, Seleção de Portfólio e Projeto de Cadeia de Suprimentos

Outros problemas podem ser modelados usando estruturas similares.

*   **Montagem MultProduto (Multiproduct Assembly):** Um fabricante produz `n` produtos usando `m` peças [^76]. Demanda `D` é um vetor aleatório [^77]. Modelo de dois estágios: (1) Pedir peças `x` a custo `c` [^78]; (2) Após observar `d`, produzir `z` (limitado por `d` e peças disponíveis `x`), incorrendo em custos `l`, obtendo receita `q` e valor de salvamento `s` [^79]. O problema do segundo estágio é um PL `Q(x, d)` [^80], [^81]. O problema do primeiro estágio é `Min_{x≥0} cᵀx + E[Q(x, D)]` [^82]. Este é um problema de programação estocástica de dois estágios [^84], onde `x` são decisões **aqui-e-agora (here-and-now)** e `z, y` são decisões **esperar-para-ver (wait-and-see)** [^89]. Se o segundo estágio é sempre factível (como no exemplo, tomando `z=0`), diz-se que o problema tem **recurso relativamente completo (relatively complete recourse)** [^90]. Uma versão com restrição de chance exige `Pr{AᵀD ≤ x} ≥ 1-α` [^95], onde `A` é a matriz de requisitos de peças. Isso leva a um problema mais complexo envolvendo a distribuição do vetor `W=AᵀD` [^96] e está relacionado à **otimização robusta** se usarmos um conjunto de incerteza `Da` [^101], [^102]. Modelos multiestágio também podem ser formulados usando DP [^112]-[^117].

*   **Seleção de Portfólio (Portfolio Selection):** Investir capital `W₀` em `n` ativos com retornos incertos `Ri` (ou `ξi = 1+Ri`) [^118]. Modelo estático: (a) Maximizar retorno esperado `E[W₁] = ∑ μi xi` [^120] (solução arriscada [^122]); (b) Maximizar utilidade esperada `E[U(W₁)]` [^124] (pode levar a um PL estocástico de dois estágios para certas `U` [^126]); (c) Otimização média-variância: `Max ∑ μi xi` s.t. `Var(W₁) = xᵀΣx ≤ v` [^128] ou `Min xᵀΣx` s.t. `E[W₁] ≥ τ` [^134] (problemas de programação quadrática [^135]); (d) Restrição de chance: `Pr{W₁ ≥ b} ≥ 1-α` [^137]. Se os retornos são normais, a restrição de chance tem forma convexa `b - μᵀx + zα √(xᵀΣx) ≤ 0` [^142] e está relacionada ao **Value-at-Risk (VaR)** [^145], [^146]. Modelo multiestágio: Rebalancear o portfólio ao longo do tempo `t=1,...,T` para maximizar `E[U(WT)]` [^153]. Formulação DP [^156]-[^159]. Sob independência estagiária e para utilidades logarítmica (`ln W`) ou de potência (`W^γ`), a política ótima é **miópica (myopic)** [^173], [^175]: a decisão em `t` depende apenas da otimização para o próximo período. A política ótima tem a forma `X̄t(Wt) = Wt x*t`, conhecida como **política de mistura fixa (fixed mix policy)** se `x*t` for constante [^178]. A introdução de custos de transação geralmente destrói o comportamento miópico [^177].

*   **Projeto de Cadeia de Suprimentos (Supply Chain Network Design):** Decidir quais instalações construir/máquinas adquirir (`x`, binário, 1º estágio) e como rotear o fluxo de produtos (`y`, contínuo, 2º estágio) para minimizar custos totais (investimento + operacional esperado) [^188]-[^191]. O problema determinístico é um MILP [^192]-[^197]. A formulação estocástica é `Min_{x∈X} cᵀx + E[Q(x, ξ)]` [^205], onde `Q(x, ξ)` é o valor ótimo de um PL do segundo estágio que depende dos parâmetros incertos `ξ = (q, d, s, R, M)` [^202], [^203]. O primeiro estágio é combinatório, o segundo é LP [^206]. A infactibilidade do segundo estágio pode ocorrer [^208] e pode ser tratada com ações de recurso (e.g., custos de penalidade por demanda não atendida) [^209], frequentemente garantindo recurso relativamente completo [^210].

### Conclusão

A programação estocástica fornece um framework poderoso para a tomada de decisão sob incerteza, superando as limitações dos modelos determinísticos. Como ilustrado, não há uma abordagem única; a escolha do modelo (dois estágios, multiestágio, restrições de chance, pior caso) depende intrinsecamente da estrutura do problema, da natureza da incerteza e dos objetivos do tomador de decisão. Os exemplos do vendedor de jornais, montagem de multiprodutos, seleção de portfólio e projeto de cadeia de suprimentos demonstram a flexibilidade da programação estocástica em capturar diferentes facetas da incerteza e da dinâmica temporal. A resolução desses modelos frequentemente envolve técnicas especializadas, como programação dinâmica, decomposição para problemas de grande escala e métodos para lidar com restrições probabilísticas, refletindo a riqueza e a complexidade deste campo da otimização.

### Referências

[^1]: Página 1, Seção 1.1, Parágrafo 2
[^2]: Página 1, Seção 1.1, Parágrafo 2
[^3]: Página 1, Seção 1.1, Parágrafo 2
[^4]: Página 1, Seção 1.1, Parágrafo 1
[^5]: Página 1, Seção 1.2.1, Parágrafo 1
[^6]: Página 2, Equação (1.1)
[^7]: Página 2, Linha 2
[^8]: Página 2, Equação (1.2)
[^9]: Página 2, Equação (1.3)
[^10]: Página 2, Linha 6
[^11]: Página 2, Parágrafo 2
[^12]: Página 2, Linha 10
[^13]: Página 2, Equação (1.4)
[^14]: Página 2, Parágrafo 3
[^15]: Página 2, Parágrafo 4
[^16]: Página 2, Equação (1.5)
[^17]: Página 3, Linha 1
[^18]: Página 3, Cálculo de f'(z)
[^19]: Página 3, Linha 9
[^20]: Página 3, Equação (1.6)
[^21]: Página 3, Remark 1, Linha 2
[^22]: Página 3, Remark 1, Linha 4
[^23]: Página 3, Parágrafo 3
[^24]: Página 3, Parágrafo 3, Linha 4
[^25]: Página 3, Parágrafo 3, Linha 6
[^26]: Página 3, Parágrafo 4
[^27]: Página 3, Último parágrafo
[^28]: Página 4, Topo
[^29]: Página 4, Linha 4 e Equação (1.7)
[^30]: Página 4, Equação (1.8)
[^31]: Página 4, Parágrafo após (1.8)
[^32]: Página 4, Seção "Worst-Case Approach", Equação (1.9)
[^33]: Página 4, Linha abaixo de (1.9)
[^34]: Página 4, Equação abaixo de max F(x,d)
[^35]: Página 4, Linha abaixo da definição de ψ(x)
[^36]: Página 4, Última linha e Página 5, Topo
[^37]: Página 5, Linha 2-4
[^38]: Página 5, Parágrafo 2 e Equação (1.10)
[^39]: Página 5, Seção 1.2.2, Parágrafo 1
[^40]: Página 5, Parágrafo 1, Linha 4
[^41]: Página 5, Equação (1.11)
[^42]: Página 5, Parágrafo 2
[^43]: Página 5, Parágrafo 3 e Equações (1.12), (1.13)
[^44]: Página 6, Parágrafo 1
[^45]: Página 6, Equação (1.14)
[^46]: Página 6, Equação (1.16)
[^47]: Página 6, Última linha do parágrafo
[^48]: Página 6, Seção 1.2.3, Parágrafo 1
[^49]: Página 6, Parágrafo 1
[^50]: Página 6, Fórmula no meio da página
[^51]: Página 6, Equação (1.17)
[^52]: Página 6, Últimas linhas
[^53]: Página 7, Linha 1
[^54]: Página 7, Parágrafo 1, Linha 4 (nonanticipativity constraint)
[^55]: Página 7, Parágrafo 1, Linha 6
[^56]: Página 7, Equação (1.18)
[^57]: Página 7, Linha abaixo de (1.18)
[^58]: Página 7, Equação (1.19)
[^59]: Página 7, Equação (1.20)
[^60]: Página 7, Equação (1.21)
[^61]: Página 7, Parágrafo 3, Linha 2
[^62]: Página 7, Parágrafo 3, Linha 4
[^63]: Página 7, Parágrafo 3, Linha 6 (stagewise independent)
[^64]: Página 7, Parágrafo 3, Linha 8
[^65]: Página 7, Última linha
[^66]: Página 8, Parágrafo 1, Linha 6 (implementable policy)
[^67]: Página 8, Parágrafo 1, Linha 9 (feasible policy)
[^68]: Página 8, Parágrafo 2
[^69]: Página 8, Parágrafo 2, Linha 3
[^70]: Página 8, Parágrafo 2, Linha 5
[^71]: Página 8, Equação (1.22)
[^72]: Página 8, Parágrafo 3, Linha 4 (basestock policy)
[^73]: Página 8, Parágrafo 3, Linha 5
[^74]: Página 8, Último parágrafo, Linha 4 (curse of dimensionality)
[^75]: Página 8, Último parágrafo, Linha 6
[^76]: Página 9, Seção 1.3.1, Parágrafo 1
[^77]: Página 9, Parágrafo 1, Linha 5
[^78]: Página 9, Parágrafo 1, Linha 6
[^79]: Página 9, Parágrafo 1, Linhas 7-10
[^80]: Página 9, Formulação LP (Min (l-q)...)
[^81]: Página 9, Linha abaixo da formulação LP (Q(x,d))
[^82]: Página 9, Equação (1.24)
[^83]: Página 9, Última linha
[^84]: Página 10, Linha 1
[^85]: Página 10, Linha 2 (second-stage problem, first-stage problem)
[^86]: Página 10, Linha 4
[^87]: Página 10, Equação (1.25)
[^88]: Página 10, Linha abaixo de (1.25)
[^89]: Página 10, Parágrafo 2 (first-stage/here-and-now, second-stage/wait-and-see)
[^90]: Página 10, Parágrafo 2, Última linha (relatively complete recourse)
[^91]: Página 10, Seção 1.3.2, Parágrafo 1
[^92]: Página 10, Parágrafo 1, Linha 3
[^93]: Página 10, Parágrafo 2, Linha 1
[^94]: Página 10, Parágrafo 2, Linha 2-4
[^95]: Página 11, Equação (1.26)
[^96]: Página 11, Parágrafo 1
[^97]: Página 11, Equação (1.27)
[^98]: Página 11, Parágrafo 2, Linha 3
[^99]: Página 11, Parágrafo 2, Linha 5
[^100]: Página 11, Equação (1.28)
[^101]: Página 11, Parágrafo 3 (uncertainty set, robust optimization problem), Equação (1.29)
[^102]: Página 11, Fórmula para xj
[^103]: Página 11, Linha abaixo da fórmula para xj
[^104]: Página 11, Último parágrafo
[^105]: Página 12, Linha 2
[^106]: Página 12, Seção 1.3.3, Parágrafo 1
[^107]: Página 12, Parágrafo 1, Linha 4
[^108]: Página 12, Parágrafo 2
[^109]: Página 12, Parágrafo 3
[^110]: Página 12, Parágrafo 3, Linha 5
[^111]: Página 12, Parágrafo 3, Linha 7
[^112]: Página 12, Equação (1.30)
[^113]: Página 12, Linha abaixo de (1.30) e definição de Q̄T
[^114]: Página 12, Equação (1.31)
[^115]: Página 13, Equação (1.32)
[^116]: Página 13, Equação (1.33)
[^117]: Página 13, Parágrafo abaixo de (1.33)
[^118]: Página 13, Seção 1.4.1, Parágrafo 1
[^119]: Página 13, Parágrafo 1, Linha 6
[^120]: Página 13, Equação (1.34) e cálculo de E[W1]
[^121]: Página 14, Linha 2
[^122]: Página 14, Linha 3
[^123]: Página 14, Parágrafo 2
[^124]: Página 14, Equação (1.35)
[^125]: Página 14, Equação (1.36) e explicação
[^126]: Página 14, Equações (1.37)-(1.38)
[^127]: Página 14, Último parágrafo e cálculo de Var[W1]
[^128]: Página 15, Equação (1.39)
[^129]: Página 15, Parágrafo abaixo de (1.39)
[^130]: Página 15, Linha 5
[^131]: Página 15, Equação (1.40)
[^132]: Página 15, Equação (1.41)
[^133]: Página 15, Parágrafo abaixo de (1.41)
[^134]: Página 15, Equação (1.42)
[^135]: Página 15, Parágrafo abaixo de (1.42)
[^136]: Página 15, Linhas 6-8
[^137]: Página 15, Equação (1.43)
[^138]: Página 15, Parágrafo abaixo de (1.43)
[^139]: Página 16, Linha 1
[^140]: Página 16, Equação (1.44)
[^141]: Página 16, Linha abaixo de (1.44)
[^142]: Página 16, Equação (1.45)
[^143]: Página 16, Linha 5
[^144]: Página 16, Equação (1.46)
[^145]: Página 16, Equação (1.47) (Value-at-Risk)
[^146]: Página 16, Equação (1.48)
[^147]: Página 16, Último parágrafo
[^148]: Página 16, Seção 1.4.2, Parágrafo 1
[^149]: Página 17, Parágrafo 1
[^150]: Página 17, Parágrafo 1, Linha 8 (implementable policy)
[^151]: Página 17, Parágrafo 1, Linha 10 (feasible policy)
[^152]: Página 17, Equação abaixo do parágrafo 1
[^153]: Página 17, Equação (1.49)
[^154]: Página 17, Parágrafo abaixo de (1.49)
[^155]: Página 17, Parágrafo 3
[^156]: Página 17, Equação (1.50)
[^157]: Página 18, Linha 2
[^158]: Página 18, Equação (1.51)
[^159]: Página 18, Equação (1.52)
[^160]: Página 18, Parágrafo abaixo de (1.52)
[^161]: Página 18, Parágrafo 2 (stagewise independent)
[^162]: Página 18, Parágrafo 2, Linha 3
[^163]: Página 18, Parágrafo 2, Linha 5
[^164]: Página 18, Parágrafo 3 (logarithmic utility)
[^165]: Página 18, Equação (1.53)
[^166]: Página 19, Equação (1.54) e texto abaixo
[^167]: Página 19, Equação (1.55) e texto abaixo
[^168]: Página 19, Equação (1.56)
[^169]: Página 19, Parágrafo abaixo de (1.56)
[^170]: Página 19, Equação (1.57)
[^171]: Página 20, Equação (1.58)
[^172]: Página 20, Equação (1.59)
[^173]: Página 20, Política x̄t(Wt) = Wt x*t
[^174]: Página 20, Parágrafo 3 (power utility)
[^175]: Página 20, Equação (1.60) e política abaixo
[^176]: Página 20, Equação (1.61)
[^177]: Página 20, Último parágrafo
[^178]: Página 21, Seção 1.4.3, Equação (1.62) (fixed mix policy)
[^179]: Página 21, Parágrafo