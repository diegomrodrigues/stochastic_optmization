## T-Stage Stochastic Programming: Nested Formulation and Dynamic Programming

### Introdução
Este capítulo explora a formulação de problemas de **programação estocástica multiestágio** (Multistage Stochastic Programming - MSP) com *T* estágios, focando na representação aninhada e nas equações de programação dinâmica [^63]. A extensão natural dos modelos de programação estocástica de dois estágios [^63] para múltiplos estágios requer a adaptação das decisões à revelação gradual de dados incertos ao longo do tempo [^63]. O objetivo é minimizar uma sequência de funções, considerando expectativas sobre incertezas futuras e adaptando as decisões em cada estágio, mantendo a não-anticipatividade [^63].

### Conceitos Fundamentais

A **formulação aninhada** de um problema de programação estocástica com *T* estágios envolve a minimização sequencial e a expectativa sobre o processo de dados aleatórios $\\xi_1, ..., \\xi_T$ [^63, 64]. Em sua forma genérica, um problema de *T*-estágios pode ser expresso como [^64]:

$$\
\\min_{x_1 \\in X_1} f_1(x_1) + \\mathbb{E} \\left[ \\inf_{x_2 \\in X_2(x_1, \\xi_2)} f_2(x_2, \\xi_2) + \\mathbb{E} \\left[ \\dots + \\mathbb{E} \\left[ \\inf_{x_T \\in X_T(x_{T-1}, \\xi_T)} f_T(x_T, \\xi_T) \\right] \\right] \\right] \\qquad (3.1)\
$$

onde $x_t \\in \\mathbb{R}^{n_t}$, $t = 1, ..., T$, são as **variáveis de decisão**, $f_t: \\mathbb{R}^{n_t} \\times \\mathbb{R}^{d_t} \\rightarrow \\mathbb{R}$ são **funções contínuas**, e $X_t: \\mathbb{R}^{n_{t-1}} \\times \\mathbb{R}^{d_t} \\rightarrow \\mathbb{R}^{n_t}$, $t = 2, ..., T$, são **multifunções mensuráveis** com valores fechados [^64]. O vetor $\\xi_1$, a função $f_1: \\mathbb{R}^{n_1} \\rightarrow \\mathbb{R}$, e o conjunto $X_1 \\subset \\mathbb{R}^{n_1}$ são **determinísticos** [^64].

Em uma formulação típica, as funções objetivo e as restrições são lineares [^64]:

$$\
f_t(x_t, \\xi_t) := c_t^T x_t, \\quad X_1 := \\{x_1 : A_1 x_1 = b_1, x_1 \\geq 0\\},\
$$
$$\
X_t(x_{t-1}, \\xi_t) := \\{x_t : B_t x_{t-1} + A_t x_t = b_t, x_t \\geq 0\\}, \\quad t = 2, ..., T.\
$$

onde $\\xi_1 := (c_1, A_1, b_1)$ é conhecido no primeiro estágio e $\\xi_t := (c_t, B_t, A_t, b_t) \\in \\mathbb{R}^{d_t}$, $t = 2, ..., T$, são **vetores de dados** [^64].

Uma abordagem para tornar essa formulação precisa é considerar as variáveis de decisão $x_t = x_t(\\xi_{[t]}), t = 1, ..., T$, como **funções do processo de dados** $\\xi_{[t]}$ até o tempo $t$ [^64]. Uma sequência de mapeamentos mensuráveis $x_t: \\mathbb{R}^{d_1} \\times \\dots \\times \\mathbb{R}^{d_t} \\rightarrow \\mathbb{R}^{n_t}$, $t = 1, ..., T$, é chamada de **política implementável** [^64]. Uma política implementável é dita **factível** se satisfaz as restrições de factibilidade [^64]:

$$\
x_t(\\xi_{[t]}) \\in X_t(x_{t-1}(\\xi_{[t-1]}), \\xi_t), \\quad t = 2, ..., T, \\quad \\text{w.p. 1.} \\qquad (3.2)\
$$

O problema multiestágio (3.1) pode ser formulado na forma [^64]:

$$\
\\min_{x_1, x_2, ..., x_T} \\mathbb{E}[f_1(x_1) + f_2(x_2(\\xi_{[2]}), \\xi_2) + \\dots + f_T(x_T(\\xi_{[T]}), \\xi_T)] \\qquad (3.3)\
$$

$$\
\\text{s.t.} \\quad x_1 \\in X_1, \\quad x_t(\\xi_{[t]}) \\in X_t(x_{t-1}(\\xi_{[t-1]}), \\xi_t), \\quad t = 2, ..., T.\
$$

A otimização em (3.3) é realizada sobre **políticas implementáveis e factíveis** [^64].

**Equações de Programação Dinâmica:**

Outra forma de abordar o problema é através das **equações de programação dinâmica**, considerando o último estágio *T* [^64]:

$$\
\\min_{x_T \\in X_T(x_{T-1}, \\xi_T)} f_T(x_T, \\xi_T).\
$$

O valor ótimo deste problema, denotado por $Q_T(x_{T-1}, \\xi_T)$, depende do vetor de decisão $x_{T-1}$ e dos dados $\\xi_T$ [^65]. Para um estágio $t = 2, ..., T-1$, formula-se o problema [^65]:

$$\
\\min_{x_t} f_t(x_t, \\xi_t) + \\mathbb{E} \\{Q_{t+1}(x_t, \\xi_{[t+1]}) | \\xi_{[t]}\\}\
$$
$$\
\\text{s.t.} \\quad x_t \\in X_t(x_{t-1}, \\xi_t),\
$$

onde $\\mathbb{E}\\{\\cdot | \\xi_{[t]}\\}$ denota a **expectativa condicional** [^65]. O valor ótimo deste problema, chamado de **função de custo-para-ir** (cost-to-go function), é denotado por $Q_t(x_{t-1}, \\xi_{[t]})$ [^65]. A ideia é calcular as funções de custo-para-ir recursivamente, retrocedendo no tempo [^65]. No primeiro estágio, precisamos resolver o problema [^65]:

$$\
\\min_{x_1 \\in X_1} f_1(x_1) + \\mathbb{E} \\{Q_2(x_1, \\xi_2)\\}.\
$$

As equações de programação dinâmica correspondentes são [^65]:

$$\
Q_t(x_{t-1}, \\xi_{[t]}) = \\inf_{x_t \\in X_t(x_{t-1}, \\xi_t)} \\{f_t(x_t, \\xi_t) + Q_{t+1}(x_t, \\xi_{[t]})\\} \\qquad (3.4)\
$$

onde

$$\
Q_{t+1}(x_t, \\xi_{[t]}) := \\mathbb{E} \\{Q_{t+1}(x_t, \\xi_{[t+1]}) | \\xi_{[t]}\\}.\
$$

Uma política implementável $x_t(\\xi_{[t]})$ é **ótima** se, para $t = 1, ..., T$ [^65]:

$$\
x_t(\\xi_{[t]}) \\in \\arg \\min_{x_t \\in X_t(x_{t-1}(\\xi_{[t-1]}), \\xi_t)} \\{f_t(x_t, \\xi_t) + Q_{t+1}(x_t, \\xi_{[t]})\\} \\quad \\text{w.p. 1} \\qquad (3.5)\
$$

onde, para $t=T$, o termo $Q_{T+1}$ é omitido e, para $t=1$, o conjunto $X_1$ depende apenas de $\\xi_1$ [^65].

**Processos Markovianos e Independência Estágio a Estágio:**

Se o processo $\\xi_1, ..., \\xi_T$ é **Markoviano**, as distribuições condicionais nas equações acima, dado $\\xi_{[t]}$, são as mesmas que as distribuições condicionais respectivas dado $\\xi_t$ [^65]. Nesse caso, cada função de custo-para-ir $Q_t$ depende de $\\xi_t$, e podemos escrevê-la como $Q_t(x_{t-1}, \\xi_t)$ [^65]. Se, além disso, a condição de **independência estágio a estágio** (stagewise independence) for válida, então cada função de expectativa $Q_t$ não depende das realizações do processo aleatório, e podemos escrevê-la simplesmente como $Q_t(x_{t-1})$ [^65].

### Conclusão

Este capítulo apresentou a formulação aninhada e as equações de programação dinâmica para problemas de programação estocástica multiestágio [^63, 64, 65]. A formulação aninhada oferece uma representação compacta do problema, enquanto as equações de programação dinâmica fornecem uma abordagem recursiva para encontrar a solução ótima [^65]. A escolha entre essas formulações depende das características específicas do problema e das técnicas de solução disponíveis [^64, 65]. As propriedades do processo estocástico subjacente, como a Markovianidade e a independência estágio a estágio, podem simplificar significativamente a solução do problema [^65].

### Referências
[^63]: Ruszczyński, A., & Shapiro, A. (2003). *Multistage Problems*.
[^64]: Ruszczyński, A., & Shapiro, A. (2003). *Multistage Problems*, Chapter 3.1.1.
[^65]: Ruszczyński, A., & Shapiro, A. (2003). *Multistage Problems*, Chapter 3.1.1, page 65.

<!-- END -->