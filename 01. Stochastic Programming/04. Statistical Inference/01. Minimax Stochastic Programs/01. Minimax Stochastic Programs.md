## Capítulo 5.1.4: Programas Estocásticos Minimax e Aproximação por Média Amostral

### Introdução

Expandindo a análise das propriedades estatísticas dos estimadores de Aproximação por Média Amostral (SAA) apresentada nas seções anteriores, este capítulo foca em uma classe específica de problemas de otimização estocástica: os **programas estocásticos minimax**. Estes problemas são caracterizados pela necessidade de minimizar o valor máximo (supremum) de uma função objetivo esperada em relação a um conjunto de decisões adversariais ou parâmetros incertos. Formalmente, consideramos problemas da forma:

$$\
\underset{x \in X}{\text{Min}} \sup_{y \in Y} \{ f(x, y) := \mathbb{E}[F(x, y, \xi)] \} \quad [^ {45}]
$$

onde $X \subseteq \mathbb{R}^n$ e $Y \subseteq \mathbb{R}^m$ são conjuntos fechados, $F : X \times Y \times \Xi \rightarrow \mathbb{R}$ é uma função de valor real, e $\xi = \xi(\omega)$ é um vetor aleatório cuja distribuição de probabilidade $P$ é suportada em um conjunto $\Xi \subseteq \mathbb{R}^d$ [^46]. Assim como nos problemas estocásticos mais simples (como o definido em (5.1) [^1]), a presença do operador de expectativa $\mathbb{E}[\cdot]$ frequentemente impede a otimização direta.

Seguindo a metodologia SAA introduzida anteriormente [^4], aproximamos a função de valor esperado $f(x, y)$ pela sua contraparte de média amostral. Dada uma amostra $\xi^1, \dots, \xi^N$ de $N$ realizações do vetor aleatório $\xi$, o problema SAA correspondente ao problema minimax (5.46) é dado por:

$$\
\underset{x \in X}{\text{Min}} \sup_{y \in Y} \{ \hat{f}_N(x, y) := \frac{1}{N} \sum_{j=1}^{N} F(x, y, \xi^j) \} \quad [^ {47}]
$$

Este capítulo investiga as propriedades estatísticas desta aproximação SAA, particularmente a consistência dos estimadores do valor ótimo e das soluções ótimas, e deriva resultados assintóticos, conectando-os aos conceitos gerais de SAA já discutidos. Denotaremos por $v^*$ e $v_N$ os valores ótimos dos problemas (5.46) e (5.47), respectivamente, e por $S_x \subseteq X$ e $\hat{S}_{x,N} \subseteq X$ os respectivos conjuntos de soluções ótimas (para a minimização externa em $x$) [^48].

### Conceitos Fundamentais e Propriedades de Consistência

Para analisar a convergência do problema SAA (5.47) para o problema verdadeiro (5.46), introduzimos algumas hipóteses fundamentais. Assumimos que $F(x, y, \xi)$ é uma **função de Carathéodory**, o que significa que $F(x, y, \xi(\cdot))$ é mensurável para cada $(x, y)$ e $F(\cdot, \cdot, \xi)$ é contínua para quase todo $\xi \in \Xi$ [^49]. Adicionalmente, impomos as seguintes condições [^50]:

> **(A'1)** A função $F(x, y, \xi)$ é uma função de Carathéodory.
> **(A'2)** Os conjuntos $X$ e $Y$ são não vazios e **compactos**.
> **(A'3)** A função $F(x, y, \xi)$ é dominada por uma função integrável $h(\xi)$, ou seja, existe um conjunto aberto $N \subset \mathbb{R}^{n+m}$ contendo $X \times Y$ e uma função $h(\xi)$ integrável (com respeito à distribuição de probabilidade de $\xi$) tal que $|F(x, y, \xi)| \le h(\xi)$ para todo $(x, y) \in N$ e para quase todo $\xi \in \Xi$.

Sob estas hipóteses, e invocando o Teorema 7.43 [^51], a função de valor esperado $f(x, y) = \mathbb{E}[F(x, y, \xi)]$ é contínua em $X \times Y$. Como $Y$ é compacto (A'2), a função *max*, definida como $\phi(x) := \sup_{y \in Y} f(x, y)$, é contínua em $X$ [^52]. Analogamente, a função de média amostral $\hat{f}_N(x, y) = \hat{f}_N(x, y, \omega)$ é uma função de Carathéodory [^53]. Consequentemente, a função *max* de média amostral $\hat{\phi}_N(x, \omega) := \sup_{y \in Y} \hat{f}_N(x, y, \omega)$ também é uma função de Carathéodory [^53]. Uma vez que o valor ótimo SAA $\hat{v}_N = \hat{v}_N(\omega)$ é dado pelo mínimo da função Carathéodory $\hat{\phi}_N(x, \omega)$ sobre o conjunto compacto $X$, segue-se que $\hat{v}_N$ é mensurável [^54], [^11].

Com base nestas premissas, podemos estabelecer a consistência dos estimadores SAA para o problema minimax.

**Teorema 5.9.** *Suponha que as hipóteses (A'1)-(A'3) sejam válidas e que a amostra $\xi^1, \dots, \xi^N$ seja i.i.d. [^7]. Então, $\hat{v}_N \rightarrow v^*$ e $D(\hat{S}_{x,N}, S_x) \rightarrow 0$ com probabilidade 1 (w.p. 1) quando $N \rightarrow \infty$* [^55].

*Prova (Esboço).* Pelo Teorema 7.48, sob as hipóteses especificadas, $\hat{f}_N(x, y)$ converge para $f(x, y)$ w.p. 1 uniformemente em $X \times Y$ [^56]. Seja $\Delta_N := \sup_{(x,y) \in X \times Y} |\hat{f}_N(x, y) - f(x, y)|$. Temos que $\Delta_N \rightarrow 0$ w.p. 1 quando $N \rightarrow \infty$ [^56]. Considerando $\hat{\phi}_N(x) := \sup_{y \in Y} \hat{f}_N(x, y)$ e $\phi(x) := \sup_{y \in Y} f(x, y)$, temos que $\sup_{x \in X} |\hat{\phi}_N(x) - \phi(x)| \le \Delta_N$ [^57]. Como $\hat{v}_N = \inf_{x \in X} \hat{\phi}_N(x)$ e $v^* = \inf_{x \in X} \phi(x)$, segue que $|\hat{v}_N - v^*| \le \Delta_N$ [^57]. Portanto, $\hat{v}_N \rightarrow v^*$ w.p. 1 [^57]. As funções $\phi(x)$ e $\hat{\phi}_N(x)$ são contínuas (como visto acima) [^52], [^53]. O conjunto $S_x$ é não vazio devido à continuidade de $\phi(x)$ e compacidade de $X$. Similarmente, $\hat{S}_{x,N}$ é não vazio w.p. 1 [^57]. A prova da convergência $D(\hat{S}_{x,N}, S_x) \rightarrow 0$ w.p. 1 segue então exatamente a mesma linha de argumentação da prova do Teorema 5.3 [^17], [^57], substituindo $f, \hat{f}_N$ por $\phi, \hat{\phi}_N$ e utilizando a convergência uniforme estabelecida. $\blacksquare$

Este resultado garante que, sob condições de regularidade e compacidade, a solução do problema SAA minimax se aproxima da solução do problema verdadeiro à medida que o tamanho da amostra aumenta.

### Análise Assintótica para o Caso Convexo-Côncavo

Investigamos agora a distribuição assintótica do estimador do valor ótimo $\hat{v}_N$ no caso particular em que o problema minimax possui estrutura de convexidade-concavidade. Para isso, adicionamos as seguintes hipóteses:

> **(A'4)** Os conjuntos $X$ e $Y$ são convexos, e para quase todo $\xi \in \Xi$, a função $F(\cdot, \cdot, \xi)$ é **convexa-côncava** em $X \times Y$, i.e., $F(\cdot, y, \xi)$ é convexa em $X$ para todo $y \in Y$, e $F(x, \cdot, \xi)$ é côncava em $Y$ para todo $x \in X$ [^58].
> **(A'5)** Para algum ponto $(\bar{x}, \bar{y}) \in X \times Y$, a esperança $\mathbb{E}[F(\bar{x}, \bar{y}, \xi)^2]$ é finita, e existe uma função mensurável $C : \Xi \rightarrow \mathbb{R}_+$ tal que $\mathbb{E}[C(\xi)^2]$ é finita e a desigualdade (condição de **Lipschitz estocástica**)
> $$\
> |F(x, y, \xi) - F(x', y', \xi)| \le C(\xi)(\|x - x'\| + \|y - y'\|) \quad [^ {60}]
> $$
> vale para todo $(x, y), (x', y') \in X \times Y$ e para quase todo $\xi \in \Xi$.

Sob a hipótese (A'4), a função de valor esperado $f(x, y)$ é convexa-côncava e contínua em $X \times Y$ [^59]. Consequentemente, o problema minimax (5.46) e seu problema dual

$$\
\underset{y \in Y}{\text{Max}} \inf_{x \in X} f(x, y) \quad [^ {59}]
$$

possuem conjuntos não vazios e limitados de soluções ótimas, $S_x \subseteq X$ e $S_y \subseteq Y$, respectivamente. Além disso, os valores ótimos dos problemas (5.46) e (5.48) são iguais, e $S_x \times S_y$ forma o conjunto de **pontos de sela** destes problemas [^59]. A hipótese (A'5) implica que $f(x, y)$ é Lipschitz contínua em $X \times Y$ com constante de Lipschitz $\kappa = \mathbb{E}[C(\xi)]$ [^61], [^36].

**Teorema 5.10.** *Considere o problema estocástico minimax (5.46) e o problema SAA (5.47) baseado em uma amostra i.i.d. Suponha que as hipóteses (A'1)-(A'2) e (A'4)-(A'5) sejam válidas. Então,

$$\
\hat{v}_N = \inf_{x \in S_x} \sup_{y \in S_y} \hat{f}_N(x, y) + o_p(N^{-1/2}). \quad [^ {62}]
$$

*Além disso, se os conjuntos $S_x = \{\bar{x}\}$ e $S_y = \{\bar{y}\}$ são singletons, então $N^{1/2}(\hat{v}_N - v^*)$ converge em distribuição para uma distribuição normal com média zero e variância $\sigma^2 = \text{Var}[F(\bar{x}, \bar{y}, \xi)]$* [^63].

*Prova (Esboço).* Considere o espaço de Banach $C(X, Y)$ das funções contínuas $\psi : X \times Y \rightarrow \mathbb{R}$ equipado com a norma do supremo $\|\psi\| = \sup_{x \in X, y \in Y} |\psi(x, y)|$. Seja $K \subset C(X, Y)$ o cone convexo fechado das funções convexas-côncavas em $X \times Y$ [^64]. A função de valor ótimo $V: C(X, Y) \rightarrow \mathbb{R}$ é definida como $V(\psi) := \inf_{x \in X} \sup_{y \in Y} \psi(x, y)$ [^64]. Pelo Teorema 7.24, a função $V(\cdot)$ é Hadamard direcionalmente diferenciável em $f$ tangencialmente ao conjunto $K$ [^65], e sua derivada direcional na direção $\gamma \in T_K(f)$ é dada por:

$$\
V'_f(\gamma) = \inf_{x \in S_x} \sup_{y \in S_y} \gamma(x, y) \quad [^ {65}]
$$

A hipótese (A'5) garante que $N^{1/2}(\hat{f}_N - f)$, considerado como uma sequência de elementos aleatórios de $C(X, Y)$, converge em distribuição para um elemento aleatório (processo Gaussiano) $Y$ de $C(X, Y)$ [^66], [^37]. Notando que $\hat{v}_N = V(\hat{f}_N)$ e $v^* = V(f)$, e aplicando uma versão do método Delta (Teorema 7.61) à função $V(\cdot)$ no ponto $f$ [^66], juntamente com a fórmula da derivada direcional (5.53), obtemos o resultado (5.50) [^62] e a convergência em distribuição $N^{1/2}(\hat{v}_N - v^*) \xrightarrow{D} \inf_{x \in S_x} \sup_{y \in S_y} Y(x, y)$ [^66]. Se $S_x = \{\bar{x}\}$ e $S_y = \{\bar{y}\}$, então $\inf_{x \in S_x} \sup_{y \in S_y} Y(x, y) = Y(\bar{x}, \bar{y})$, que, pelo Teorema Central do Limite (aplicado a $F(\bar{x}, \bar{y}, \xi)$), tem distribuição normal $N(0, \text{Var}[F(\bar{x}, \bar{y}, \xi)])$ [^63]. $\blacksquare$

Este teorema estabelece a taxa de convergência $O_p(N^{-1/2})$ para $\hat{v}_N$ e caracteriza sua distribuição limite, que depende da estrutura do conjunto de pontos de sela $S_x \times S_y$. No caso bem-comportado de um único ponto de sela, obtemos a convergência assintótica normal padrão, similar ao resultado do Teorema 5.7 [^38] para problemas de minimização simples com solução única.

### Conclusão

Este capítulo detalhou a aplicação da metodologia SAA aos programas estocásticos minimax. Demonstramos a consistência dos estimadores SAA para o valor ótimo e o conjunto de soluções ótimas sob condições de compacidade e continuidade, alinhando-se com os resultados gerais de consistência como o Teorema 5.3 [^16]. Além disso, para a subclasse importante de problemas minimax convexo-côncavos satisfazendo condições de Lipschitz estocásticas, derivamos a distribuição assintótica do estimador do valor ótimo SAA. A análise assintótica, baseada no Teorema Central do Limite funcional [^37] e no método Delta [^39], [^65], revelou que a distribuição limite depende da estrutura do conjunto de pontos de sela, convergindo para uma distribuição normal no caso de um ponto de sela único [^63]. Estes resultados estendem a teoria SAA padrão para a estrutura minimax, fornecendo fundamentos teóricos para a aplicação de métodos de amostragem na resolução destes problemas complexos.

### Referências
[^1]: Página 155, Eq (5.1) definição de programa estocástico geral.
[^2]: Página 155, Explicação de X, ξ, P, E, F(x, ξ).
[^3]: Página 155, Assunção que f(x) é bem definida e de valor finito.
[^4]: Página 155, Definição do problema SAA, Eq (5.2).
[^5]: Página 156, Escrevendo a função SAA fN(x) como expectativa w.r.t. medida empírica PN, Eq (5.3).
[^6]: Página 156, SAA como um programa estocástico com cenários ξ¹, ..., ξN, prob 1/N.
[^7]: Página 156, Definição de amostra iid.
[^8]: Página 156, LGN implica que fN(x) converge pontualmente para f(x).
[^9]: Página 156, fN(x) é um estimador não viesado: E[fN(x)] = f(x).
[^10]: Página 156, Notação v*, S para valor/soluções ótimas do problema verdadeiro; vN, SN para valor/soluções ótimas SAA.
[^11]: Página 156, Discussão de mensurabilidade (Carathéodory, seleção mensurável).
[^12]: Página 156, Proposição 5.1 relacionando convergência pontual em sequências com convergência uniforme em conjuntos compactos.
[^13]: Página 157, Definição de consistência para estimadores.
[^14]: Página 157, lim sup vN ≤ v* w.p. 1 se LGN pontual vale, Eq (5.6).
[^15]: Página 157, Proposição 5.2: Convergência uniforme de fN para f implica que vN converge para v*.
[^16]: Página 158, Teorema 5.3: Condições para consistência de vN e SN (D(SN, S) -> 0). Requer compacidade, continuidade, convergência uniforme.
[^17]: Página 158, Prova do Teorema 5.3 usando contradição e propriedades de conjuntos compactos.
[^18]: Página 158, Equivalência de Prop 5.1(i) e (ii)+(iii) do Thm 5.3. Condição de inf-compacidade mencionada.
[^19]: Página 158, D(SN, S) -> 0 implica dist(x̂N, S) -> 0 para qualquer seleção x̂N. Se S é singleton, x̂N -> x̄.
[^20]: Página 159, Teorema 5.4: Consistência para problemas convexos sob condições mais fracas (LSC, convexidade, LGN pontual). Usa funções estendidas de valor real F̃, f̃, f̃N.
[^21]: Página 160, Teorema 5.5: Consistência quando o conjunto viável XN também é estimado. Precisa das condições (a) e (b).
[^22]: Página 161, Exemplo: X definido por restrições de valor esperado gi(x) <= 0.
[^23]: Página 161, Estimação de X por XN usando ĝin(x) <= 0.
[^24]: Página 161, Remark 5: Usando amostras iguais ou independentes para fN e ĝin. Amostras independentes podem ser melhores para variabilidade.
[^25]: Página 161, Necessidade de qualificação de restrição para condição (b) do Thm 5.5.
[^26]: Página 162, Exemplo: Restrições probabilísticas Pr(Ci(x, ξ) <= 0) >= 1 - αi.
[^27]: Página 162, Reescrevendo restrição prob. usando função indicadora, Eq (5.15), (5.16).
[^28]: Página 162, Versão SAA do conjunto de restrições prob. XN, Eq (5.17).
[^29]: Página 162, Descontinuidade da função indicadora. Condições para convergência uniforme (Thm 7.48).
[^30]: Página 162, Remark 6: Usando amostras independentes para aproximar restrições.
[^31]: Página 163, Seção 5.1.2 Assintótica do Valor Ótimo SAA. fN(x) não viesado, variância σ²(x)/N. Resultado TLC Eq (5.19).
[^32]: Página 163, Intervalo de confiança para f(x), Eq (5.20), (5.21). Erro O_p(N^-1/2).
[^33]: Página 163, v* >= E[vN] (viés descendente), Eq (5.22).
[^34]: Página 163, Proposição 5.6: E[vN] é monotonicamente crescente com N.
[^35]: Página 164, Hipóteses (A1) E[F(x̄, ξ)²] finito, (A2) Lipschitz estocástico |F(x,ξ) − F(x', ξ)| ≤ C(ξ)||x − x' ||.
[^36]: Página 164, (A1)+(A2) implicam que f(x) é Lipschitz contínua.
[^37]: Página 164, TLC funcional: N^1/2(fN - f) converge em distribuição para processo Gaussiano Y em C(X).
[^38]: Página 165, Teorema 5.7: Assintótica de vN. N^1/2(vN - v*) converge para inf_{x∈S} Y(x). Eq (5.25). Se S={x̄}, converge para N(0, σ²(x̄)). Eq (5.26).
[^39]: Página 165, Prova usando TLC funcional e teorema Delta para função de valor mínimo V(ψ).
[^40]: Página 165, Viés assintótico E[vN] - v* = N^-1/2 E[inf_{x∈S} Y(x)] + o(N^-1/2). Eq (5.29). Viés é O(N^-1/2) se |S|>1, o(N^-1/2) se |S|=1.
[^41]: Página 166, Seção 5.1.3 Assintótica de Segunda Ordem. Relaciona-se com assintótica das soluções ótimas x̂N. Requer hipóteses mais fortes (S1)-(S4).
[^42]: Página 167, Teorema 5.8: Expansão de segunda ordem para vN e primeira ordem para x̂N. Usa teorema Delta de segunda ordem.
[^43]: Página 168, Remark 7: Viés assintótico O(N^-1) quando S={x̄}. Comparação com O(N^-1/2) quando |S|>1.
[^44]: Página 169, Análise para programas convexos com restrições. Condições KKT, LICQ, complementaridade estrita.
[^45]: Página 170, Seção 5.1.4 Programas Estocásticos Minimax. Definição Eq (5.46): Min_x sup_y {f(x,y) := E[F(x,y,ξ)]}.
[^46]: Página 170, X, Y conjuntos fechados, F: XxYxΞ -> R, ξ vetor aleatório.
[^47]: Página 170, Problema SAA para minimax, Eq (5.47): Min_x sup_y {fN(x,y) := (1/N) Σ F(x,y,ξ^j)}.
[^48]: Página 170, Notação v*, vN para valores ótimos, Sx, Sx,N para conjuntos de soluções ótimas (problema externo).
[^49]: Página 170, Definição de Carathéodory para F(x, y, ξ).
[^50]: Página 170, Hipóteses (A'1) F é Carathéodory, (A'2) X, Y não vazios compactos, (A'3) F dominada por h(ξ) integrável.
[^51]: Página 170, Teorema 7.43 implica que f(x,y) é contínua em X x Y.
[^52]: Página 170, Compacidade de Y implica que a função max φ(x) := sup_y f(x,y) é contínua em X.
[^53]: Página 170, fN(x,y) é função de Carathéodory. Função max de média amostral φ̂N(x,ω) := sup_y fN(x,y,ω) é Carathéodory.
[^54]: Página 170, v̂N é mensurável.
[^55]: Página 170, Teorema 5.9: Consistência para minimax. Sob (A'1)-(A'3) e amostra iid, v̂N -> v* e D(Ŝx,N, Sx) -> 0 w.p. 1.
[^56]: Página 170, Esboço da prova: Teorema 7.48 fornece convergência uniforme de fN para f em X x Y. ΔN -> 0 w.p. 1.
[^57]: Página 171, Continuação da prova: |v̂N - v*| ≤ ΔN. φ(x) e φ̂N(x) são contínuas. Restante segue prova do Thm 5.3.
[^58]: Página 171, Assintótica para caso convexo-côncavo. Hipóteses adicionais: (A'4) X, Y convexos, F(·,·,ξ) convexo-côncavo.
[^59]: Página 171, f(x,y) é convexo-côncavo e contínuo. Problema (5.46) e dual Max_y inf_x f(x,y) (Eq 5.48) têm conjuntos de soluções ótimas Sx, Sy não vazios e limitados. SxxSy é conjunto de pontos de sela.
[^60]: Página 171, (A'5) E[F(x̄,ȳ,ξ)²] finito, condição de Lipschitz estocástica para F w.r.t (x,y).
[^61]: Página 171, (A'5) implica que f(x,y) é Lipschitz contínua em X x Y.
[^62]: Página 171, Teorema 5.10: Assintótica para minimax convexo-côncavo. v̂N = inf_{x∈Sx} sup_{y∈Sy} fN(x,y) + o_p(N^-1/2). Eq (5.50).
[^63]: Página 171, Se Sx={x̄}, Sy={ȳ} são singletons, N^1/2(v̂N - v*) converge para N(0, σ²), σ² = Var[F(x̄,ȳ,ξ)].
[^64]: Página 171, Esboço da prova: Considera espaço C(X,Y). Conjunto K de funções convexas-côncavas. Aplica teorema Delta à função de valor ótimo V(ψ) = inf_x sup_y ψ(x,y).
[^65]: Página 172, Teorema 7.24 fornece diferenciabilidade direcional de Hadamard de V(·). V'_f(γ) = inf_{x∈Sx} sup_{y∈Sy} γ(x,y). Eq (5.53).
[^66]: Página 172, (A'5) implica N^1/2(fN - f) converge em distribuição em C(X,Y). Aplica teorema Delta (Thm 7.61).
[^67]: Página 172, Problema minimax com restrições, Lagrangiano L(x,λ).
[^68]: Página 173, Teorema 5.11: Assintótica para problema convexo com restrições de valor esperado. N^1/2(v̂N - v*) converge para inf_{x∈S} sup_{λ∈Λ} [Y(x) + Σ λi Yi(x)]. Eq (5.56). Se S={x̄}, Λ={λ̄}, converge para N(0, σ²). Eq (5.57), (5.58).
[^69]: Página 173, Ideia da prova: Usa dualidade Lagrangiana, conecta com estrutura minimax (Thm 5.10).
[^70]: Página 173, Remark 9: Amostras iguais vs. independentes para objetivo e restrições em SAA. Amostras independentes reduzem variância se covariâncias são positivas.
[^71]: Página 174, Seção 5.2 Equações Generalizadas Estocásticas. Definição φ(x) ∈ Γ(x), Eq (5.60). φ(x)=E[Φ(x,ξ)].
[^72]: Página 175, Versão SAA Φ̂N(x) ∈ Γ(x), Eq (5.67). Teorema de Consistência 5.12.
[^73]: Página 176, Definição de regularidade forte (Def 5.13). Resultado baseado em Robinson [171] sobre existência/Lipschitzianidade de soluções para GE perturbada.
[^74]: Página 177, Teorema 5.14: Regularidade forte + convergência uniforme de Φ̂N, ∇Φ̂N implica existência/unicidade/convergência da solução SAA x̂N.
[^75]: Página 177, Teorema 5.15: Combina consistência e unicidade/convergência local.
[^76]: Página 177, Seção 5.2.2 Assintótica dos Estimadores SAA de GE. Aproximação de primeira ordem (5.69), assintótica para x̂N. Caso Γ(x)={0}. Eq (5.71).
[^77]: Página 178, Caso Γ(x)=Nx(x) (inequação variacional). Cone crítico Cx(x). Assintótica para x̂N via teorema Delta. Eq (5.74). Normalidade assintótica sse Cx(x) é espaço linear.
[^78]: Página 180, Seção 5.3 Métodos de Amostragem Monte Carlo. Números Aleatórios Comuns (CRN). Redução de variância para diferenças f(x1)-f(x2). Eq (5.83) vs (5.84).
[^79]: Página 181, Seção 5.3.1 Taxas Exponenciais... Conjunto Viável Finito. Evento {Ŝδ ⊂ Sε}. Limitando probabilidade usando união de limites. Eq (5.85), (5.86).
[^80]: Página 182, Introduz Y(x,ξ), usa limites LD. Hipótese (M2) MGF existe. Teorema 5.16 limite 1-Pr ≤ |X|exp(-Nη(δ,ε)). Eq (5.93), (5.94).
[^81]: Página 183, Taxa assintótica lim sup (1/N)ln(1-Pr) ≤ -η(δ,ε). Eq (5.95). Hipótese (M3) MGF sub-Gaussiana. Limite da função taxa Ix(z) >= (z-E[Y])²/2σ². Eq (5.100). Limite η(δ,ε). Eq (5.101), (5.102). Limite final |X|exp(-N(ε-δ)²/(2σ²)). Eq (5.103).
[^82]: Página 184, Teorema 5.17 Estimativa do tamanho da amostra N > 2σ²(ε-δ)⁻² ln(|X|/α). Eq (5.104).
[^83]: Página 184, Remark 10: Dependência logarítmica em |X| e α. Constante σ². Desigualdade de Hoeffding fornece σ²=b² se Y limitado por b.
[^84]: Página 184, Remark 11: Dependência em (σ/ε)². Comparação com caso normal Φ(μ√N/σ). N ~ zα²σ²/ε².
[^85]: Página 185, Remark 12: Limite MGF geral Mx(t) ≤ exp(ψ(t)). Usa função conjugada ψ*. Eq (5.109).
[^86]: Página 185, Seção 5.3.2 Estimativas de Tamanho de Amostra Caso Geral. X subconjunto limitado. Hipóteses (M4) MGF para Yx',x existe, (M5) Lipschitz estocástico para F.
[^87]: Página 186, (M5) implica f é Lipschitz. Teorema LD de Cramér para constante de Lipschitz amostral K̂N. Eq (5.114). fN é Lipschitz com K̂N. Eq (5.115).
[^88]: Página 186, Teorema 5.18 Estimativa do tamanho da amostra para X geral limitado. Usa argumento de v-net. Eq (5.116).
[^89]: Página 187, Esboço da prova: reduz para conjunto finito usando net, aplica Thm 5.17, controla constante de Lipschitz K̂N.
[^90]: Página 188, Discussão de complexidade O(σ²/ε²). Linear na dimensão n. Log em 1/α.
[^91]: Página 188, Hipótese (M6) limite MGF mais forte envolvendo ||x'-x||. Corolário 5.19 estimativa do tamanho da amostra. Eq (5.122).
[^92]: Página 189, Exemplo: Constante de Lipschitz κ(ξ) = L. Obtém estimativa (5.126).
[^93]: Página 189, Remark 14: Relaxando X limitado para problemas convexos usando conjuntos de nível Sα.
[^94]: Página 189, Remark 15: Verificando (M4