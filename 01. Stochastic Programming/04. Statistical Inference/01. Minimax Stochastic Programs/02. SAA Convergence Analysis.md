## Convergência Consistente de Estimadores SAA para Programas Minimax Estocásticos

### Introdução

Expandindo a análise das propriedades estatísticas dos estimadores de Aproximação por Média Amostral (SAA) apresentada anteriormente, este capítulo foca-se numa classe específica de problemas estocásticos: os **Programas Minimax Estocásticos**. Estes problemas surgem em diversas áreas onde é necessário tomar decisões ótimas face à incerteza, considerando o pior cenário em relação a um conjunto de parâmetros ou decisões adversárias. O problema "verdadeiro" é formulado como [^1]:

$$\
\text{Min}_{x \in X} \sup_{y \in Y} \{ f(x, y) := \mathbb{E}[F(x, y, \xi)] \} \quad (5.46)
$$

onde $X \subseteq \mathbb{R}^n$ e $Y \subseteq \mathbb{R}^m$ são conjuntos fechados, $F: X \times Y \times \Xi \to \mathbb{R}$ é uma função objetivo, e $\xi = \xi(\omega)$ é um vetor aleatório com distribuição de probabilidade $P$ suportada no conjunto $\Xi \subseteq \mathbb{R}^d$ [^1]. A função $f(x, y)$ representa o valor esperado da função objetivo $F$ [^1].

A abordagem SAA, como introduzida previamente, substitui o valor esperado pela média amostral. Para o problema minimax, a aproximação SAA correspondente é obtida usando uma amostra $\xi^1, ..., \xi^N$ de $N$ realizações do vetor aleatório $\xi$, resultando no problema [^2]:

$$\
\text{Min}_{x \in X} \sup_{y \in Y} \left\{ \hat{f}_N(x, y) := \frac{1}{N} \sum_{j=1}^{N} F(x, y, \xi^j) \right\} \quad (5.47)
$$

Denotamos por $v^*$ e $\hat{v}_N$ os valores ótimos dos problemas (5.46) e (5.47), respetivamente, e por $S_X \subseteq X$ e $\hat{S}_{X,N} \subseteq X$ os respetivos conjuntos de soluções ótimas (para a variável $x$) [^3]. O objetivo central deste capítulo é estabelecer as condições sob as quais os estimadores SAA $\hat{v}_N$ e $\hat{S}_{X,N}$ convergem para os seus homólogos verdadeiros $v^*$ e $S_X$, garantindo a **consistência** do método SAA para esta classe de problemas. Analisaremos as propriedades de convergência sob pressupostos chave como a propriedade de Carathéodory, compacidade e dominância.

### Conceitos Fundamentais e Análise de Convergência

A análise da convergência dos estimadores SAA para programas minimax requer um conjunto específico de pressupostos sobre a função $F$ e os conjuntos $X$ e $Y$.

**Pressupostos Chave:**

Assumimos as seguintes condições, referidas no texto original como (A\'1)-(A\'3) [^5, ^6, ^7]:

> **(A\'1)** A função $F(x, y, \xi)$ é uma **Função de Carathéodory**, ou seja, $F(x, y, \xi(\cdot))$ é mensurável para cada $(x, y)$ e $F(\cdot, \cdot, \xi)$ é contínua para quase todo $\xi \in \Xi$ [^5].
> **(A\'2)** Os conjuntos $X$ e $Y$ são não vazios e **compactos** [^6].
> **(A\'3)** A função $F(x, y, \xi)$ é **dominada por uma função integrável**, isto é, existe um conjunto aberto $N \subseteq \mathbb{R}^{n+m}$ contendo $X \times Y$ e uma função $h(\xi)$ integrável (com respeito à distribuição de probabilidade de $\xi$) tal que $|F(x, y, \xi)| \leq h(\xi)$ para todo $(x, y) \in N$ e quase todo $\xi \in \Xi$ [^7].

**Propriedades Induzidas pelos Pressupostos:**

Sob estes pressupostos, podemos derivar várias propriedades importantes. O Teorema 7.43 (referenciado em [^8]) implica que a função de valor esperado $f(x, y)$ é contínua em $X \times Y$ [^8]. Como $Y$ é compacto (A\'2), a função **max-function** $\phi(x) := \sup_{y \in Y} f(x, y)$ é contínua em $X$ [^9].

Da mesma forma, a função de média amostral $\hat{f}_N(x, y) = \hat{f}_N(x, y, \omega)$ também é uma função de Carathéodory [^10]. Consequentemente, a função **sample average max-function** $\hat{\phi}_N(x, \omega) := \sup_{y \in Y} \hat{f}_N(x, y, \omega)$ é, por sua vez, uma função de Carathéodory [^11]. Isto garante que o valor ótimo do problema SAA, $\hat{v}_N = \hat{v}_N(\omega)$, que é o mínimo da função $\hat{\phi}_N(x, \omega)$ sobre o conjunto compacto $X$, é mensurável [^12].

**Convergência Uniforme e Consistência:**

A base para a consistência dos estimadores SAA reside na convergência uniforme da função de média amostral $\hat{f}_N(x, y)$ para a função de valor esperado $f(x, y)$.

> **Teorema (Ref. Teorema 7.48 em [^14]):** Sob os pressupostos (A\'1)-(A\'3) e assumindo que a amostra $\xi^1, ..., \xi^N$ é iid, a função $\hat{f}_N(x, y)$ converge para $f(x, y)$ com probabilidade 1 (w.p. 1), uniformemente em $X \times Y$, à medida que $N \to \infty$.

Isto significa que a diferença uniforme máxima, definida como $\Delta_N := \sup_{(x,y) \in X \times Y} |\hat{f}_N(x, y) - f(x, y)|$, converge para zero w.p. 1 quando $N \to \infty$ [^14].

Esta convergência uniforme é a chave para provar a consistência dos estimadores SAA, formalizada no seguinte teorema:

> **Teorema 5.9 [^13]:** Suponha que os pressupostos (A\'1)–(A\'3) se verificam e que a amostra é iid. Então, $\hat{v}_N \to v^*$ w.p. 1 e $D(\hat{S}_{X,N}, S_X) \to 0$ w.p. 1 quando $N \to \infty$.

Este teorema estabelece que o valor ótimo $\hat{v}_N$ do problema SAA (5.47) converge quase certamente para o valor ótimo $v^*$ do problema verdadeiro (5.46) [^13]. Adicionalmente, a **deviation** do conjunto de soluções SAA $\hat{S}_{X,N}$ para o conjunto de soluções verdadeiras $S_X$, medida por $D(\cdot, \cdot)$ (ver definição em (7.4) no texto original), converge para zero w.p. 1 [^13]. Isto implica que, para $N$ suficientemente grande, qualquer solução ótima do problema SAA estará arbitrariamente próxima do conjunto de soluções ótimas do problema verdadeiro.

**Esboço da Demonstração (Teorema 5.9 [^14]):**
A prova da convergência do valor ótimo baseia-se na convergência uniforme. Temos que $\hat{\phi}_N(x) = \sup_{y \in Y} \hat{f}_N(x, y)$ e $\phi(x) = \sup_{y \in Y} f(x, y)$. A convergência uniforme de $\hat{f}_N$ para $f$ em $X \times Y$ implica a convergência uniforme de $\hat{\phi}_N(x)$ para $\phi(x)$ em $X$. Ou seja, $\sup_{x \in X} |\hat{\phi}_N(x) - \phi(x)| \leq \Delta_N$ [^14]. Como $\hat{v}_N = \min_{x \in X} \hat{\phi}_N(x)$ e $v^* = \min_{x \in X} \phi(x)$, e dado que a minimização sobre um conjunto compacto preserva a convergência uniforme (ver Proposição 5.2, por exemplo), segue-se que $|\hat{v}_N - v^*| \leq \sup_{x \in X} |\hat{\phi}_N(x) - \phi(x)| \leq \Delta_N$ [^14]. Uma vez que $\Delta_N \to 0$ w.p. 1, concluímos que $\hat{v}_N \to v^*$ w.p. 1 [^14]. A prova da convergência do conjunto de soluções, $D(\hat{S}_{X,N}, S_X) \to 0$ w.p. 1, segue uma linha de argumentação análoga à utilizada na prova do Teorema 5.3 (referenciado em [^14]), explorando a compacidade de $X$ e a continuidade das funções objetivo. $\blacksquare$

**Extensão para o Caso Convexo-Côncavo e Análise Assintótica:**

Para obter resultados mais fortes sobre a taxa de convergência e a distribuição assintótica dos estimadores, são frequentemente impostas condições adicionais de convexidade.

> **(A\'4)** Os conjuntos $X$ e $Y$ são convexos, e para quase todo $\xi \in \Xi$, a função $F(\cdot, \cdot, \xi)$ é **convexo-côncava** em $X \times Y$, i.e., $F(\cdot, y, \xi)$ é convexa em $X$ para cada $y \in Y$, e $F(x, \cdot, \xi)$ é côncava em $Y$ para cada $x \in X$ [^16].
> **(A\'5)** Para algum ponto $(\bar{x}, \bar{y}) \in X \times Y$, a esperança $\mathbb{E}[F(\bar{x}, \bar{y}, \xi)^2]$ é finita, e existe uma função mensurável $C: \Xi \to \mathbb{R}_+$ tal que $\mathbb{E}[C(\xi)^2]$ é finita e a desigualdade $|F(x, y, \xi) - F(x\', y\', \xi)| \leq C(\xi)(\|x - x\'\| + \|y - y\'\|)$ vale para todo $(x, y), (x\', y\') \in X \times Y$ e quase todo $\xi \in \Xi$ [^17].

Sob (A\'4), a função de valor esperado $f(x, y)$ é convexo-côncava e contínua em $X \times Y$ [^18]. Consequentemente, o problema minimax (5.46) e o seu dual $\text{Max}_{y \in Y} \inf_{x \in X} f(x, y)$ (5.48) possuem conjuntos não vazios e limitados de soluções ótimas, $S_X \subseteq X$ e $S_Y \subseteq Y$, respetivamente. Além disso, os valores ótimos são iguais, e $S_X \times S_Y$ forma o conjunto de **saddle points** do problema [^18]. O pressuposto (A\'5) implica que $f(x, y)$ é Lipschitz contínua em $X \times Y$ com constante $\kappa = \mathbb{E}[C(\xi)]$ [^18].

Sob estas condições mais fortes ((A\'1)-(A\'2) e (A\'4)-(A\'5)) e com amostragem iid, pode-se estabelecer a distribuição assintótica de $\hat{v}_N$.

> **Teorema 5.10 [^19]:** Considere o problema minimax (5.46) e o problema SAA (5.47) baseado numa amostra iid. Suponha que as condições (A\'1)-(A\'2) e (A\'4)-(A\'5) se verificam. Então,
> $$ \hat{v}_N = \inf_{x \in S_X} \sup_{y \in S_Y} \hat{f}_N(x, y) + o_p(N^{-1/2}). \quad (5.50) $$
> Além disso, se os conjuntos $S_X = \{\bar{x}\}$ e $S_Y = \{\bar{y}\}$ são singletons, então $N^{1/2}(\hat{v}_N - v^*)$ converge em distribuição para uma distribuição Normal com média zero e variância $\sigma^2 = \text{Var}[F(\bar{x}, \bar{y}, \xi)]$.

A prova deste teorema [^20] utiliza ferramentas mais avançadas, como o **Teorema do Limite Central funcional (functional CLT)** no espaço $C(X, Y)$ das funções contínuas equipado com a **sup-norm**, e o **Teorema Delta** para funcionais como a função valor ótimo $V(\psi) = \inf_{x \in X} \sup_{y \in Y} \psi(x, y)$. A diferenciabilidade direcional de Hadamard da função $V(\cdot)$ (Teorema 7.24) é um ingrediente chave [^20]. $\blacksquare$

### Conclusão

Este capítulo demonstrou a consistência dos estimadores SAA para programas minimax estocásticos sob condições de regularidade padrão: a propriedade de Carathéodory da função objetivo, a compacidade dos conjuntos de decisão e a dominância por uma função integrável. A convergência uniforme da função de média amostral para a função de valor esperado (garantida pelo Teorema 7.48 sob amostragem iid) é fundamental para estabelecer a convergência do valor ótimo SAA ($\hat{v}_N$) e do conjunto de soluções SAA ($\hat{S}_{X,N}$) para os seus correspondentes verdadeiros ($v^*$ e $S_X$), conforme estabelecido no Teorema 5.9. Estes resultados fornecem uma justificação teórica para a aplicação do método SAA na resolução aproximada de problemas minimax estocásticos. Foram também brevemente mencionadas as condições adicionais (convexidade-concavidade e Lipschitzianidade estocástica) que permitem obter resultados assintóticos mais fortes sobre a taxa de convergência e a distribuição limite dos estimadores (Teorema 5.10).

### Referências

[^1]: O problema minimax estocástico é definido como $\text{Min}_{x \in X} \sup_{y \in Y} \{ f(x, y) := \mathbb{E}[F(x, y, \xi)] \}$ (5.46), onde $X \subseteq \mathbb{R}^n$, $Y \subseteq \mathbb{R}^m$ são conjuntos fechados, $F: X \times Y \times \Xi \to \mathbb{R}$, e $\xi$ é um vetor aleatório com distribuição suportada em $\Xi \subseteq \mathbb{R}^d$. (p. 170)
[^2]: A aproximação SAA correspondente é $\text{Min}_{x \in X} \sup_{y \in Y} \{ \hat{f}_N(x, y) := \frac{1}{N} \sum_{j=1}^{N} F(x, y, \xi^j) \}$ (5.47). (p. 170)
[^3]: $v^*$ e $\hat{v}_N$ são os valores ótimos de (5.46) e (5.47), respetivamente. $S_X \subseteq X$ e $\hat{S}_{X,N} \subseteq X$ são os respetivos conjuntos de soluções ótimas. (p. 170)
[^4]: $F(x, y, \xi)$ é uma função de Carathéodory se $F(x, y, \xi(\cdot))$ é mensurável para cada $(x, y)$ e $F(\cdot, \cdot, \xi)$ é contínua para q.t.p. $\xi \in \Xi$. (p. 170)
[^5]: Pressuposto (A\'1): $F(x, y, \xi)$ é uma função de Carathéodory. (p. 170)
[^6]: Pressuposto (A\'2): Os conjuntos $X$ e $Y$ são não vazios e compactos. (p. 170)
[^7]: Pressuposto (A\'3): $F(x, y, \xi)$ é dominada por uma função integrável $h(\xi)$ num conjunto aberto $N \supset X \times Y$. (p. 170)
[^8]: Pelo Teorema 7.43, segue-se que a função de valor esperado $f(x, y)$ é contínua em $X \times Y$. (p. 170)
[^9]: Como $Y$ é compacto, a max-function $\phi(x) := \sup_{y \in Y} f(x, y)$ é contínua em $X$. (p. 170)
[^10]: Segue-se também que a função $\hat{f}_N(x, y) = \hat{f}_N(x, y, \omega)$ é uma função de Carathéodory. (p. 170)
[^11]: Consequentemente, a sample average max-function $\hat{\phi}_N(x, \omega) := \sup_{y \in Y} \hat{f}_N(x, y, \omega)$ é uma função de Carathéodory. (p. 170)
[^12]: Como $\hat{v}_N = \hat{v}_N(\omega)$ é dado pelo mínimo da função de Carathéodory $\hat{\phi}_N(x, \omega)$, segue-se que é mensurável. (p. 170)
[^13]: Teorema 5.9: Suponha que os pressupostos (A\'1)–(A\'3) se verificam e a amostra é iid. Então $\hat{v}_N \to v^*$ e $D(\hat{S}_{X,N}, S_X) \to 0$ w.p. 1 quando $N \to \infty$. (p. 170)
[^14]: Prova do Teorema 5.9: Pelo Teorema 7.48, sob as condições especificadas, $\hat{f}_N(x, y)$ converge para $f(x, y)$ w.p. 1 uniformemente em $X \times Y$. Seja $\Delta_N := \sup_{(x,y) \in X \times Y} |\hat{f}_N(x, y) - f(x, y)|$. Então $\Delta_N \to 0$ w.p. 1. Temos que $\sup_{x \in X} |\hat{\phi}_N(x) - \phi(x)| \leq \Delta_N$, e portanto $|\hat{v}_N - v^*| \leq \Delta_N$. Segue-se que $\hat{v}_N \to v^*$ w.p. 1. A prova para $D(\hat{S}_{X,N}, S_X) \to 0$ procede de forma análoga à prova do Teorema 5.3. (p. 170-171)
[^15]: Discutimos agora a assintótica de $\hat{v}_N$ no caso convexo-côncavo. Fazemos as seguintes pressupostos adicionais. (p. 171)
[^16]: Pressuposto (A\'4): Os conjuntos $X$ e $Y$ são convexos, e para q.t.p. $\xi \in \Xi$ a função $F(\cdot, \cdot, \xi)$ é convexo-côncava em $X \times Y$. (p. 171)
[^17]: Pressuposto (A\'5): Para algum $(\bar{x}, \bar{y}) \in X \times Y$, $\mathbb{E}[F(\bar{x}, \bar{y}, \xi)^2] < \infty$, e existe $C: \Xi \to \mathbb{R}_+$ mensurável com $\mathbb{E}[C(\xi)^2] < \infty$ tal que $|F(x, y, \xi) - F(x\', y\', \xi)| \leq C(\xi)(\|x - x\'\| + \|y - y\'\|)$ para todo $(x, y), (x\', y\') \in X \times Y$ e q.t.p. $\xi \in \Xi$. (p. 171)
[^18]: Segue-se que a função de valor esperado $f(x, y)$ é convexo-côncava e contínua em $X \times Y$. Consequentemente, o problema (5.46) e o seu dual (5.48) têm conjuntos não vazios e limitados de soluções ótimas $S_X \subset X$ e $S_Y \subset Y$. Os valores ótimos são iguais e $S_X \times S_Y$ forma o conjunto de saddle points. A pressuposição acima implica que $f(x, y)$ é Lipschitz contínua em $X \times Y$ com constante de Lipschitz $\kappa = \mathbb{E}[C(\xi)]$. (p. 171)
[^19]: Teorema 5.10: Considere o problema minimax (5.46) e o problema SAA (5.47) baseado numa amostra iid. Suponha que (A\'1)-(A\'2) e (A\'4)-(A\'5) se verificam. Então $\hat{v}_N = \inf_{x \in S_X} \sup_{y \in S_Y} \hat{f}_N(x, y) + o_p(N^{-1/2})$. Além disso, se $S_X = \{\bar{x}\}$ e $S_Y = \{\bar{y}\}$ são singletons, então $N^{1/2}(\hat{v}_N - v^*)$ converge em distribuição para Normal com média zero e variância $\sigma^2 = \text{Var}[F(\bar{x}, \bar{y}, \xi)]$. (p. 171)
[^20]: Prova do Teorema 5.10: Considere o espaço $C(X, Y)$ de funções contínuas $\psi: X \times Y \to \mathbb{R}$ equipado com a sup-norm. Considere a função de valor ótimo $V(\psi) := \inf_{x \in X} \sup_{y \in Y} \psi(x, y)$. Pelo Teorema 7.24, a função $V(\cdot)$ é Hadamard direcionalmente diferenciável em $f$ tangencialmente ao conjunto $\mathcal{K}$ (funções convexo-côncavas). Pela pressuposição (A\'5), $N^{1/2}(\hat{f}_N - f)$ converge em distribuição para um elemento aleatório de $C(X, Y)$. O resultado segue usando a diferenciabilidade direcional de Hadamard e uma versão do método Delta (Teorema 7.61). (p. 171-172)

<!-- END -->