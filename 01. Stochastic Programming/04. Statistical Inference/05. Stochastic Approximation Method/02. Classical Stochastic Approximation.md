## Algoritmo Clássico de Aproximação Estocástica

### Introdução

Este capítulo foca na análise do algoritmo clássico de **Aproximação Estocástica (SA - Stochastic Approximation)**, um método iterativo fundamental projetado para resolver problemas de otimização estocástica da forma geral:
$$ \underset{x \in X}{\text{Min}} \{f(x) := \mathbb{E}[F(x, \xi)]\} \quad (5.1) $$
onde $X$ é um subconjunto não vazio, fechado e convexo de $\mathbb{R}^n$, $\xi$ é um vetor aleatório, e $f(x)$ é a função objetivo de valor esperado [^1]. Assumimos que a função $f(x)$ é convexa, finita e contínua em $X$ [^3]. Os métodos SA operam utilizando informações obtidas a partir de um **oráculo estocástico**, que, para um dado $x \in X$ e uma realização do vetor aleatório $\xi$, fornece o valor $F(x, \xi)$ e um **subgradiente estocástico** $G(x, \xi)$. Este subgradiente é tal que seu valor esperado, $g(x) := \mathbb{E}[G(x, \xi)]$, é um subgradiente (ou gradiente, se $f$ for diferenciável) da função $f(\cdot)$ no ponto $x$, ou seja, $g(x) \in \partial f(x)$ [^3].

A abordagem clássica do SA, que será detalhada aqui, emula um método de descida por subgradiente determinístico [^2]. A sua formulação iterativa envolve um passo de subgradiente estocástico seguido por uma **projeção** sobre o conjunto viável $X$ [^2, ^4]. Especificamente, o algoritmo clássico utiliza uma sequência de passos $\gamma_j$ que decrescem com o tempo e impõe condições específicas sobre a função objetivo e o conjunto viável, notadamente a **convexidade forte** da função $f(x)$ e a simplicidade computacional da projeção $\Pi_X$ [^2, ^5]. O objetivo deste capítulo é apresentar formalmente o algoritmo clássico de SA e analisar suas propriedades de convergência sob estas suposições, baseando-nos exclusivamente nas informações contextuais fornecidas.

### Conceitos Fundamentais e Análise de Convergência

O algoritmo clássico de Aproximação Estocástica (SA) é definido pelo seguinte processo iterativo:
> Para um ponto inicial escolhido $x_1 \in X$ e uma sequência de tamanhos de passo $\gamma_j > 0, j = 1, \dots$, as iterações são geradas pela fórmula:
> $$ x_{j+1} = \Pi_X(x_j - \gamma_j G(x_j, \xi^j)) \quad (5.281) $$
> onde $\xi^j$ são realizações iid do vetor aleatório $\xi$, $G(x_j, \xi^j)$ é o subgradiente estocástico no ponto $x_j$ correspondente à realização $\xi^j$, e $\Pi_X(x) := \text{arg min}_{z \in X} ||x - z||_2$ denota a projeção métrica sobre o conjunto $X$ [^2, ^4].

A análise de convergência deste método requer um conjunto de suposições:

1.  **Estrutura do Problema:** O problema a ser resolvido é (5.1), com $f(x)$ convexa e $X$ convexo, fechado e limitado [^1, ^3].
2.  **Oráculo Estocástico:** Existe um oráculo que fornece $G(x, \xi)$ tal que $\mathbb{E}[G(x, \xi)] = g(x) \in \partial f(x)$ [^3].
3.  **Subgradientes Estocásticos:** Os subgradientes estocásticos têm segundo momento uniformemente limitado, ou seja, existe $M > 0$ tal que:
    $$ \mathbb{E} [||G(x, \xi)||_2^2] \leq M^2, \quad \forall x \in X \quad (5.282) $$
    Isso implica que $\mathbb{E}[||G(x, \xi)||_2] \leq M$ [^6].
4.  **Convexidade Forte:** A função esperada $f(x)$ é fortemente convexa em $X$ com parâmetro $c > 0$. Se $f$ for diferenciável, isso significa:
    $$ (x' - x)^T (\nabla f(x') - \nabla f(x)) \geq c||x' - x||_2^2, \quad \forall x, x' \in X \quad (5.286) $$
    A convexidade forte garante que o minimizador $x^*$ de $f(x)$ em $X$ é único [^11, ^12].
5.  **Passos Decrescentes:** A abordagem clássica utiliza especificamente passos da forma:
    $$ \gamma_j = \frac{\theta}{j}, \quad \text{para algum } \theta > 0 \quad [^14] $$
6.  **Projeção Simples:** O conjunto $X$ é tal que a projeção $\Pi_X(x)$ pode ser calculada eficientemente [^5].

**Análise de Convergência:**

A análise clássica baseia-se no comportamento da distância quadrática esperada ao ótimo $x^*$. Seja $x^*$ a solução ótima única (garantida pela convexidade forte). Definimos $A_j := \frac{1}{2} ||x_j - x^*||_2^2$ e $a_j := \mathbb{E}[A_j]$ (adaptado de (5.283) [^7]). A propriedade de não expansão da projeção (5.280) [^8] é crucial: $|| \Pi_X(x') - \Pi_X(x) ||_2 \leq ||x' - x||_2$. Usando esta propriedade e a definição da iteração (5.281), temos:
$$ A_{j+1} = \frac{1}{2} ||\Pi_X(x_j - \gamma_j G(x_j, \xi^j)) - \Pi_X(x^*)||_2^2 \leq \frac{1}{2} ||x_j - \gamma_j G(x_j, \xi^j) - x^*||_2^2 $$
$$ A_{j+1} \leq A_j - \gamma_j (x_j - x^*)^T G(x_j, \xi^j) + \frac{\gamma_j^2}{2} ||G(x_j, \xi^j)||_2^2 \quad (\text{similar a } 5.284) [^9] $$
Tomando a esperança condicional em $\xi^{[j-1]}$ (histórico até $j-1$), e depois a esperança total, e notando que $x_j$ é independente de $\xi^j$, obtemos:
$$ a_{j+1} \leq a_j - \gamma_j \mathbb{E}[(x_j - x^*)^T g(x_j)] + \frac{\gamma_j^2}{2} \mathbb{E}[||G(x_j, \xi^j)||_2^2] $$
Usando a suposição (5.282), chegamos a:
$$ a_{j+1} \leq a_j - \gamma_j \mathbb{E}[(x_j - x^*)^T g(x_j)] + \frac{\gamma_j^2 M^2}{2} \quad (5.285) [^10] $$
Se $f$ for diferenciável, $g(x_j) = \nabla f(x_j)$. Pela otimalidade de $x^*$, temos $(x - x^*)^T \nabla f(x^*) \geq 0$ para todo $x \in X$ (adaptado de 5.287 [^12]). Usando a convexidade forte (5.286), temos $(x_j - x^*)^T (\nabla f(x_j) - \nabla f(x^*)) \geq c ||x_j - x^*||_2^2 = 2c A_j$. Combinando com a condição de otimalidade, $\mathbb{E}[(x_j - x^*)^T \nabla f(x_j)] \geq \mathbb{E}[2c A_j] = 2c a_j$ (como em 5.288 [^12]). Substituindo na recorrência:
$$ a_{j+1} \leq a_j - \gamma_j (2c a_j) + \frac{\gamma_j^2 M^2}{2} = (1 - 2c\gamma_j)a_j + \frac{\gamma_j^2 M^2}{2} \quad (5.289) [^13] $$
Agora, introduzimos os passos clássicos $\gamma_j = \theta/j$ [^14]:
$$ a_{j+1} \leq \left(1 - \frac{2c\theta}{j}\right)a_j + \frac{\theta^2 M^2}{2j^2} \quad (5.290) [^15] $$
Para a convergência, a análise padrão requer a condição $\theta > 1/(2c)$ [^16]. Sob esta condição, pode-se mostrar por indução que:
> $$ a_j = \frac{1}{2} \mathbb{E} [||x_j - x^*||_2^2] \leq \frac{Q(\theta)}{j} \quad (\text{baseado em } 5.291, 5.292) $$
> onde $Q(\theta) := \max \{ \frac{\theta^2 M^2}{2(2c\theta - 1)}, \frac{1}{2} ||x_1 - x^*||_2^2 \}$ (adaptado de 5.293) [^17].

Este resultado estabelece uma taxa de convergência de $O(1/j)$ para a distância quadrática média ao ótimo. A escolha ótima do parâmetro $\theta$ que minimiza o fator $Q(\theta)$ (assintoticamente) é $\theta = 1/c$ [^18].

**Convergência do Valor Objetivo:**

Se adicionalmente assumirmos que $x^*$ é um ponto interior de $X$ e que $\nabla f(x)$ é Lipschitz contínuo com constante $L$ [^19], i.e., $||\nabla f(x') - \nabla f(x)||_2 \leq L ||x' - x||_2$ (5.294), então temos $f(x) \leq f(x^*) + \frac{L}{2} ||x - x^*||_2^2$ (5.295) [^20]. Tomando a esperança:
$$ \mathbb{E}[f(x_j) - f(x^*)] \leq \frac{L}{2} \mathbb{E}[||x_j - x^*||_2^2] = L a_j \leq \frac{L Q(\theta)}{j} \quad (\text{baseado em } 5.296) [^20] $$
Isso mostra uma taxa de convergência de $O(1/j)$ para o erro esperado no valor da função objetivo [^21].

**Discussão:**

A análise clássica do SA, sob a hipótese de convexidade forte e passos $\gamma_j = \theta/j$ com $\theta > 1/(2c)$, estabelece taxas de convergência de $O(1/\sqrt{j})$ para a raiz do erro quadrático médio $\sqrt{\mathbb{E} [||x_j - x^*||_2^2]}$ e $O(1/j)$ para o gap esperado de otimalidade $\mathbb{E}[f(x_j) - f(x^*)]$ [^21]. A condição $\theta > 1/(2c)$ é crucial; uma superestimação da constante de convexidade forte $c$ (levando a um $\theta$ muito pequeno, tal que $\theta \leq 1/(2c)$) pode comprometer severamente a convergência, como ilustrado no Exemplo 5.36 [^22, ^23]. Este método clássico, apesar de sua importância teórica, pode apresentar convergência lenta na prática, especialmente se a convexidade forte for fraca ( $c$ pequeno) ou ausente. Abordagens mais robustas, como o método SA Robusto (Seção 5.9.2) que utiliza passos constantes e médias (Polyak-Ruppert averaging), foram desenvolvidas para mitigar essas limitações [^24], mas estão fora do escopo desta seção focada na abordagem clássica.

### Conclusão

O algoritmo clássico de Aproximação Estocástica oferece um framework fundamental para a otimização estocástica, baseado na ideia de descida por subgradiente com informação estocástica. Sua análise de convergência, sob a hipótese de **convexidade forte** da função objetivo e utilizando **passos decrescentes** da forma $\gamma_j = \theta/j$ (com a condição $\theta > 1/(2c)$), garante taxas de convergência de $O(1/j)$ para o erro quadrático médio e para o gap esperado de otimalidade. Contudo, a sensibilidade à escolha do parâmetro $\theta$ e à constante de convexidade forte $c$, juntamente com a taxa de convergência que pode ser lenta em problemas mal condicionados, motivou o desenvolvimento de variantes mais robustas do SA. Ainda assim, a abordagem clássica permanece como um pilar teórico essencial no campo da otimização estocástica.

### Referências
[^1]: Capítulo 5, Página 155, Equação (5.1) e texto circundante.
[^2]: Capítulo 5, Página 231, Equação (5.281) e texto introdutório da seção 5.9.1; Página 230, definição do problema (5.1).
[^3]: Capítulo 5, Página 230, Descrição do oráculo estocástico e definição de $g(x)$.
[^4]: Capítulo 5, Página 230, Definição da norma Euclidiana e da projeção $\Pi_X$ (5.279).
[^5]: Capítulo 5, Página 231, Discussão sobre a escolha dos passos $\gamma_j$ e a necessidade de projeção calculável.
[^6]: Capítulo 5, Página 231, Suposição (5.282) sobre o momento dos subgradientes estocásticos.
[^7]: Capítulo 5, Página 231, Definição de $A_j$ e $a_j$ (5.283).
[^8]: Capítulo 5, Página 231, Propriedade de não expansão da projeção (5.280).
[^9]: Capítulo 5, Página 231, Derivação da desigualdade para $A_{j+1}$ (baseado em 5.284).
[^10]: Capítulo 5, Página 231, Desigualdade para a esperança $a_{j+1}$ (5.285).
[^11]: Capítulo 5, Página 231, Definição de convexidade forte (5.286).
[^12]: Capítulo 5, Página 232, Uso da convexidade forte e otimalidade (5.287, 5.288).
[^13]: Capítulo 5, Página 232, Recorrência para $a_{j+1}$ sob convexidade forte (5.289).
[^14]: Capítulo 5, Página 232, Introdução da regra clássica de passos $\gamma_j = \theta/j$.
[^15]: Capítulo 5, Página 232, Recorrência para $a_{j+1}$ com passos clássicos (5.290).
[^16]: Capítulo 5, Página 232, Condição $\theta > 1/(2c)$ para análise de convergência.
[^17]: Capítulo 5, Página 232, Resultado de convergência para $a_j$ (5.291, 5.292) e definição de $Q(\theta)$ (5.293).
[^18]: Capítulo 5, Página 232, Menção da escolha ótima $\theta = 1/c$.
[^19]: Capítulo 5, Página 232, Suposição de Lipschitz continuidade de $\nabla f(x)$ (5.294).
[^20]: Capítulo 5, Página 232, Derivação da convergência do valor objetivo (5.295, 5.296).
[^21]: Capítulo 5, Página 232, Sumário das taxas de convergência esperadas.
[^22]: Capítulo 5, Página 232, Aviso sobre a superestimação de $c$.
[^23]: Capítulo 5, Página 233, Exemplo 5.36 ilustrando convergência lenta.
[^24]: Capítulo 5, Página 233, Menção à abordagem SA Robusta (Polyak/Juditsky).
<!-- END -->