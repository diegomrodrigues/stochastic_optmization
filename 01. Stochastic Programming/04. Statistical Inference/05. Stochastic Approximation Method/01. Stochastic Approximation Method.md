## Capítulo 5.9: Métodos de Aproximação Estocástica

### Introdução

Nesta seção, abordamos a resolução do problema de otimização estocástica introduzido anteriormente:
$$ \text{Min}_{x \in X} \{f(x) := \mathbb{E}[F(x, \xi)]\} $$
onde $X \subseteq \mathbb{R}^n$ é o conjunto de soluções viáveis e $\xi$ é um vetor aleatório [^2]. Assumimos que a função de valor esperado $f(x)$ é bem definida, de valor finito e contínua em todo $x \in X$. Adicionalmente, assumimos que o conjunto $X$ é não vazio, fechado, limitado e **convexo**, e que a função $f(\cdot)$ é **convexa** [^2]. Denotamos por $x^*$ uma solução ótima do problema (5.1) e por $v^* = f(x^*)$ o valor ótimo [^2]. Uma solução ótima $x^*$ existe sob estas condições, dado que $X$ é compacto e $f(x)$ é contínua [^2].

Os **métodos de Aproximação Estocástica (SA)** são algoritmos iterativos projetados para resolver tais problemas [^1]. Eles operam utilizando informações ruidosas ou aproximadas do gradiente (ou subgradiente) para atualizar iterativamente a solução candidata [^1]. Assumimos a disponibilidade de um **oráculo estocástico** que, para qualquer $x \in X$ e uma realização do vetor aleatório $\xi$, retorna o valor $F(x, \xi)$ e um **subgradiente estocástico** $G(x, \xi)$. Este vetor $G(x, \xi)$ é tal que seu valor esperado, $g(x) := \mathbb{E}[G(x, \xi)]$, é um subgradiente de $f(\cdot)$ em $x$, ou seja, $g(x) \in \partial f(x)$ [^2]. Notavelmente, se $F(\cdot, \xi)$ for convexa para todo $\xi$, então uma seleção mensurável $G(x, \xi) \in \partial_x F(x, \xi)$ pode servir como um subgradiente estocástico, desde que a troca entre expectativa e subdiferenciação seja válida [^3]. Assumimos também a capacidade de gerar uma sequência iid $\xi^1, \xi^2, \ldots$ de realizações de $\xi$ [^3].

### Abordagem Clássica de Aproximação Estocástica

A abordagem clássica de SA mimetiza o método de descida por subgradiente [^5]. Dado um ponto inicial $x_1 \in X$ e uma sequência de tamanhos de passo $\gamma_j > 0, j = 1, \ldots$, as iterações são geradas pela fórmula:
$$ x_{j+1} = \Pi_X(x_j - \gamma_j G(x_j, \xi^j)) $$
onde $\Pi_X(x)$ denota a projeção métrica de $x$ sobre o conjunto $X$ em relação à norma Euclidiana $||\cdot||_2$ [^4, ^5]. Sabemos que $\Pi_X$ é um operador não expansivo, i.e., $||\Pi_X(x') - \Pi_X(x)||_2 \leq ||x' - x||_2$ [^5]. A escolha dos tamanhos de passo $\gamma_j$ é crucial [^5]. O conjunto $X$ deve ser suficientemente simples para que a projeção $\Pi_X$ seja computacionalmente tratável [^5].

Para analisar a convergência, assumimos que existe $M > 0$ tal que
$$ \mathbb{E}[||G(x, \xi)||_2^2] \leq M^2, \quad \forall x \in X $$ [^5].
Seja $A_j := \frac{1}{2} ||x_j - x^*||_2^2$ e $a_j := \mathbb{E}[A_j]$ [^6]. Usando a não expansividade da projeção e a independência de $x_j$ e $\xi^j$ (condicionado ao histórico $\xi^{[j-1]}$), pode-se mostrar que
$$ a_{j+1} \leq a_j - \gamma_j \mathbb{E}[(x_j - x^*)^T g(x_j)] + \frac{1}{2} \gamma_j^2 M^2 $$ [^6].

Se adicionalmente assumirmos que $f(x)$ é diferenciável e **fortemente convexa** em $X$ com parâmetro $c > 0$, i.e.,
$$ (x' - x)^T (\nabla f(x') - \nabla f(x)) \geq c ||x' - x||_2^2, \quad \forall x, x' \in X $$ [^7],
então o minimizador $x^*$ é único e $g(x) = \nabla f(x)$ [^8]. Usando a condição de otimalidade $(x - x^*)^T \nabla f(x^*) \geq 0$ [^8] e a forte convexidade, temos $\mathbb{E}[(x_j - x^*)^T \nabla f(x_j)] \geq c \mathbb{E}[||x_j - x^*||_2^2] = 2 c a_j$ [^8]. Substituindo na desigualdade anterior, obtemos:
$$ a_{j+1} \leq (1 - 2c\gamma_j) a_j + \frac{1}{2} \gamma_j^2 M^2 $$ [^8].

Na abordagem clássica, os passos são $\gamma_j = \theta/j$ para alguma constante $\theta > 0$ [^9]. Se $\theta > 1/(2c)$, então por indução pode-se mostrar que $2a_j \leq Q(\theta)/j$ para $j=1, \ldots$, onde
$$ Q(\theta) := \max \{ \theta^2 M^2 (2c\theta - 1)^{-1}, ||x_1 - x^*||_2^2 \} $$ [^9].
Isso implica que a taxa de convergência esperada da distância quadrática é $O(j^{-1})$:
$$ \mathbb{E}[||x_j - x^*||_2^2] \leq \frac{Q(\theta)}{j} $$ [^9].
O valor ótimo de $\theta$ que minimiza $Q(\theta)$ é $\theta = 1/c$ [^9]. Se, além disso, $\nabla f(x)$ for Lipschitz contínua com constante $L > 0$ [^10], então $f(x) \leq f(x^*) + \frac{L}{2} ||x - x^*||_2^2$ [^10], e a taxa de convergência esperada do erro no valor objetivo é $O(j^{-1})$:
$$ \mathbb{E}[f(x_j) - f(x^*)] \leq \frac{Q(\theta)L}{2j} $$ [^10].

Contudo, a escolha clássica $\gamma_j = \theta/j$ pode ser problemática. Se o parâmetro de forte convexidade $c$ for superestimado (levando a $\theta < 1/(2c)$), ou se $f$ não for fortemente convexa ($c=0$), a convergência pode ser extremamente lenta ou inexistente [^10]. O Exemplo 5.36 ilustra como a convergência pode se tornar arbitrariamente lenta quando a constante de forte convexidade $\kappa$ (análoga a $c$) é pequena [^11].

### Abordagem Robusta de SA (Polyak-Juditsky)

Para superar as limitações da SA clássica, Polyak e Juditsky desenvolveram uma abordagem aprimorada [^12]. Essa abordagem, frequentemente chamada de **SA Robusta**, utiliza passos mais longos e faz a média das iterações geradas [^12]. A análise a seguir, baseada em Nemirovski e Yudin [^13], foca em obter estimativas de erro para soluções médias.

Usando a convexidade de $f$, temos $f(x_t) - f(x^*) \leq (x_t - x^*)^T g(x_t)$ [^13]. Combinando isso com (5.285), obtemos $\gamma_t \mathbb{E}[f(x_t) - f(x^*)] \leq a_t - a_{t+1} + \frac{1}{2} \gamma_t^2 M^2$ [^13]. Somando de $t=i$ até $j$ ($1 \leq i \leq j$), temos:
$$ \sum_{t=i}^j \gamma_t \mathbb{E}[f(x_t) - f(x^*)] \leq a_i + \frac{1}{2} M^2 \sum_{t=i}^j \gamma_t^2 $$ [^13].
Defina os pesos $v_t := \gamma_t / (\sum_{\tau=i}^j \gamma_\tau)$ para $t=i, \ldots, j$ e o ponto médio $\bar{x}_{i,j} := \sum_{t=i}^j v_t x_t$ [^13]. Como $X$ é convexo, $\bar{x}_{i,j} \in X$. Pela convexidade de $f$, $f(\bar{x}_{i,j}) \leq \sum_{t=i}^j v_t f(x_t)$. Combinando essas observações:
$$ \mathbb{E}[f(\bar{x}_{i,j}) - f(x^*)] \leq \frac{a_i + \frac{1}{2} M^2 \sum_{t=i}^j \gamma_t^2}{\sum_{t=i}^j \gamma_t} $$ [^13].
Se $i=1$, e lembrando que $a_1 = \frac{1}{2} ||x_1 - x^*||_2^2 \leq \frac{1}{2} D_X^2$, onde $D_X := \max_{x \in X} ||x - x_1||_2$ [^13], obtemos:
$$ \mathbb{E}[f(\bar{x}_{1,j}) - f(x^*)] \leq \frac{\frac{1}{2} D_X^2 + \frac{1}{2} M^2 \sum_{t=1}^j \gamma_t^2}{\sum_{t=1}^j \gamma_t} $$ [^13].

**Política de Passo Constante:** Se o número de iterações $N$ é fixo a priori, podemos usar um passo constante $\gamma_t = \gamma$ para $t=1, \ldots, N$ [^14]. Minimizando o lado direito de (5.306) (a versão de (5.304) para passo constante) em relação a $\gamma > 0$, obtemos o passo ótimo:
$$ \gamma_t = \frac{D_X}{M\sqrt{N}}, \quad t=1, \ldots, N $$ [^14].
Isso leva à estimativa de eficiência:
$$ \mathbb{E}[f(\bar{x}_{1,N}) - f(x^*)] \leq \frac{D_X M}{\sqrt{N}} $$ [^14].
Notavelmente, essa taxa de convergência $O(N^{-1/2})$ é garantida **independentemente de qualquer hipótese de suavidade ou forte convexidade** de $f(\cdot)$ [^14]. Além disso, usar um passo $\gamma_t = \theta D_X / (M\sqrt{N})$ com $\theta > 0$ apenas reescala a estimativa por $\max\{\theta, \theta^{-1}\}$ [^14]. Essa insensibilidade ao ajuste fino dos parâmetros explica o termo "robusto" [^14].

Comparando com a abordagem SAA, a desigualdade de Chebyshev implica que para obter uma solução $\varepsilon$-ótima com probabilidade $1-\alpha$ usando SA robusta, precisamos de $N \geq D_X^2 M^2 / (\varepsilon^2 \alpha)$ iterações (cf. (5.313)) [^15], que escala como $O(\alpha^{-1}\varepsilon^{-2})$. O método SAA correspondente (veja (5.126)) requer $N = O(\varepsilon^{-2} \ln(\alpha^{-1}))$ [^15]. A dependência de $\alpha$ é diferente, mas a dependência de $\varepsilon$ é a mesma, $O(\varepsilon^{-2})$ [^15]. No entanto, a SA geralmente requer muito menos esforço computacional por iteração do que resolver o problema SAA [^28].

### Método de Aproximação Estocástica por Descida no Espelho (Mirror Descent)

A abordagem robusta de SA é adaptada à estrutura Euclidiana do espaço $\mathbb{R}^n$. O método de **Descida no Espelho (Mirror Descent SA)** generaliza essa abordagem, permitindo ajustar o método à geometria do problema, que pode não ser Euclidiana [^16].

Introduzimos uma norma geral $||\cdot||$ em $\mathbb{R}^n$ e sua norma dual $||x||_* := \sup_{||y||\leq 1} y^T x$ [^16]. Uma **função geradora de distância** $d: X \to \mathbb{R}$ é uma função convexa e contínua em $X$, continuamente diferenciável em $X^*$ (que inclui o interior relativo de $X$), e **fortemente convexa** com módulo $\kappa > 0$ em relação à norma $||\cdot||$:
$$ (x' - x)^T (\nabla d(x') - \nabla d(x)) \geq \kappa ||x' - x||^2, \quad \forall x, x' \in X^* $$ [^17].
Um exemplo não Euclidiano é a **função de entropia** $d(x) = \sum x_i \ln x_i$ no simplex padrão $X = \{x \in \mathbb{R}^n_+ : \sum x_i = 1\}$, que é fortemente convexa com $\kappa=1$ em relação à norma $l_1$ ($||x||_1 = \sum |x_i|$) [^18].

Associada a $d(x)$, definimos a **prox-função** (ou divergência de Bregman) $V(x, z) := d(z) - [d(x) + \nabla d(x)^T (z-x)]$ para $x \in X^*, z \in X$ [^19]. $V(x, \cdot)$ é não negativa e fortemente convexa com módulo $\kappa$ [^19]. O **prox-mapeamento** $P_x(y)$ é definido como:
$$ P_x(y) := \arg \min_{z \in X} \{y^T (z - x) + V(x, z)\} $$ [^19].
Para $d(x) = \frac{1}{2} ||x||_2^2$, temos $V(x, z) = \frac{1}{2} ||x-z||_2^2$ e $P_x(y) = \Pi_X(x-y)$ [^19]. O algoritmo Mirror Descent SA generaliza (5.281) como:
$$ x_{j+1} = P_{x_j}(\gamma_j G(x_j, \xi^j)), \quad x_1 \in X^* $$ [^19].

Um resultado chave é o Lema 5.38 [^20]: Para $u \in X, x \in X^*, y \in \mathbb{R}^n$,
$$ V(P_x(y), u) \leq V(x, u) + y^T(u - x) + (2\kappa)^{-1} ||y||_*^2 $$ [^21].
Aplicando este lema com $x = x_j, y = \gamma_j G(x_j, \xi^j)$ e $u = x^*$, obtemos a desigualdade fundamental análoga a (5.284)/(5.327):
$$ \gamma_j (x_j - x^*)^T G(x_j, \xi^j) \leq V(x_j, x^*) - V(x_{j+1}, x^*) + \frac{\gamma_j^2}{2\kappa} ||G(x_j, \xi^j)||_*^2 $$ [^21].

Assumindo a condição de limitação na norma dual, $\mathbb{E}[||G(x, \xi)||_*^2] \leq M_*^2$ para todo $x \in X$ [^23], e seguindo uma análise análoga à da SA Robusta (usando médias $\bar{x}_{1,j} = \sum_{t=1}^j v_t x_t$) [^22], chega-se à Proposição 5.39: Se $x_1 = \arg \min_{x \in X} d(x)$, então
$$ \mathbb{E}[f(\bar{x}_{1,j}) - f(x^*)] \leq \frac{D_{d,X} + (2\kappa)^{-1} M_*^2 \sum_{t=1}^j \gamma_t^2}{\sum_{t=1}^j \gamma_t} $$
onde $D_{d,X} := \max_{u \in X} d(u) - \min_{x \in X} d(x)$ [^23].

Com a **política de passo constante** $\gamma_t = \gamma = \sqrt{2\kappa D_{d,X}} / (M_* \sqrt{N})$ para $t=1, \ldots, N$, a estimativa de eficiência se torna:
$$ \mathbb{E}[f(\bar{x}_{1,N}) - f(x^*)] \leq D_{d,X} M_* \sqrt{\frac{2}{\kappa N}} $$ [^24].
O benefício da Mirror Descent reside na possibilidade de reduzir a constante $M_*$ ou $D_{d,X}$ ou aumentar $\kappa$ escolhendo uma norma e uma função $d(\cdot)$ apropriadas para a geometria de $X$ [^25]. O Exemplo 5.40 mostra que para o simplex padrão, a configuração $l_1$ com entropia pode ser significativamente melhor que a configuração Euclidiana para $n$ grande, pois $M_*$ (baseado em $||\cdot||_\infty$) pode ser muito menor que $M$ (baseado em $||\cdot||_2$) [^25].

### Tópicos Adicionais

**Limites de Probabilidade de Desvio:** Sob a suposição mais forte $\mathbb{E}[\exp\{||G(x, \xi)||_*^2 / M_*^2\}] \leq \exp\{1\}$ [^26], é possível obter limites exponenciais para a probabilidade de desvio usando a teoria de grandes desvios (Teorema 5.41) [^26, ^27]. Para a política de passo constante (5.343),
$$ \Pr\{f(\bar{x}_{1,N}) - f(x^*) \geq \varepsilon\} \leq 12 \exp\{-\varepsilon C^{-1} \sqrt{\kappa N}\} $$
onde $C$ é uma constante dependendo de $M_*, D_{d,X}, \theta$ [^27]. Isso leva a uma estimativa do tamanho da amostra $N = O(\varepsilon^{-2} \kappa^{-1} M_*^2 D_{d,X} \ln^2(\alpha^{-1}))$ para garantir $\varepsilon$-otimalidade com probabilidade $1-\alpha$ [^28]. A dependência em $\alpha$ é melhor (polilogarítmica) do que a obtida via Chebyshev ($O(\alpha^{-1})$) [^28].

**Certificados de Acurácia (Limites Online):** Durante a execução da SA (Mirror Descent), podemos calcular limites inferior e superior observáveis para $v^*$ [^29]. Definimos:
$$ \underline{f}^N := \min_{x \in X} \left\{ \sum_{t=1}^N v_t [F(x_t, \xi^t) + G(x_t, \xi^t)^T (x - x_t)] \right\} $$
$$ \bar{f}^N := \sum_{t=1}^N v_t F(x_t, \xi^t) $$ [^29].
Pode-se mostrar que $\mathbb{E}[\underline{f}^N] \leq v^* \leq \mathbb{E}[\bar{f}^N]$ [^30]. O Teorema 5.43 fornece limites para o gap esperado $\mathbb{E}[\bar{f}^N - \underline{f}^N]$ e outros erros relacionados, que também são da ordem de $O(N^{-1/2})$ sob condições apropriadas [^31, ^32, ^33]. Notavelmente, o limite inferior $\underline{f}^N$ da SA é geralmente mais fraco que o limite inferior $\hat{v}_N$ da SAA (calculado com a mesma amostra) [^33]. No entanto, $\underline{f}^N$ é computacionalmente muito mais barato de obter [^33].

### Conclusão

Os métodos de Aproximação Estocástica oferecem uma abordagem iterativa para resolver problemas de otimização estocástica, utilizando gradientes (ou subgradientes) estocásticos. Enquanto a SA clássica pode sofrer de convergência lenta e sensibilidade a parâmetros, as abordagens Robusta (Polyak-Juditsky) e Mirror Descent fornecem métodos mais estáveis com taxas de convergência $O(N^{-1/2})$ garantidas sob condições gerais de convexidade. A Mirror Descent permite adaptar o algoritmo à geometria do problema, potencialmente melhorando o desempenho. Além disso, técnicas como limites de grandes desvios e certificados de acurácia online fornecem ferramentas adicionais para análise e validação de soluções obtidas por SA. A escolha entre SA e SAA envolve um trade-off entre o esforço computacional por iteração/amostra e a qualidade das estimativas e limites obtidos.

### Referências

[^1]: Definição fornecida no prompt.
[^2]: Página 230, Seção 5.9, Introdução, Problema (5.1), Definições, Suposições, Oráculo Estocástico.
[^3]: Página 230, Remark 18, Geração de amostras iid.
[^4]: Página 230, Seção 5.9.1, Norma Euclidiana, Projeção $\Pi_X$ (5.279).
[^5]: Página 231, Operador $\Pi_X$ (5.280), Algoritmo SA Clássico (5.281), Passos $\gamma_j$, Dependência do histórico $\xi^{[j]}$, Suposição de limitação (5.282).
[^6]: Página 231, Definição de $A_j, a_j$ (5.283), Derivação da desigualdade (5.284), Resultado da expectativa (5.285).
[^7]: Página 231, Suposição de diferenciabilidade e forte convexidade (5.286).
[^8]: Página 232, Propriedades de otimalidade (5.287), Implicação (5.288), Desigualdade resultante (5.289).
[^9]: Página 232, Passo clássico $\gamma_j = \theta/j$, Desigualdade (5.290), Taxa de convergência (5.291, 5.292), Constante $Q(\theta)$ (5.293), $\theta$ ótimo.
[^10]: Página 232, Suposição de Lipschitz (5.294), Limite no valor objetivo (5.295), Taxa de erro $O(j^{-1})$ (5.296), Perigos do passo clássico.
[^11]: Página 233, Exemplo 5.36, Convergência lenta para $\kappa$ pequeno.
[^12]: Página 233, Seção 5.9.2, Introdução à SA Robusta (Polyak, Juditsky).
[^13]: Página 234, Análise da SA Robusta, Desigualdade (5.299), Soma (5.300), Iteradas médias $\bar{x}_{i,j}$ (5.303), Limites (5.304, 5.305), Definição de $v_t$ (5.301).
[^14]: Página 235, Política de Passo Constante (5.306, 5.307), Estimativa de eficiência (5.308), Extensão para $\bar{x}_{K,N}$ (5.309), Passos reescalados (5.310) e estimativa (5.311), Explicação da robustez.
[^15]: Página 235, Comparação com SAA via Chebyshev (5.312, 5.313, 5.314).
[^16]: Página 236, Seção 5.9.3, Introdução à Mirror Descent SA, Norma geral, Norma dual.
[^17]: Página 236, Definição 5.37: Função geradora de distância $d(x)$, módulo $\kappa$, propriedades (5.315, 5.316).
[^18]: Página 237, Exemplos: Euclidiana, Entropia (5.317), Propriedades da entropia.
[^19]: Página 237, Prox-função $V(x, z)$ (5.319), Prox-mapeamento $P_x(y)$ (5.320), Algoritmo Mirror Descent (5.321).
[^20]: Página 237, Lema 5.38, desigualdade (5.322).
[^21]: Página 238, Prova do Lema 5.38 (5.323-5.325), Desigualdade central (5.326), Caso Euclidiano (5.327).
[^22]: Página 239, Análise da Mirror Descent, Definição de $\Delta_j$ (5.328), Desigualdade (5.329), Soma (5.330), Iterada média $\bar{x}_{1,j}$ (5.331), Limite (5.332), Suposição sobre $x_1$ (5.333), Limite em $V(x_1, u)$ (5.334, 5.335), Limite final (5.336).
[^23]: Página 240, Suposição de limitação na norma dual (5.338), Proposição 5.39 (limite de erro) (5.339).
[^24]: Página 240, Política de Passo Constante (5.341), Estimativa de eficiência (5.342), Política reescalada (5.343) e estimativa (5.344).
[^25]: Página 241, Comparação Euclidiana vs Mirror Descent, Exemplo 5.40 (simplex), Estimativas (5.345, 5.346).
[^26]: Página 242, Comparação com SAA, Suposição mais forte (5.347), Teorema 5.41 (Limite de Grande Desvio) (5.348).
[^27]: Página 242-243, Esboço da prova do Teorema 5.41 (5.349-5.355), Forma final (5.356).
[^28]: Página 244, Estimativa do tamanho da amostra (5.357), Comparação com SAA em $\alpha$.
[^29]: Página 244, Seção 5.9.4, Certificados de Acurácia, Limites online $\underline{f}^N, \bar{f}^N$ (5.358, 5.359, 5.361).
[^30]: Página 245, Propriedades dos limites online: $\mathbb{E}[\underline{f}^N] \leq v^* \leq \mathbb{E}[\bar{f}^N]$ (5.362), Lema 5.42 (5.363).
[^31]: Página 245-246, Condições (5.366, 5.367), Teorema 5.43 (limites no gap esperado) (5.368, 5.369, 5.370).
[^32]: Página 246-247, Prova do Teorema 5.43 (5.371-5.377).
[^33]: Página 248, Conclusão da prova, Taxa $O(N^{-1/2})$, Remark 19 (Comparação $\underline{f}^N$ vs $\hat{v}_N$) (5.381).
<!-- END -->