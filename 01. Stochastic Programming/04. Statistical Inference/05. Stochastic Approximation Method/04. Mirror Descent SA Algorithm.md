Okay, aqui está o capítulo detalhado sobre o método Mirror Descent SA, estritamente baseado no contexto fornecido.

## O Método Stochastic Approximation Mirror Descent

### Introdução

Expandindo a discussão sobre métodos de Stochastic Approximation (SA) apresentada nas seções anteriores, particularmente a abordagem clássica Euclidiana (Seção 5.9.1) [^76], [^77] e a abordagem robusta (Seção 5.9.2) [^79], [^80], [^81], introduzimos agora o método **Mirror Descent SA (MDSA)**. O método SA robusto discutido anteriormente é adaptado à estrutura Euclidiana do espaço $\\mathbb{R}^n$ [^82]. Esta seção aborda uma generalização da abordagem SA Euclidiana, permitindo ajustar, até certo ponto, o método à geometria, não necessariamente Euclidiana, do problema em questão [^82]. Uma forma rudimentar desta generalização pode ser encontrada em Nemirovski e Yudin [136], de onde o nome "mirror descent" se origina [^82].

A intuição central por trás do MDSA é que, ao selecionar apropriadamente uma métrica ou geometria que se alinhe melhor com a estrutura do conjunto de viabilidade $X$ e/ou com o comportamento da função objetivo $f(x)$, podemos obter melhores garantias de desempenho ou taxas de convergência práticas. Componentes chave nesta generalização são a **função geradora de distância** (*distance-generating function*) $d(x)$ e a **função prox** (*prox-function*) $V(x, z)$ associada [^1], [^83]. Ao utilizar a função prox, o algoritmo mirror descent SA pode alcançar uma melhor estimativa do erro conforme se relaciona com a geometria do problema, em comparação com a SA Euclidiana [^1]. O objetivo é demonstrar que as propriedades principais da recorrência SA Euclidiana (5.281) são herdadas pela formulação mais geral do MDSA (5.321) [^83].

### Conceitos Fundamentais

#### Normas e Funções Geradoras de Distância

Nesta seção, denotamos por $|| \\cdot ||$ uma norma geral em $\\mathbb{R}^n$. Sua norma dual é definida como $||x||_* := \\sup_{||y|| \\le 1} y^T x$ [^82]. Recordamos a norma $l_p$, $p \\in [1, \\infty)$, definida como $||x||_p := (|x_1|^p + \\dots + |x_n|^p)^{1/p}$, com o caso particular $|| \\cdot ||_2$ sendo a norma Euclidiana [^82]. A norma dual de $|| \\cdot ||_p$ é $|| \\cdot ||_q$, onde $q \\ge 1$ é tal que $1/p + 1/q = 1$ [^82]. A norma dual da norma $l_1$, $||x||_1 = |x_1| + \\dots + |x_n|$, é a norma $l_\\infty$, $||x||_\\infty = \\max \\{|x_1|, \\dots, |x_n|\\}$ [^82].

O conceito central para adaptar a geometria é a **função geradora de distância**.

> **Definição 5.37.** Dizemos que uma função $d: X \\to \\mathbb{R}$ é uma **função geradora de distância** (*distance-generating function*) com módulo $\\kappa > 0$ em relação à norma $|| \\cdot ||$ se o seguinte se verifica: $d(\\cdot)$ é convexa contínua em $X$, o conjunto $X^* := \\{x \\in X : \\partial d(x) \\ne \\emptyset\\}$ é convexo, $d(\\cdot)$ é continuamente diferenciável em $X^*$, e
> $$ (x\' - x)^T (\\nabla d(x\') - \\nabla d(x)) \\ge \\kappa ||x\' - x||^2, \\quad \\forall x, x\' \\in X^*. \\quad (5.316) $$
> [^82]

Note que o conjunto $X^*$ inclui o interior relativo do conjunto $X$ [^82]. A condição (5.316) implica que $d(\\cdot)$ é fortemente convexa em $X^*$ com o parâmetro $\\kappa$ tomado em relação à norma considerada $|| \\cdot ||$ [^82].

Um exemplo simples de uma função geradora de distância (com módulo 1 em relação à norma Euclidiana) é $d(x) := \\frac{1}{2} x^T x$ [^83]. Esta função é continuamente diferenciável em todo $x \\in \\mathbb{R}^n$ [^83]. Outro exemplo interessante é a **função entropia** (*entropy function*)
$$ d(x) := \\sum_{i=1}^n x_i \\ln x_i, \\quad (5.317) $$
definida no simplex padrão $X := \\{x \\in \\mathbb{R}^n_+ : \\sum_{i=1}^n x_i = 1, x \\ge 0\\}$ [^83]. Aqui, $X^*$ é formado por pontos $x \\in X$ com todas as coordenadas diferentes de zero [^83]. A função entropia é fortemente convexa com módulo 1 no simplex padrão em relação à norma $|| \\cdot ||_1$ [^83].

#### Função Prox e Mapeamento Prox

Associada à função geradora de distância $d(x)$, definimos a **função prox** (*prox-function*) $V: X^* \\times X \\to \\mathbb{R}_+$ da seguinte forma:
$$ V(x, z) := d(z) - [d(x) + \\nabla d(x)^T (z - x)]. \\quad (5.319) $$
[^83]
Note que $V(x, \\cdot)$ é não negativa e é fortemente convexa com módulo $\\kappa$ em relação à norma $|| \\cdot ||$ [^83]. A função $V(\\cdot, \\cdot)$ também é conhecida como **divergência de Bregman** (*Bregman divergence*) [^83 footnote].

Definimos também o **mapeamento prox** (*prox-mapping*) $P_x : \\mathbb{R}^n \\to X^*$, associado à função geradora de distância e a um ponto $x \\in X^*$, como:
$$ P_x(y) := \\arg \\min_{z \\in X} \\{y^T (z - x) + V(x, z)\\}. \\quad (5.320) $$
[^83]
O mínimo no lado direito de (5.320) é atingido, pois $d(\\cdot)$ é contínua em $X$ e $X$ é compacto (assumido no início da Seção 5.9 [^76]), e um minimizador correspondente é único, pois $V(x, \\cdot)$ é fortemente convexa em $X$ [^83]. Além disso, pela definição do conjunto $X^*$, todos esses minimizadores pertencem a $X^*$ [^83]. Assim, o mapeamento prox está bem definido [^83].

Para a função geradora de distância Euclidiana $d(x) := \\frac{1}{2} x^T x$, temos $V(x, z) = \\frac{1}{2} ||x-z||_2^2$ e $P_x(y) = \\Pi_X(x - y)$, onde $\\Pi_X$ é a projeção métrica em $X$ definida em (5.279) [^83], [^77]. Neste caso, a fórmula de iteração (5.281) do algoritmo SA Euclidiano pode ser escrita como $x_{j+1} = P_{x_j}(y_j G(x_j, \\xi^j))$, assumindo $x_1 \\in X^*$ [^83].

#### O Algoritmo Mirror Descent SA

O algoritmo Mirror Descent SA generaliza a iteração Euclidiana (5.281). Para uma função geradora de distância $d(x)$ arbitrária, a iteração é definida como:
> $$ x_{j+1} = P_{x_j}(\\gamma_j G(x_j, \\xi^j)), \\quad x_1 \\in X^*. \\quad (5.321) $$
> [^83]

Aqui, $P_{x_j}$ é o mapeamento prox (5.320) parametrizado pelo iterado atual $x_j$, $\\gamma_j > 0$ são os tamanhos de passo, e $G(x_j, \\xi^j)$ é o subgradiente estocástico calculado no iterado $x_j$ usando a realização $\\xi^j$ do vetor aleatório [^83]. O nosso objetivo é demonstrar que as propriedades principais da recorrência Euclidiana (5.281) são herdadas por (5.321) [^83].

### Análise de Convergência

A análise de convergência do MDSA baseia-se numa propriedade fundamental do mapeamento prox encapsulada no seguinte lema, que relaciona a função prox antes e depois de uma atualização.

> **Lemma 5.38.** Para todo $u \\in X$, $x \\in X^*$ e $y \\in \\mathbb{R}^n$ tem-se
> $$ V(P_x(y), u) \\le V(x, u) + y^T(u - x) + (2\\kappa)^{-1} ||y||_*^2. \\quad (5.322) $$
> [^83]

*Prova (Esboço baseado no texto):* Seja $v := P_x(y)$. Como $v \\in X^*$, $d(\\cdot)$ é diferenciável em $v$ [^84]. As condições de otimalidade para (5.320) implicam $(\\nabla d(v) - \\nabla d(x) + y)^T (v - u) \\le 0$ para todo $u \\in X$ [^84]. Usando a definição de $V(\\cdot, \\cdot)$, manipulando termos e aplicando a desigualdade $a^T b \\le (||a||_*^2/\\kappa + \\kappa ||b||^2)/2$ (que decorre da definição da norma dual [^84]) com $a=y$ e $b=x-v$, e utilizando a forte convexidade de $V(x, \\cdot)$ (i.e., $V(x, v) \\ge \\frac{\\kappa}{2} ||x-v||^2$ [^84]), obtemos a desigualdade desejada (5.322) [^84]. $\\blacksquare$

Usando o Lemma 5.38 com $x = x_j$, $y = \\gamma_j G(x_j, \\xi^j)$ e $u = \\bar{x}$ (uma solução ótima), e notando que por (5.321) $x_{j+1} = P_{x_j}(y)$, obtemos:
$$ \\gamma_j (x_j - \\bar{x})^T G(x_j, \\xi^j) \\le V(x_j, \\bar{x}) - V(x_{j+1}, \\bar{x}) + \\frac{\\gamma_j^2}{2\\kappa} ||G(x_j, \\xi^j)||_*^2. \\quad (5.326) $$
[^84]
Observe que para o caso Euclidiano ($d(x) = \\frac{1}{2} x^T x$, $V(x, z) = \\frac{1}{2} ||x-z||_2^2$, $\\kappa=1$, $|| \\cdot ||_* = || \\cdot ||_2$), esta desigualdade (5.326) reduz-se exatamente à relação (5.284) [^84], [^77], que foi crucial na análise do SA Euclidiano.

Podemos agora processar a relação (5.326) de forma semelhante ao caso Euclidiano [^84]. Definindo o erro do subgradiente estocástico $\\Delta_j := G(x_j, \\xi^j) - g(x_j)$ [^85], onde $g(x_j) = E[G(x_j, \\xi^j) | \\xi^{[j-1]}]$ é um subgradiente de $f$ em $x_j$, podemos reescrever (5.326) (substituindo $j$ por $t$) como:
$$ \\gamma_t (x_t - \\bar{x})^T g(x_t) \\le V(x_t, \\bar{x}) - V(x_{t+1}, \\bar{x}) - \\gamma_t (x_t - \\bar{x})^T \\Delta_t + \\frac{\\gamma_t^2}{2\\kappa} ||G(x_t, \\xi^t)||_*^2. \\quad (5.329) $$
[^85]
Somando sobre $t = 1, \\dots, j$ e usando $V(x_{j+1}, \\bar{x}) \\ge 0$, obtemos:
$$ \\sum_{t=1}^j \\gamma_t (x_t - \\bar{x})^T g(x_t) \\le V(x_1, \\bar{x}) + \\sum_{t=1}^j \\frac{\\gamma_t^2}{2\\kappa} ||G(x_t, \\xi^t)||_*^2 - \\sum_{t=1}^j \\gamma_t (x_t - \\bar{x})^T \\Delta_t. \\quad (5.330) $$
[^85]
Definindo os pesos $v_t := \\gamma_t / (\\sum_{\\tau=1}^j \\gamma_\\tau)$ e a solução média $\\bar{x}_{1,j} := \\sum_{t=1}^j v_t x_t$ [^85], por convexidade de $f(\\cdot)$ temos $f(x_t) - f(\\bar{x}) \\le (x_t - \\bar{x})^T g(x_t)$ e $f(\\bar{x}_{1,j}) \\le \\sum_{t=1}^j v_t f(x_t)$ [^85]. Combinando estas, obtemos:
$$ f(\\bar{x}_{1,j}) - f(\\bar{x}) \\le \\frac{V(x_1, \\bar{x}) + \\sum_{t=1}^j (2\\kappa)^{-1} \\gamma_t^2 ||G(x_t, \\xi^t)||_*^2 - \\sum_{t=1}^j \\gamma_t \\Delta_t^T (x_t - \\bar{x})}{\\sum_{t=1}^j \\gamma_t}. \\quad (5.332) $$
[^85]
Assumimos agora que o procedimento começa com o minimizador de $d(\\cdot)$:\n
$$ x_1 := \\arg \\min_{x \\in X} d(x). \\quad (5.333) $$
[^85]
Neste caso, $V(x_1, u) \\le D_{d,X}$, onde $D_{d,X} := [\\max_{u \\in X} d(u) - \\min_{x \\in X} d(x)]^{1/2}$ (note a definição ligeiramente diferente em (5.335) no texto, mas a ideia é um limite superior para a variação de $d$) [^85]. A desigualdade (5.332) torna-se:
$$ f(\\bar{x}_{1,j}) - f(\\bar{x}) \\le \\frac{D_{d,X}^2 + \\sum_{t=1}^j (2\\kappa)^{-1} \\gamma_t^2 ||G(x_t, \\xi^t)||_*^2 - \\sum_{t=1}^j \\gamma_t \\Delta_t^T (x_t - \\bar{x})}{\\sum_{t=1}^j \\gamma_t}. \\quad (5.336) $$
[^85]
Assumindo, como na seção anterior (5.282), que existe uma constante $M_*$ tal que:
$$ E[||G(x, \\xi)||_*^2] \\le M_*^2, \\quad \\forall x \\in X. \\quad (5.338) $$
[^86]
Tomando a esperança em (5.336) e notando que $E[\\Delta_t] = 0$ e $x_t$ é independente de $\\xi^t$ (condicional em $\\xi^{[t-1]}$), obtemos a seguinte proposição.

> **Proposição 5.39.** Seja $x_1 := \\arg \\min_{x \\in X} d(x)$ e suponha que a condição (5.338) se verifica. Então
> $$ E[f(\\bar{x}_{1,j}) - f(\\bar{x})] \\le \\frac{D_{d,X}^2 + (2\\kappa)^{-1} M_*^2 \\sum_{t=1}^j \\gamma_t^2}{\\sum_{t=1}^j \\gamma_t}. \\quad (5.339) $$
> [^86]

### Política de Passo Constante e Estimativas de Erro

Assumimos agora que o número de iterações $N$ é fixado antecipadamente e usamos a política de passo constante $\\gamma_t = \\gamma$ para $t=1, \\dots, N$ [^86]. Então (5.339) torna-se:
$$ E[f(\\bar{x}_{1,N}) - f(\\bar{x})] \\le \\frac{D_{d,X}^2 + (2\\kappa)^{-1} M_*^2 N \\gamma^2}{N\\gamma}. \\quad (5.340) $$
[^86]
Minimizando o lado direito de (5.340) sobre $\\gamma > 0$, chegamos à política de passo constante:
$$ \\gamma_t = \\frac{\\sqrt{2\\kappa} D_{d,X}}{M_* \\sqrt{N}}, \\quad t=1, \\dots, N, \\quad (5.341) $$
[^86]
com a estimativa de eficiência associada:
$$ E[f(\\bar{x}_{1,N}) - f(\\bar{x})] \\le D_{d,X} M_* \\sqrt{\\frac{2}{\\kappa N}}. \\quad (5.342) $$
[^86]
Este resultado pode ser comparado com a estimativa de passo constante (5.307) e a estimativa de eficiência (5.308) para o método SA Euclidiano robusto [^86]. A taxa de convergência esperada $O(N^{-1/2})$ é a mesma [^87]. No entanto, o fator constante $D_{d,X} M_* \\sqrt{2/\\kappa}$ pode ser potencialmente reduzido ajustando a norma $|| \\cdot ||$ (que afeta $M_* = \\sup_x (E[||G(x, \\xi)||_*^2])^{1/2}$) e a função geradora de distância $d(\\cdot)$ (que afeta $D_{d,X}$ e $\\kappa$) à geometria do problema [^87].

Se passarmos dos passos (5.341) para $\\gamma_t = \\theta \\frac{\\sqrt{2\\kappa} D_{d,X}}{M_* \\sqrt{N}}$ com um parâmetro de reescalonamento $\\theta > 0$, a estimativa de eficiência (5.342) torna-se:
$$ E[f(\\bar{x}_{1,N}) - f(\\bar{x})] \\le \\max\\{\\theta, \\theta^{-1}\\} D_{d,X} M_* \\sqrt{\\frac{2}{\\kappa N}}. \\quad (5.344) $$
[^86]
Isto demonstra a robustez da política de passo constante, semelhante ao caso Euclidiano (5.311) [^86].

### Exemplo: O Simplex Padrão

Para ilustrar o potencial benefício do MDSA, consideramos o Exemplo 5.40.
> **Exemplo 5.40.** Seja $X := \\{x \\in \\mathbb{R}^n : \\sum_{i=1}^n x_i = 1, x \\ge 0\\}$ o simplex padrão [^87].
>\
> *   **Configuração Euclidiana:** Usamos $|| \\cdot || = || \\cdot ||_2$ e $d(x) = \\frac{1}{2} x^T x$. Então $\\kappa=1$, $D_{d,X}^2 \\approx 1/2$ (o diâmetro Euclidiano é $\\sqrt{2}$), $x_1$ é o centro $n^{-1}(1, \\dots, 1)^T$, e $M_*^2 = M_2^2 := \\sup_{x \\in X} E[||G(x, \\xi)||_2^2]$. A estimativa (5.344) é $E[f(\\bar{x}_{1,N}) - f(\\bar{x})] \\le O(1) \\max\\{\\theta, \\theta^{-1}\\} M_2 N^{-1/2}$ [^87].
> *   **Configuração $l_1$:** Usamos $|| \\cdot || = || \\cdot ||_1$ e $d(x) = \\sum x_i \\ln x_i$ (entropia) [^87]. Então $\\kappa=1$ (w.r.t. $|| \\cdot ||_1$) [^87], $x_1 = n^{-1}(1, \\dots, 1)^T$ [^87], $D_{d,X}^2 = \\ln n$ [^87], $|| \\cdot ||_* = || \\cdot ||_\\infty$ [^87], e $M_*^2 = M_\\infty^2 := \\sup_{x \\in X} E[||G(x, \\xi)||_\\infty^2]$ [^87]. A prox-função e o mapeamento prox têm formas explícitas [^87]. A estimativa (5.344) é $E[f(\\bar{x}_{1,N}) - f(\\bar{x})] \\le O(1) \\max\\{\\theta, \\theta^{-1}\\} (\\ln n)^{1/2} M_\\infty N^{-1/2}$ [^87].
>\
> Comparando as duas estimativas, observamos que $M_\\infty \\le M_2$ e a razão $M_\\infty / M_2$ pode ser tão pequena quanto $n^{-1/2}$ [^87]. Portanto, a estimativa para a configuração $l_1$ nunca é muito pior que a Euclidiana, e para $n$ grande pode ser muito melhor [^87]. A razão $\\frac{(\\ln n)^{1/2} M_\\infty}{M_2}$ governa a comparação. Como $\\frac{1}{\\sqrt{n}} \\le \\frac{M_\\infty}{M_2} \\le 1$, temos $\\frac{(\\ln n)^{1/2}}{\\sqrt{n}} \\le \\frac{(\\ln n)^{1/2} M_\\infty}{M_2} \\le (\\ln n)^{1/2}$ [^87]. Assim, quando $X$ é um simplex padrão de grande dimensão, temos fortes razões para preferir a configuração $l_1$ à Euclidiana usual [^87].

### Certificados de Acurácia

Semelhante ao método SA Euclidiano robusto, é possível derivar certificados de acurácia para as soluções obtidas pelo MDSA, fornecendo limites superiores e inferiores para o valor ótimo $v^*$ [^90]. Assumimos que os valores da função objetivo estocástica $F(x, \\xi)$ e do subgradiente estocástico $G(x, \\xi)$ são computáveis [^90].

Definimos os limites *online* observáveis:
$$ \\underline{f}^N := \\min_{x \\in X} \\left\\{ \\sum_{t=1}^N v_t [F(x_t, \\xi^t) + G(x_t, \\xi^t)^T (x - x_t)] \\right\\}, \\quad (5.361a) $$
$$ \\bar{F}^N := \\sum_{t=1}^N v_t F(x_t, \\xi^t). \\quad (5.361b) $$
[^90]
Estes limites podem ser calculados durante a execução do algoritmo SA. O limite inferior $\\underline{f}^N$ requer a resolução de um problema de otimização que minimiza uma função linear sobre $X$ [^91].

Pode-se mostrar que, em média, estes limites delimitam o verdadeiro valor ótimo:
> $$ E[\\underline{f}^N] \\le v^* \\le E[\\bar{F}^N]. \\quad (5.362) $$
> [^91]

Além disso, sob condições adicionais, como a limitação da variância de $F(x, \\xi)$ (Condição (5.367): $\\text{Var}[F(x, \\xi)] \\le Q^2$) [^92], é possível derivar estimativas para a esperança dos erros destes limites.

> **Teorema 5.43.** Suponha que as condições (5.366) e (5.367) se verificam. Então
> $$ E[\\bar{F}^N - \\underline{f}^N] \\le \\frac{2 D_{d,X}^2 + \\kappa^{-1} M_*^2 \\sum_{t=1}^N \\gamma_t^2}{\\sum_{t=1}^N \\gamma_t}, \\quad (5.368) $$
> $$ E[\\bar{F}^N - f^*] \\le Q \\sqrt{\\sum_{t=1}^N v_t^2}, \\quad (5.369) $$
> $$ E[|\\underline{f}^N - f^*|] \\le \\left( Q + 4\\sqrt{2}\\kappa^{-1/2} M_* D_{d,X} \\right) \\sqrt{\\sum_{t=1}^N v_t^2} + \\frac{D_{d,X}^2 + 2\\kappa^{-1} M_*^2 \\sum_{t=1}^N \\gamma_t^2}{\\sum_{t=1}^N \\gamma_t}. \\quad (5.370) $$
> [^92]

Para a política de passo constante (5.343), todas estas estimativas de erro são da ordem $O(N^{-1/2})$ [^94]. O limite inferior SA $\\underline{f}^N$ pode ser comparado com o limite inferior SAA $\\hat{v}_N$ (ver Seção 5.6.1). Para a mesma amostra, o limite SA é mais fraco: $\\hat{v}_N \\ge \\underline{f}^N$ (Remark 19) [^94]. No entanto, o limite SA $\\underline{f}^N$ pode ser computado muito mais rapidamente [^95].

### Conclusão

O método Mirror Descent SA representa uma generalização significativa e poderosa da abordagem SA Euclidiana clássica e robusta. Ao introduzir uma função geradora de distância $d(x)$ e uma norma $|| \\cdot ||$ adaptadas à geometria do problema, o MDSA pode potencialmente oferecer melhor desempenho, refletido nas constantes das estimativas de erro $O(N^{-1/2})$. A análise de convergência e as estimativas de erro seguem uma estrutura paralela à do SA Euclidiano robusto, destacando a função prox $V(x, z)$ e o mapeamento prox $P_x(y)$ como análogos da distância quadrática e da projeção Euclidiana. A flexibilidade na escolha da geometria, exemplificada pela configuração $l_1$ no simplex padrão, demonstra o potencial do MDSA para problemas de otimização estocástica em espaços não Euclidianos ou com estruturas específicas. Adicionalmente, a disponibilidade de certificados de acurácia online fornece ferramentas práticas para avaliar a qualidade das soluções obtidas.

### Referências

[^1]: [Página 236] "The robust SA approach discussed in the previous section is tailored to Euclidean structure of the space R^n. In this section, we discuss a generalization of the Euclidean SA approach allowing to adjust, to some extent, the method to the geometry, not necessary Euclidean, of the problem in question; a key component is the prox-function. By using the prox-function and distance-generating function, the mirror descent SA algorithm can achieve a better estimate of the error as it relates to the geometry of the problem compared to the Euclidean SA."
[^76]: [Página 230] "Consider the stochastic optimization problem (5.1)... We denote by x* an optimal solution... We also assume throughout this section that the set X is convex and the function f(·) is convex... We assume availability of the following stochastic oracle: ... a stochastic subgradient G(x, ξ)..."
[^77]: [Página 231] "The classical stochastic approximation (SA) algorithm solves problem (5.1) by mimicking a simple subgradient descent method... generates the iterates by the formula Xj+1 = Πx(xj − YjG(xj, ξ¹))... Πx(x) := arg min ||x - z||2... ||Πx(x\') – Пx(x)||2 ≤ ||x\' − x ||2..."
[^79]: [Página 233] "5.9.2 Robust SA Approach It was argued... that the classical stepsizes yj = O(j⁻¹) can be too small... An important improvement... was developed by Polyak [152] and Polyak and Juditsky [153], where longer stepsizes were suggested with consequent averaging..."
[^80]: [Página 234] "...Based of the above bounds on the expected accuracy of approximate solutions xi, j, we can now develop "reasonable" stepsize policies along with the associated efficiency estimates."
[^81]: [Página 235] "Constant Stepsizes and Error Estimates Assume now that the number of iterations... is fixed... equal to N, and that we use the constant stepsize policy... γt = γ... Minimizing the right-hand side of (5.306)... we arrive at the constant stepsize policy Yt = Dx / (M√N)... associated efficiency estimate E[f(x1,N) − f(x)] ≤ DxM / √N... adjective "robust" in the name of the method."
[^82]: [Página 236] "In this section we denote by || || a general norm on R". Its dual norm is defined as ||x||* := sup_{||y||≤1} y^T x... Definition 5.37. We say that a function d : X → R is a distance-generating function... d(·) is convex continuous... X* := {x ∈ X : ∂d(x) ≠ Ø} is convex, d(·) is continuously differentiable on X*... (x\' – x)^T (∇d(x\') – ∇d(x)) ≥ κ||x\' − x ||^2... Note that the set X* includes the relative interior... implies that d(.) is strongly convex on X with the parameter κ..."
[^83]: [Página 237] "A simple example... d(x) := ½x^T x... Another interesting example is the entropy function d(x) := ∑ xi ln xi... Let us define function V : X* × X → R+ as follows: V(x, z) := d(z) – [d(x) + ∇d(x)^T (z – x)]... refer to V(·, ·) as the prox-function... Note that V(x, ·) is nonnegative and is strongly convex... Let us define prox-mapping Px : R" → X*... Px(y) := arg min_{z∈X} {y^T (z – x) + V(x, z)}... the prox-mapping is well defined... For the (Euclidean) distance-generating function d(x) := ½x^T x, we have that Px (y) = Πx (x - y)... the iteration formula (5.281) of the SA algorithm can be written as Xj+1 = Pxj(yjG(xj, ξ¹))... Our goal is to demonstrate that the main properties of the recurrence (5.281) are inherited by (5.321) for any distance-generating function d(x)."
[^84]: [Página 238] "Lemma 5.38... Proof... v := Px(y)... optimality conditions for (5.320) imply (∇d(v) – ∇d(x) + y)^T (v – u) ≤ 0... Applying this inequality... Also due to the strong convexity of V (x, ·)... V(x, v) ≥ ½κ ||x - v||^2... Using (5.322) with x = xj, y = yjG(xj, §¹), and u = x... we get γj(xj – x)^T G(xj, §¹) ≤ V(xj, x) – V (xj+1, x) + (γj^2 / 2κ) ||G(xj, §¹)||_*^2 (5.326)... Let us observe that for the Euclidean distance-generating function d(x) = ½x^T x... in the Euclidean case (5.326) becomes... exactly the relation (5.284)... We are about to process, in a similar way, the relation (5.326)... arriving at the mirror descent SA."
[^85]: [Página 239] "Specifically, setting Δj := G(xj, ξ¹) – g(xj), (5.328)... rewrite (5.326)... as γt(xt – x)^T g(xt) ≤ V(xt, x) - V(xt+1, x) - γt Δt^T (xt – x) + (γt^2 / 2κ) ||G(xt, ξ^t)||_*^2. (5.329)... Summing up over t = 1, ..., j... Σ γt(xt – x)^T g(xt) ≤ V(x1, x) + Σ (γt^2 / 2κ) ||G(xt, ξ^t)||_*^2 - Σ γt Δt^T (xt – x). (5.330)... Set vt := γt / (Σ γτ)... x1,j := Σ vt xt. (5.331)... By convexity... Σ vt(xt – x)^T g(xt) ≥ (Σ γt) [f(x1,j) – f(x)]. Combining this with (5.330) we obtain f(x1,j) - f(x) ≤ [V(x1, x) + ... ] / (Σ γt). (5.332)... Assume... x1 := argmin d(x). (5.33