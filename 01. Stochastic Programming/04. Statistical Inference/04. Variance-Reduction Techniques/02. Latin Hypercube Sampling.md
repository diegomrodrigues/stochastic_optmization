## Capítulo 5.5.1: Amostragem por Hipercubo Latino (LH)

### Introdução

No contexto das **Variance-Reduction Techniques** [^44], a amostragem por Hipercubo Latino (LH) emerge como um método poderoso para aprimorar a eficiência da estimação em problemas de otimização estocástica, particularmente aqueles abordados pela metodologia Sample Average Approximation (SAA). Conforme discutido anteriormente (Seção 5.4 [^44]), a convergência dos estimadores SAA pode ser melhorada através da redução da variância das médias amostrais [^44]. Enquanto a amostragem Monte Carlo padrão baseia-se em amostras independentes e identicamente distribuídas (iid), e os métodos quasi-Monte Carlo utilizam sequências determinísticas de baixa discrepância [^40, ^43], a amostragem LH adota uma abordagem estratificada combinada com permutação aleatória para induzir correlações negativas entre as amostras, visando uma redução substancial da variância [^45]. Este capítulo detalha a construção e as propriedades da amostragem LH, focando em sua aplicação e vantagens teóricas, especialmente em cenários envolvendo funções objetivo decomponíveis.

### Conceitos Fundamentais

#### O Caso Unidimensional

Consideremos inicialmente a avaliação da esperança $E[F(x, \\xi)]$ onde $\\xi$ é uma variável aleatória unidimensional com função de distribuição acumulada (cdf) $H(\\cdot)$ [^44, Eq. 5.154]. A intuição sugere que gerar pontos amostrais distribuídos uniformemente ao longo do suporte da distribuição pode ser mais eficiente do que usar uma amostra iid, que tende a aglomerar-se em algumas regiões e deixar outras descobertas [^45].

A amostragem estratificada, neste contexto, envolve gerar pontos aleatórios independentes $U^j$ de forma que cada um seja uniformemente distribuído em um subintervalo específico [^45]:
$$
U^j \sim U [(j - 1)/N, j/N], \quad j = 1, ..., N
$$
[^45, Eq. 5.155]. Subsequentemente, uma amostra aleatória de $\\xi$ é construída aplicando a transformação inversa [^45]:
$$
\\xi^j := H^{-1}(U^j), \quad j = 1, ..., N
$$
[^45].

A característica distintiva da abordagem LH unidimensional reside na introdução de uma permutação aleatória. Seja $\\{j_1, ..., j_N\\}$ uma permutação aleatória do conjunto de índices $\\{1, ..., N\\}$ [^45]. As variáveis aleatórias resultantes $\\xi^{j_1}, ..., \\xi^{j_N}$ mantêm a mesma distribuição marginal, com cdf $H(\\cdot)$, mas crucialmente, tornam-se negativamente correlacionadas entre si [^45].

O estimador para $f(x) = E[F(x, \\xi)]$ é então formado pela média amostral:
$$
\\hat{f}_N(x) = \\frac{1}{N} \\sum_{s=1}^N F(x, \\xi^{j_s})
$$
[^45, Eq. 5.156]. Este estimador $\\hat{f}_N(x)$ é não viciado, i.e., $E[\\hat{f}_N(x)] = f(x)$ [^45]. A variância deste estimador é dada por:
$$
\\text{Var}[\\hat{f}_N(x)] = N^{-1}\\sigma^2(x) + 2N^{-2}\\sum_{s<t} \\text{Cov}(F(x, \\xi^{j_s}), F(x, \\xi^{j_t}))
$$
[^45, Eq. 5.157], onde $\\sigma^2(x) := \\text{Var}[F(x, \\xi)]$.

Se a função $F(x, \\cdot)$ for monotonicamente crescente ou decrescente, as variáveis aleatórias $F(x, \\xi^{j_s})$ e $F(x, \\xi^{j_t})$ para $s \\neq t$ também serão negativamente correlacionadas [^45]. Consequentemente, o termo de covariância na equação (5.157) será negativo, resultando em $\\text{Var}[\\hat{f}_N(x)]$ sendo menor, e em alguns casos muito menor, do que a variância $\\sigma^2(x)/N$ obtida com amostragem iid [^45].

#### O Caso Multidimensional: Amostragem por Hipercubo Latino (LH)

Suponha agora que o vetor aleatório $\\xi = (\\xi_1, ..., \\xi_d)$ seja $d$-dimensional e que seus componentes $\\xi_i$, $i = 1, ..., d$, sejam distribuídos **independentemente** uns dos outros [^45]. A ideia da amostragem LH é estender o procedimento unidimensional a cada componente $\\xi_i$ de forma independente [^45].

O procedimento é o seguinte:
1.  Para cada componente $\\xi_i$, $i=1,...,d$, gerar uma amostra estratificada $U_i^j \\sim U[(j-1)/N, j/N]$, para $j=1,...,N$, conforme a equação (5.155) [^45].
2.  Gerar, **independentemente** para cada componente $i$, uma permutação aleatória $\\pi_i$ do conjunto de índices $\\{1, ..., N\\}$ [^45].
3.  Construir as $N$ replicações do vetor $\\xi$. A $j$-ésima replicação, $\\xi^j = (\\xi_1^j, ..., \\xi_d^j)$, tem sua $i$-ésima componente calculada como:
    $$
    \\xi_i^j = H_i^{-1}(U_i^{\\pi_i(j)})
    $$
    onde $H_i$ é a cdf da componente $\\xi_i$ [^45].

Este esquema de amostragem multidimensional é precisamente o que se denomina **Latin hypercube (LH) sampling** [^45].

#### Propriedades e Aplicações

Uma propriedade particularmente interessante da amostragem LH emerge quando a função objetivo $F(x, \\cdot)$ é **decomposable**, ou seja, pode ser escrita como a soma das contribuições de cada componente [^45]:
$$
F(x, \\xi) = F_1(x, \\xi_1) + \\dots + F_d(x, \\xi_d)
$$
Neste caso, a esperança também se decompõe: $E[F(x, \\xi)] = \\sum_{i=1}^d E[F_i(x, \\xi_i)]$ [^45]. A amostragem LH possui uma vantagem teórica notável neste cenário:

> *If the function is decomposable, the LH sampling ensures that each expectation $E[F_i(x, \\xi_i)]$ is estimated in a nearly optimal way* [^45].

Portanto, a amostragem LH funciona especialmente bem em casos onde a função $F(x, \\cdot)$ tende a ter uma estrutura de alguma forma decomponível [^45]. Além disso, o procedimento de amostragem LH é fácil de implementar e pode ser aplicado diretamente aos procedimentos de otimização SAA [^45].

#### Estimação da Variância com Amostragem LH

Um ponto crucial a ser observado é a estimação da variância do estimador $\\hat{f}_N(x)$ quando se utiliza a amostragem LH. Devido à correlação induzida entre as replicações $F(x, \\xi^j)$, os estimadores de variância padrão, como o $\\hat{\\sigma}^2(x)$ definido na equação (5.21) [^9], não são mais válidos.

> *Since in LH sampling the random replications of $F(x, \\xi)$ are correlated with each other, one cannot use variance estimates like (5.21)* [^45].

Para contornar essa dificuldade, uma prática comum é aplicar o método LH em vários **lotes independentes** (independent batches) [^45]. Ou seja, geram-se $M$ amostras LH independentes, cada uma de tamanho $N$. Calcula-se o estimador $\\hat{f}_N^{(m)}(x)$ para cada lote $m=1,...,M$. A média desses estimadores $\\frac{1}{M}\\sum_{m=1}^M \\hat{f}_N^{(m)}(x)$ ainda é um estimador não viciado de $f(x)$, e sua variância pode ser estimada usando a variância amostral dos $\\hat{f}_N^{(m)}(x)$ entre os lotes, pois estes são independentes [^45, ^49]. Esta abordagem permite a construção de intervalos de confiança e a avaliação da precisão do estimador, mesmo sob amostragem LH [^49].

### Conclusão

A amostragem por Hipercubo Latino (LH) representa uma técnica de redução de variância valiosa no arsenal de métodos Monte Carlo para otimização estocástica via SAA [^44, ^45]. Ao impor uma estrutura estratificada e introduzir correlação negativa através de permutações aleatórias independentes para cada dimensão, a LH busca oferecer estimadores com variância reduzida em comparação com a amostragem iid padrão [^45]. Sua eficácia é particularmente pronunciada para funções com estrutura (aproximadamente) decomponível [^45]. Embora a correlação induzida complique a estimação direta da variância a partir de uma única amostra LH, a utilização de lotes independentes fornece uma solução prática para avaliar a incerteza dos estimadores [^45, ^49]. A facilidade de implementação torna a LH uma alternativa atraente para melhorar a eficiência computacional na resolução de problemas SAA [^45].

### Referências

[^9]: Shapiro, A. (2009). Statistical Inference. *Chapter 5*, page 163.
[^40]: Shapiro, A. (2009). Statistical Inference. *Chapter 5*, page 194.
[^43]: Shapiro, A. (2009). Statistical Inference. *Chapter 5*, page 197.
[^44]: Shapiro, A. (2009). Statistical Inference. *Chapter 5*, page 198.
[^45]: Shapiro, A. (2009). Statistical Inference. *Chapter 5*, page 199.
[^49]: Shapiro, A. (2009). Statistical Inference. *Chapter 5*, page 203.

<!-- END -->