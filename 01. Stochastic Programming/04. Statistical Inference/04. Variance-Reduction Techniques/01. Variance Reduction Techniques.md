## Capítulo 5.5: Técnicas de Redução de Variância

### Introdução

Como discutido anteriormente, os estimadores SAA (Sample Average Approximation), como $f_N(x)$ [^1], são construídos para aproximar a função objetivo esperada $f(x) = \mathbb{E}[F(x, \xi)]$ [^1]. A qualidade dessa aproximação, para um tamanho de amostra $N$ finito, está intrinsecamente ligada à variância do estimador SAA. Especificamente, para amostras iid, temos que a variância de $f_N(x)$ é $\sigma^2(x)/N$, onde $\sigma^2(x) := \text{Var}[F(x, \xi)]$ [^44]. Uma variância menor implica em uma convergência mais rápida e estimativas mais precisas dos valores e soluções ótimas do problema estocástico [^44, ^0]. **Variance-reduction techniques** são métodos projetados especificamente para reduzir a variância dos estimadores SAA gerados a partir de amostras, potencializando assim a convergência e a eficiência do método SAA [^44, ^0]. Nesta seção, discutiremos brevemente duas dessas técnicas que parecem ser úteis no contexto SAA: **Latin hypercube sampling** e o método de **linear control random variables** [^44, ^0].

### 5.5.1 Latin Hypercube Sampling (LHS)

A ideia fundamental por trás do *Latin hypercube sampling* (LHS) é gerar pontos amostrais que sejam mais uniformemente distribuídos no espaço amostral do que uma amostra iid padrão, como as geradas por métodos Monte Carlo convencionais [^45]. Esta distribuição mais uniforme visa reduzir a variância do estimador SAA [^45].

Consideremos o caso em que o vetor aleatório $\xi = (\xi_1, ..., \xi_d)$ é $d$-dimensional e seus componentes $\xi_i$, $i = 1, ..., d$, são distribuídos independentemente uns dos outros [^45]. O procedimento LHS para este caso é o seguinte:

1.  Para cada componente $\xi_i$, $i=1,...,d$, geramos $N$ pontos $U_i^j$ independentemente, onde cada $U_i^j$ é uniformemente distribuído no intervalo $[(j-1)/N, j/N]$ [^45]. Matematicamente,
    $$ U_i^j \sim U [(j - 1)/N, j/N], \quad j = 1, ..., N $$ [^45]
2.  Para cada componente $i$, aplicamos uma permutação aleatória $\pi_i$ ao conjunto de índices $\{1, ..., N\}$, gerando as permutações $\pi_i(1), ..., \pi_i(N)$ de forma independente para cada $i$ [^45].
3.  Construímos a amostra aleatória de $\xi$. A $j$-ésima realização amostral $\xi^j$ é obtida aplicando a transformação inversa da função de distribuição acumulada (cdf) $H_i$ de cada componente $\xi_i$ aos pontos uniformes permutados correspondentes [^45]:
    $$ \xi^j = (H_1^{-1}(U_1^{\pi_1(j)}), H_2^{-1}(U_2^{\pi_2(j)}), ..., H_d^{-1}(U_d^{\pi_d(j)})), \quad j = 1, ..., N $$
    (Compare com a transformação inversa univariada em (5.141) [^45]).

Este procedimento garante que as variáveis aleatórias $\xi^1, ..., \xi^N$ tenham a mesma distribuição marginal que $\xi$, com a mesma cdf $H(\cdot)$ [^45]. No entanto, ao contrário de uma amostra iid, as realizações $\xi^j$ geradas por LHS são, em geral, correlacionadas. Especificamente, se a função $F(x, \cdot)$ for monotonicamente crescente ou decrescente em seus argumentos, as variáveis aleatórias $F(x, \xi^s)$ e $F(x, \xi^t)$ para $s \neq t$ tendem a ser negativamente correlacionadas [^45].

A consequência direta dessa correlação negativa é uma redução na variância do estimador SAA $f_N(x)$. A variância de $f_N(x)$ sob LHS é dada por:
$$ \text{Var}[f_N(x)] = N^{-1}\sigma^2(x) + 2N^{-2}\sum_{s<t} \text{Cov}(F(x, \xi^s), F(x, \xi^t)) $$ [^45]
Como os termos de covariância tendem a ser negativos, a variância resultante $\text{Var}[f_N(x)]$ tende a ser menor, e em alguns casos significativamente menor, do que a variância $\sigma^2(x)/N$ obtida com amostragem iid [^45].

O LHS é particularmente eficaz quando a função $F(x, \cdot)$ é aproximadamente decomponível, ou seja, $F(x, \xi) \approx F_1(x, \xi_1) + \dots + F_d(x, \xi_d)$ [^45]. Nesses casos, a estrutura de LHS garante que a expectativa de cada termo $F_i(x, \xi_i)$ seja estimada de forma quase ótima [^45].

Embora o procedimento LHS seja fácil de implementar e possa ser aplicado diretamente em procedimentos de otimização SAA, ele apresenta uma complicação: como as réplicas $F(x, \xi^j)$ são correlacionadas, estimadores de variância padrão, como o $\hat{\sigma}^2(x)$ definido em (5.21) [^9], não são válidos [^45]. Portanto, para estimar a variância do estimador $f_N(x)$ obtido via LHS, o método é usualmente aplicado em múltiplos lotes (*batches*) independentes, e a variância é estimada a partir da variação dos resultados entre os lotes [^45].

### 5.5.2 Método de Variáveis Aleatórias de Controle Lineares (LCRV)

O método de **Linear Control Random Variables** (LCRV) busca reduzir a variância explorando a correlação entre a função de interesse $F(x, \xi)$ e outra função $A(x, \xi)$ cuja esperança seja conhecida, tipicamente zero [^46].

Suponha que tenhamos uma função mensurável $A(x, \xi)$ tal que $\mathbb{E}[A(x, \xi)] = 0$ para todo $x \in X$ [^46]. Para qualquer constante $t \in \mathbb{R}$, a variável aleatória $F(x, \xi) + tA(x, \xi)$ tem a mesma esperança que $F(x, \xi)$, ou seja, $\mathbb{E}[F(x, \xi) + tA(x, \xi)] = f(x)$ [^46]. A variância dessa nova variável aleatória é dada por:
$$ \text{Var}[F(x, \xi) + tA(x, \xi)] = \text{Var}[F(x, \xi)] + t^2\text{Var}[A(x, \xi)] + 2t \text{Cov}(F(x, \xi), A(x, \xi)) $$ [^46]
Esta variância é uma função quadrática em $t$ e atinge seu mínimo para o valor $t^*$ [^46]:
$$ t^* := -\rho_{F,A}(x) \left[ \frac{\text{Var}[F(x, \xi)]}{\text{Var}[A(x, \xi)]} \right]^{1/2} $$ [^46]
onde $\rho_{F,A}(x) := \text{Corr}(F(x, \xi), A(x, \xi))$ é a correlação entre $F(x, \xi)$ e $A(x, \xi)$ [^46]. Substituindo $t^*$ na expressão da variância, obtemos a variância mínima:
$$ \text{Var}[F(x, \xi) + t^*A(x, \xi)] = \text{Var}[F(x, \xi)] [1 - \rho_{F,A}(x)^2] $$ [^46]
> A equação (5.159) demonstra que a redução de variância alcançada é tanto maior quanto mais forte for a correlação (em valor absoluto) entre $F(x, \xi)$ e a variável de controle $A(x, \xi)$. Se a correlação for perfeita ($|\rho_{F,A}(x)| = 1$), a variância pode ser reduzida a zero. [^46]

Na prática, o valor ótimo $t^*$ não é conhecido e precisa ser estimado a partir da amostra $\xi^1, ..., \xi^N$. Pode-se estimar as covariâncias e variâncias na equação (5.158) usando estimadores amostrais padrão, obtendo assim uma estimativa $\hat{t}$ de $t^*$ [^46]. O valor de $f(x)$ pode então ser estimado por:
$$ \hat{f}_N^c(x) := \frac{1}{N} \sum_{j=1}^N [F(x, \xi^j) + \hat{t}A(x, \xi^j)] $$ [^46]
Pela equação (5.159), espera-se que o estimador de controle $\hat{f}_N^c(x)$ tenha uma variância menor que o estimador SAA padrão $f_N(x)$ se $F(x, \xi)$ e $A(x, \xi)$ forem altamente correlacionados [^46].

Existem algumas considerações importantes sobre a aplicação deste método:
1.  O estimador ótimo $\hat{t}$ depende de $x$ e da amostra gerada. Isso torna a aplicação direta de estimadores de controle linear dentro de um procedimento de otimização SAA (que busca otimizar sobre $x$) mais complexa, sendo mais adequados para estimar $\mathbb{E}[F(x, \xi)]$ em um ponto $x$ fixo [^46].
2.  Se a mesma amostra for usada para estimar $\hat{t}$ e para calcular $\hat{f}_N^c(x)$, o estimador resultante pode ser ligeiramente enviesado (*biased*) para $f(x)$ [^46].
3.  O sucesso do método depende crucialmente da disponibilidade de uma função de controle $A(x, \xi)$ com média zero e alta correlação com $F(x, \xi)$. A escolha de tal função depende do problema específico [^46]. Por exemplo, em problemas estocásticos de dois estágios com recurso da forma (2.1)-(2.2), se o vetor $h = h(\omega)$ e a matriz $T = T(\omega)$ no problema de segundo estágio (2.2) forem independentemente distribuídos, e $\mu := \mathbb{E}[h]$, então pode-se usar $A(x, \xi) := (h - \mu)^T Tx$ como variável de controle, pois $\mathbb{E}[(h - \mu)^T T] = \mathbb{E}[h - \mu]\mathbb{E}[T] = 0$ [^46].
4.  O procedimento pode ser estendido para o caso de múltiplas variáveis de controle $A_1(x, \xi), ..., A_m(x, \xi)$, cada uma com média zero e correlacionada com $F(x, \xi)$ [^46].

### Conclusão

As técnicas de redução de variância, como Latin Hypercube Sampling (LHS) e o método de Variáveis Aleatórias de Controle Lineares (LCRV), oferecem estratégias para melhorar a eficiência dos estimadores SAA. O LHS busca uma cobertura mais uniforme do espaço amostral, induzindo correlações negativas que reduzem a variância, especialmente para funções decomponíveis [^45]. O LCRV explora a correlação entre a função objetivo e variáveis auxiliares com média zero para construir estimadores com variância analiticamente menor [^46]. Ambas as técnicas apresentam benefícios potenciais, mas também considerações práticas, como a dificuldade na estimativa da variância para LHS e a necessidade de encontrar variáveis de controle adequadas e a complexidade da aplicação em otimização para LCRV [^45, ^46]. A escolha e a implementação eficaz dessas técnicas dependem das características específicas do problema estocástico em questão.

### Referências

[^0]: Variance-reduction techniques are methods used to reduce the variance of generated sample averages, which in turn enhances convergence of the corresponding SAA estimators. These techniques include Latin hypercube sampling and linear control random variables method.
[^1]: Min {f(x) := E[F(x,§)]}. XEX (5.1) ... Min f(x) := = F(x, ξ) (5.2)
[^9]: ô²(x) := N=1 Σ₁[F(x, §¹) – În(x)]² (5.21)
[^44]: 5.5 Variance-Reduction Techniques. Consider the sample average estimators f(x). We have that if the sample is iid, then the variance of fn(x) is equal to o²(x)/N, where σ²(x) := Var[F(x, §)]. In some cases it is possible to reduce the variance of generated sample averages, which in turn enhances convergence of the corresponding SAA estimators. In section 5.4 we discussed quasi-Monte Carlo techniques for enhancing rates of convergence of sample average approximations. In this section we briefly discuss some other variance-reduction techniques which seem to be useful in the SAA method. 5.5.1 Latin Hypercube Sampling ... 5.5.2 Linear Control Random Variables Method ... 5.5.3 Importance Sampling and Likelihood Ratio Methods
[^45]: 5.5. Variance-Reduction Techniques ... In order to evaluate the above integral numerically, it will be much better to generate sample points evenly distributed than to use an iid sample. (This was already discussed in section 5.4.) That is, we can generate independent random points Uj ~ U [(j − 1)/N, j/N], j = 1, ..., N, (5.155) and then construct the random sample of § by the inverse transformation ξj := H−1(UJ), j = 1, ..., N (compare with (5.141)). Now suppose that j is chosen at random from the set {1, . . ., N} (with equal probability for each element of that set). Then conditional on j, the corresponding random variable Uj is uniformly distributed on the interval [(j – 1)/N, j/N], and the unconditional distribution of Uj is uniform on the interval [0, 1]. Consequently, let {j1, . . ., jn } be a random permutation of the set {1, . . ., N}. Then the random variables §j¹, ..., §jN have the same marginal distribution, with the same cdf H(·), and are negatively correlated with each other. Therefore, the expected value of fn(x) = (1/N) Σ F(x, §ji) = (1/N) Σ F(x, §js) (5.156) is f(x), while Var [f(x)] = N-¹σ²(x) + 2N−²∑s<t Cov (F(x, §js), F(x, §jt)) . (5.157) If the function F(x, ·) is monotonically increasing or decreasing, than the random variables F(x, ξjs) and F(x, ξjt), s ≠ t, are also negatively correlated. Therefore, the variance of fn(x) tends to be smaller, and in some cases much smaller, than σ²(x)/N. Suppose now that the random vector ξ = (§1, ..., §a) is d-dimensional and that its components ξi, i = 1, . . ., d, are distributed independently of each other. Then we can use the above procedure for each component §¡. That is, a random sample Uij of the form (5.155) is generated, and consequently N replications of the first component of § are computed by the corresponding inverse transformation applied to randomly permuted Ujs. The same procedure is applied to every component of § with the corresponding random samples of the form (5.155) and random permutations generated independently of each other. This sampling scheme is called the Latin hypercube (LH) sampling. If the function F(x, ·) is decomposable, i.e., F(x, §) := F₁(x, §1) + ··· + Fa(x, ξα), then E[F(x, §)] = E[F₁(x, §1)] + ··· + E[Fa(x, §a)], where each expectation is calculated with respect to a one-dimensional distribution. In that case, the LH sampling ensures that each expectation E[F; (x, ξ₁)] is estimated in a nearly optimal way. Therefore, the LH sampling works especially well in cases where the function F(x, ·) tends to have a somewhat decomposable structure. In any case, the LH sampling procedure is easy to implement and can be applied to SAA optimization procedures in a straightforward way. Since in LH sampling the random replications of F(x, §) are correlated with each other, one cannot use variance estimates like (5.21). Therefore, the LH method usually is applied in several independent batches in order to estimate variance of the corresponding estimators.
[^46]: 5.5.2 Linear Control Random Variables Method. Suppose that we have a measurable function A(x, §) such that E[A(x, §)] = 0 for all x ∈ X. Then, for any t ∈ R, the expected value of F(x, §) + tA(x, §) is f (x), while Var[F(x, §) + tA(x, §)] = Var [F(x, §)] + t²Var [A(x, §)] + 2t Cov(F(x, §), A(x, §)). It follows that the above variance attains its minimum, with respect to t, for t* := -PF.A(x) [Var(F(x, ξ))/Var(A(x, ξ))]^1/2 (5.158) where PF,A(x) := Corr(F(x, ξ), A(x, §)), and with Var[F(x, §) + t*A(x, §)] = Var [F(x, §)] [1 – PF,A(x)²]. (5.159) For a given x ∈ X and generated sample §¹, ..., §N, one can estimate, in the standard way, the covariance and variances appearing in the right-hand side of (5.158), and hence construct an estimate î of t*. Then f(x) can be estimated by f_hat_N^c(x) := (1/N) Σ [F(x, ξ^j) + îA(x, ξ^j)]. (5.160) By (5.159), the linear control estimator f_hat_N^c(x) has a smaller variance than fn(x) if F(x, §) and A(x, §) are highly correlated with each other. Let us make the following observations. The estimator î, of the optimal value t*, depends on x and the generated sample. Therefore, it is difficult to apply linear control estimators in an SAA optimization procedure. That is, linear control estimators are mainly suitable for estimating expectations at a fixed point. Also, if the same sample is used in estimating î and f_hat_N^c(x), then f_hat_N^c(x) can be a slightly biased estimator of f (x). Of course, the above linear control procedure can be successful only if a function A(x, ξ), with mean zero and highly correlated with F(x, ξ), is available. Choice of such a function is problem dependent. For instance, one can use a linear function A(x, §) := λ(ξ)ᵀx. Consider, for example, two-stage stochastic programming problems with recourse of the form (2.1)-(2.2). Suppose that the random vector h = h(w) and matrix T = T(ω), in the second-stage problem (2.2), are independently distributed, and let μ := E[h]. Then E[(h − μ)ᵀT] = E [(h − μ)]ᵀ E [T] = 0, and hence one can use A(x, §) := (h − µ)ᵀTx as the control variable. Let us finally remark that the above procedure can be extended in a straightforward way to a case where several functions A₁(x,§),..., Am(x, ξ), each with zero mean and highly correlated with F(x, ξ), are available.

<!-- END -->