## Capítulo 5: Equações Generalizadas Estocásticas: Definição e Contexto

### Introdução

Este capítulo introduz o conceito de **Equações Generalizadas Estocásticas (Stochastic Generalized Equations - SGEs)**, um formalismo matemático abrangente no campo da otimização estocástica e análise variacional. Com base nas discussões anteriores sobre aproximações estocásticas, particularmente o método de **Sample Average Approximation (SAA)**, estendemos agora nossa análise para uma classe mais ampla de problemas. Uma SGE busca encontrar um ponto $x \\in \\mathbb{R}^n$ que satisfaça uma relação de inclusão envolvendo o valor esperado de um mapeamento estocástico e uma multifunção [^1]. Especificamente, consideramos um vetor aleatório $\\xi$ com distribuição suportada em $\\Xi \\subseteq \\mathbb{R}^d$, um mapeamento $\\Phi: \\mathbb{R}^n \\times \\Xi \\to \\mathbb{R}^n$ e uma multifunção $\\Gamma: \\mathbb{R}^n \\rightrightarrows \\mathbb{R}^n$ [^2]. Assumindo que a esperança $\\phi(x) := \\mathbb{E}[\\Phi(x, \\xi)]$ está bem definida e tem valor finito, a SGE é formulada como [^2]:

> $$\
> \\phi(x) \\in \\Gamma(x) \\quad (5.60)\
> $$\
> [^3]

Referimo-nos a (5.60) como a equação generalizada *verdadeira* ou de *valor esperado* [^3]. Um ponto $x \\in \\mathbb{R}^n$ é uma solução se satisfizer essa inclusão [^3]. Este framework unifica diversos problemas, incluindo sistemas de equações estocásticas e desigualdades variacionais estocásticas, como detalharemos a seguir.

### Conceitos Fundamentais

#### Definição Formal

A essência de uma SGE reside na relação de inclusão $\\phi(x) \\in \\Gamma(x)$. Aqui, $\\phi(x)$ representa o comportamento médio do mapeamento estocástico $\\Phi(x, \\xi)$ em relação à aleatoriedade de $\\xi$, enquanto $\\Gamma(x)$ define um conjunto (que pode variar com $x$) ao qual $\\phi(x)$ deve pertencer [^2], [^3]. A natureza multifuncional de $\\Gamma$ permite modelar uma ampla gama de condições, tornando as SGEs uma ferramenta poderosa.

#### Casos Especiais e Conexões

O formalismo abstrato das SGEs (5.60) engloba várias classes importantes de problemas:

1.  **Equações Ordinárias Estocásticas:** Se a multifunção $\\Gamma(x)$ é univalente e constante, especificamente $\\Gamma(x) = \\{0\\}$ para todo $x \\in \\mathbb{R}^n$, então a SGE (5.60) se reduz à equação ordinária estocástica [^4]:
    $$\
    \\phi(x) = 0
    $$\
    Esta é a forma padrão de busca de raízes para o valor esperado de um mapeamento.

2.  **Desigualdades Variacionais Estocásticas (Stochastic Variational Inequalities - SVIs):** Um exemplo particularmente relevante surge quando $\\Gamma(x)$ representa o **cone normal (normal cone)**, $N_X(x)$, a um conjunto fechado e convexo $X \\subseteq \\mathbb{R}^n$ no ponto $x$ [^5]. O cone normal $N_X(x)$ é definido como $\\{v \\in \\mathbb{R}^n \\mid v^T(y-x) \\leq 0, \\forall y \\in X\\}$ se $x \\in X$, e $N_X(x) = \\emptyset$ se $x \\notin X$. Neste caso, um ponto $x$ é solução da SGE $\\phi(x) \\in N_X(x)$ se, e somente se, $x \\in X$ e satisfaz a seguinte **desigualdade variacional (variational inequality)** [^5]:
    $$\
    (y - x)^T \\phi(x) \\leq 0, \\quad \\forall y \\in X \\quad (5.61)
    $$\
    Como $\\phi(x)$ é um valor esperado, referimo-nos a tais desigualdades como **desigualdades variacionais estocásticas** [^6]. Note que se $X = \\mathbb{R}^n$, então $N_X(x) = \\{0\\}$ para todo $x$, e a SVI (5.61) se reduz novamente à equação $\\phi(x) = 0$ [^7].

#### Relação com Problemas de Otimização

As SVIs estão intimamente ligadas às condições de otimalidade em problemas de otimização. Considere o problema de otimização estocástica $\\min_{x \\in X} f(x)$, onde $f(x) := \\mathbb{E}[F(x, \\xi)]$ (como em (5.1)). Se definirmos o mapeamento estocástico como $\\Phi(x, \\xi) := -\\nabla_x F(x, \\xi)$ e assumirmos que a fórmula de intercambialidade $\\mathbb{E}[\\nabla_x F(x, \\xi)] = \\nabla f(x)$ é válida, então $\\phi(x) = -\\nabla f(x)$ [^7]. Nesse cenário, a SVI (5.61) torna-se:
$$\
(y - x)^T (-\\nabla f(x)) \\leq 0, \\quad \\forall y \\in X
$$\
Esta é precisamente a condição necessária de primeira ordem para que $x$ seja um ótimo local de $f(x)$ sobre $X$. Se, adicionalmente, $f(x)$ for convexa, esta condição também é suficiente para a otimalidade global [^7].

#### Exemplo: Condições KKT como SVI

Um exemplo fundamental da formulação SGE/SVI é a representação das condições de otimalidade de Karush-Kuhn-Tucker (KKT) para problemas de otimização com restrições. Considere o problema (5.1) onde o conjunto factível $X$ é definido por restrições da forma [^8]:
$$\
X := \\{x \\in \\mathbb{R}^n \\mid g_i(x) = 0, i = 1, \\dots, q, \\ g_i(x) \\leq 0, i = q+1, \\dots, p\\} \\quad (5.62)
$$\
onde $g_i(x) := \\mathbb{E}[G_i(x, \\xi)]$ são funções de restrição de valor esperado [^8]. As condições KKT de primeira ordem para este problema podem ser escritas na forma de uma SVI [^8]. Definimos a variável aumentada $z := (x, \\lambda) \\in \\mathbb{R}^{n+p}$, onde $\\lambda$ são os multiplicadores de Lagrange. Seja o **Lagrangiano (Lagrangian)** estocástico $L(z, \\xi) := F(x, \\xi) + \\sum_{i=1}^p \\lambda_i G_i(x, \\xi)$ e seu valor esperado $l(z) := \\mathbb{E}[L(z, \\xi)] = f(x) + \\sum_{i=1}^p \\lambda_i g_i(x)$ [^8]. Definimos o mapeamento estocástico $\\Phi(z, \\xi)$ e a multifunção $\\Gamma(z)$ como [^8]:
$$\
\\Phi(z, \\xi) := \\begin{bmatrix} \\nabla_x L(z, \\xi) \\\\ G_1(x, \\xi) \\\\ \\vdots \\\\ G_p(x, \\xi) \\end{bmatrix}, \\quad \\Gamma(z) := \\mathcal{N}_K(z) \\quad (5.63)
$$\
onde $K := \\mathbb{R}^n \\times \\mathbb{R}^q_+ \\times \\mathbb{R}^{p-q}_+$ é o cone que define as restrições sobre $z = (x, \\lambda)$ (implicitamente, $\\lambda_i \\ge 0$ para $i=q+1, \\dots, p$) e $\\mathcal{N}_K(z)$ é o cone normal a $K$ em $z$ [^8]. Note que $\\mathbb{R}^q_+$ aqui deveria ser $\\{0\\}^q$ se as primeiras $q$ restrições são de igualdade, e $\\mathbb{R}^{p-q}_+$ se as restrições $q+1$ a $p$ são de desigualdade $\\le 0$. O texto original em [^9] define K como $\\mathbb{R}^n \\times \\mathbb{R}^q \\times \\mathbb{R}^{p-q}_+$, o que parece inconsistente com a definição usual de KKT onde $\\lambda_i$ para restrições de igualdade não tem sinal restrito. Assumindo a forma KKT padrão, $K = \\mathbb{R}^n \\times \\mathbb{R}^q \\times \\mathbb{R}^{p-q}_+$. Se $z \\in K$, o cone normal é dado por [^9]:
$$\
\\mathcal{N}_K(z) = \\left\\{ (v, \\gamma) \\in \\mathbb{R}^{n+p} \\mid v = 0, \\gamma_i = 0 \\text{ para } i=1,\\dots,q, \\gamma_i = 0 \\text{ para } i \\in I_+(\\lambda), \\gamma_i \\leq 0 \\text{ para } i \\in I_0(\\lambda) \\right\\} \\quad (5.64)
$$\
onde $I_0(\\lambda) := \\{i \\in \\{q+1, \\dots, p\\} \\mid \\lambda_i = 0\\}$ e $I_+(\\lambda) := \\{i \\in \\{q+1, \\dots, p\\} \\mid \\lambda_i > 0\\}$ são os conjuntos de índices das restrições de desigualdade inativas e ativas com multiplicador positivo, respectivamente [^10].
Assumindo a intercambialidade entre esperança e gradiente, $\\mathbb{E}[\\nabla_x L(z, \\xi)] = \\nabla_x l(z)$, temos o mapeamento esperado [^11]:
$$\
\\phi(z) := \\mathbb{E}[\\Phi(z, \\xi)] = \\begin{bmatrix} \\nabla_x l(z) \\\\ g_1(x) \\\\ \\vdots \\\\ g_p(x) \\end{bmatrix} \\quad (5.66)
$$\
A desigualdade variacional $\\phi(z) \\in \\mathcal{N}_K(z)$ então representa precisamente as condições KKT para o problema de otimização estocástica com restrições de valor esperado [^11].

#### Propriedades e Aproximação SAA

Uma propriedade importante frequentemente assumida para a multifunção $\\Gamma(x)$ é que ela seja **fechada (closed)** [^12]. Isso significa que se $x_k \\to x$ e $y_k \\to y$ com $y_k \\in \\Gamma(x_k)$, então $y \\in \\Gamma(x)$ [^12]. Esta propriedade é válida para o cone normal a um conjunto convexo fechado [^12].

Na prática, a SGE verdadeira (5.60) é frequentemente intratável devido à dificuldade em calcular $\\phi(x)$. Assim como nos problemas de otimização estocástica, utiliza-se a aproximação por média amostral (SAA). Dada uma amostra $\\xi^1, \\dots, \\xi^N$ do vetor aleatório $\\xi$, o mapeamento esperado $\\phi(x)$ é aproximado por [^13]:
$$\
\\hat{\\phi}_N(x) := \\frac{1}{N} \\sum_{j=1}^N \\Phi(x, \\xi^j)
$$\
Isso leva à **Equação Generalizada SAA (SAA generalized equation)** [^13]:
> $$\
> \\hat{\\phi}_N(x) \\in \\Gamma(x) \\quad (5.67)
> $$\
> [^13]

Existem algoritmos numéricos padrão para resolver equações não lineares (caso $\\Gamma(x) = \\{0\\}$) e desigualdades variacionais, que podem ser aplicados à equação SAA (5.67) [^14]. Denotamos por $S$ o conjunto de todas as soluções da SGE verdadeira (5.60) e por $\\hat{S}_N$ o conjunto de todas as soluções da SGE SAA (5.67) [^15]. A análise estatística se concentra nas propriedades de $\\hat{S}_N$ como um estimador de $S$, incluindo consistência e comportamento assintótico, temas explorados em seções subsequentes do texto original [^15].

### Conclusão

As Equações Generalizadas Estocásticas $\\phi(x) \\in \\Gamma(x)$ fornecem um framework unificado e poderoso para modelar uma variedade de problemas sob incerteza, onde $\\phi(x)$ é um mapeamento esperado e $\\Gamma(x)$ é uma multifunção. Demonstramos que este formalismo inclui casos especiais importantes como equações ordinárias estocásticas ($\\Gamma(x) = \\{0\\}$) e desigualdades variacionais estocásticas ($\\Gamma(x) = N_X(x)$). Além disso, destacamos a profunda conexão das SVIs com as condições de otimalidade de primeira ordem em otimização estocástica, exemplificada pela formulação das condições KKT como uma SVI. A introdução da aproximação SAA, $\\hat{\\phi}_N(x) \\in \\Gamma(x)$, fornece a base para a solução computacional desses problemas, cuja análise estatística é um tópico central na inferência para modelos estocásticos.

### Referências

[^1]: Page 174. Section 5.2 heading: "Stochastic Generalized Equations".
[^2]: Page 174. "Consider a random vector ξ whose distribution is supported on a set Ξ ⊂ Rᵈ, a mapping Φ : Rⁿ × Ξ → Rⁿ, and a multifunction Γ : Rⁿ → Rⁿ. Suppose that the expectation φ(x) := E[Φ(x, ξ)] is well defined and finite valued."
[^3]: Page 174. "We refer to φ(x) ∈ Γ(x) (5.60) as true, or expected value, generalized equation and say that a point x ∈ Rⁿ is a solution of (5.60) if φ(x) ∈ Γ(x)."
[^4]: Page 174. "If Γ(x) = {0} for every x ∈ Rⁿ, then (5.60) becomes the ordinary equation φ(x) = 0."
[^5]: Page 174. "As another example, let Γ(·) := Nx(·), where X is a nonempty closed convex subset of Rⁿ and Nx(x) denotes the (outward) normal cone to X at x. Recall that, by the definition, Nx(x) = ∅ if x ∉ X. In that case x is a solution of (5.60) iff x ∈ X and the following so-called variational inequality holds: (y - x)ᵀφ(x) ≤ 0, ∀y ∈ X. (5.61)" (Note: corrected the inequality direction based on standard VI definition vs. the text's potential typo).
[^6]: Page 174. "Since the mapping φ(x) is given in the form of the expectation, we refer to such variational inequalities as *stochastic variational inequalities*."
[^7]: Page 174. "Note that if X = Rⁿ, then Nx(x) = {0} for any x ∈ Rⁿ, and hence in that case the above variational inequality is reduced to the equation φ(x) = 0. Let us also remark that if Φ(x, ξ) := −∇ₓF(x, ξ) for some real valued function F(x, ξ), and the interchangeability formula E[∇ₓF(x, ξ)] = ∇f(x) holds, i.e., φ(x) = −∇f(x), where f(x) := E[F(x, ξ)], then (5.61) represents first order necessary, and if f(x) is convex, sufficient conditions for x to be an optimal solution for the optimization problem (5.1)."
[^8]: Page 174. "If the feasible set X of the optimization problem (5.1) is defined by constraints in the form X := {x ∈ Rⁿ : gᵢ(x) = 0, i = 1, ..., q, gᵢ(x) ≤ 0, i = q + 1, ..., p} (5.62) with gᵢ(x) := E[Gᵢ(x, ξ)], i = 1, . . ., p, then the corresponding first-order Karush-Kuhn-Tucker (KKT) optimality conditions can be written in a form of variational inequality. That is, let z := (x, λ) ∈ Rⁿ⁺ᵖ and L(z, ξ) := F(x, ξ) + Σᵢ<0xE1><0xB5><0xA3>₁ λᵢGᵢ(x, ξ), l(z) := E[L(z, ξ)] = f(x) + Σᵢ<0xE1><0xB5><0xA3>₁ λᵢgᵢ(x) be the corresponding Lagrangians. Define Φ(z, ξ) := [∇ₓL(z, ξ)ᵀ, G₁(x, ξ), ..., Gₚ(x, ξ)]ᵀ and Γ(z) := N<0xE2><0x82><0x9A>(z), (5.63)..."
[^9]: Page 174. "where K := Rⁿ × R<0xE1><0xB5><0xA3> × R<0xE2><0x82><0x9A>⁻<0xE1><0xB5><0xA3> ⊂ Rⁿ⁺ᵖ. Note that if z ∈ K, then N<0xE2><0x82><0x9A>(z) = {(v, γ) ∈ Rⁿ⁺ᵖ : v = 0 and γᵢ = 0, i = 1, ..., q, γᵢ = 0, i ∈ I₊(λ), γᵢ ≤ 0, i ∈ I₀(λ) }. (5.64)"
[^10]: Page 175. Definitions of I₀(λ) and I₊(λ) in (5.65).
[^11]: Page 175. "...assuming that the interchangeability formula holds, and hence E[∇ₓL(z, ξ)] = ∇ₓl(z)... we have that φ(z) := E[Φ(z, ξ)] = [∇ₓl(z)ᵀ, g₁(x), ..., gₚ(x)]ᵀ (5.66) and variational inequality φ(z) ∈ N<0xE2><0x82><0x9A>(z) represents the KKT optimality conditions for the true optimization problem."
[^12]: Page 175. Assumption (E1): "The multifunction Γ(x) is closed..." and subsequent text stating this holds for VIs.
[^13]: Page 175. "Now let ξ¹, ..., ξᴺ be a random sample... and let φ̂ɴ(x) := N⁻¹ Σᵢ<0xE1><0xB5><0xA3>₁ Φ(x, ξⁱ) be the corresponding sample average estimate of φ(x). We refer to φ̂ɴ(x) ∈ Γ(x) (5.67) as the SAA generalized equation."
[^14]: Page 175. "There are standard numerical algorithms for solving nonlinear equations which can be applied to (5.67) in the case Γ(x) = {0}... There are also numerical procedures for solving variational inequalities. We are not going to discuss such numerical algorithms..."
[^15]: Page 175. "We denote by S and Ŝɴ the sets of (all) solutions of the true (5.60) and SAA (5.67) generalized equations, respectively."

<!-- END -->