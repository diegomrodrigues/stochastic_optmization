## Propriedades Estatísticas da Função de Aproximação por Média Amostral $f_N(x)$

### Introdução

No contexto da programação estocástica, frequentemente nos deparamos com problemas da forma:
$$ \text{Min}_{x \in X} \{f(x) := E[F(x, \xi)]\} $$
onde $X$ é um subconjunto não vazio e fechado de $\mathbb{R}^n$, $\xi$ é um vetor aleatório com distribuição de probabilidade $P$ suportada em $\Xi \subset \mathbb{R}^d$, e $F: X \times \Xi \to \mathbb{R}$ [^1]. A função $f(x)$ representa o valor esperado de $F(x, \xi)$ e é frequentemente difícil ou impossível de calcular analiticamente. A metodologia de **Sample Average Approximation (SAA)** surge como uma abordagem poderosa para lidar com tais problemas. Ela consiste em aproximar a função objetivo $f(x)$ pela sua média amostral, baseada em uma amostra $\xi^1, ..., \xi^N$ de $N$ realizações do vetor aleatório $\xi$. A função SAA é definida como:
$$ f_N(x) := \frac{1}{N} \sum_{j=1}^N F(x, \xi^j) $$
e o problema SAA associado é $\min_{x \in X} f_N(x)$ [^1].

Este capítulo foca nas propriedades estatísticas fundamentais da própria função de aproximação $f_N(x)$ como um estimador para a função "verdadeira" $f(x)$. Analisaremos suas características de não viesamento (*unbiasedness*) e convergência, tanto pontual (*pointwise*) quanto uniforme (*uniform*). Como veremos, estas propriedades são a base para a justificação teórica do método SAA e para a análise da convergência dos estimadores SAA do valor ótimo ($\hat{v}_N$) e das soluções ótimas ($\hat{S}_N$) do problema original [^6].

### Conceitos Fundamentais

#### Definição e Interpretação

A função SAA $f_N(x)$ é a média aritmética dos valores da função $F(x, \cdot)$ avaliada nos pontos da amostra $\xi^1, ..., \xi^N$ [^1]. Uma interpretação alternativa útil é considerar $f_N(x)$ como o valor esperado de $F(x, \xi)$ com respeito à **medida de probabilidade empírica** $P_N := N^{-1} \sum_{j=1}^N \delta(\xi^j)$, onde $\delta(\xi)$ denota a medida de massa unitária no ponto $\xi$ [^2]. Ou seja, $f_N(x) = E_{P_N}[F(x, \xi)]$ [^2]. Assume-se frequentemente que a amostra $\xi^1, ..., \xi^N$ é **independentemente e identicamente distribuída (iid)**, seguindo a mesma distribuição $P$ de $\xi$ [^3].

#### Não Viesamento (Unbiasedness)

Uma propriedade estatística elementar e importante de $f_N(x)$ é que, para qualquer $x \in X$ fixo, ele é um estimador não viesado de $f(x)$.

> **Propriedade 1 (Não Viesamento):** Para qualquer $x \in X$, temos $E[f_N(x)] = f(x)$ [^5].

*Prova.* Assumindo que cada $\xi^j$ na amostra tem a mesma distribuição marginal $P$ que $\xi$ [^3], a esperança de $f_N(x)$ é:
$$ E[f_N(x)] = E\left[\frac{1}{N} \sum_{j=1}^N F(x, \xi^j)\right] $$
Pela linearidade da esperança:
$$ E[f_N(x)] = \frac{1}{N} \sum_{j=1}^N E[F(x, \xi^j)] $$
Como $E[F(x, \xi^j)] = E[F(x, \xi)] = f(x)$ para todo $j=1, ..., N$:
$$ E[f_N(x)] = \frac{1}{N} \sum_{j=1}^N f(x) = \frac{1}{N} (N f(x)) = f(x) $$
Isso confirma que $f_N(x)$ é um **estimador não viesado** (*unbiased estimator*) de $f(x)$ [^5]. $\blacksquare$

#### Convergência Pontual (Pointwise Convergence)

A Lei dos Grandes Números (LLN) fundamenta a convergência de $f_N(x)$ para $f(x)$ à medida que o tamanho da amostra $N$ aumenta.

> **Propriedade 2 (Convergência Pontual):** Sob condições de regularidade, $f_N(x)$ converge pontualmente para $f(x)$ com probabilidade 1 (w.p. 1) quando $N \to \infty$ [^2].

Em particular, pela LLN clássica, esta convergência pontual ocorre se a amostra for iid [^3] e $E[|F(x, \xi)|] < \infty$. Esta propriedade é crucial, pois sugere que, para $N$ suficientemente grande, a função SAA $f_N(x)$ se aproxima da função verdadeira $f(x)$ em cada ponto $x$. Isso motiva a expectativa de que a solução do problema SAA (5.2) se aproxime da solução do problema verdadeiro (5.1) [^6]. De fato, se a LLN pontual se mantém, temos que $\limsup_{N\to\infty} \hat{v}_N \le f(x)$ w.p. 1 para qualquer $x \in X$, o que implica $\limsup_{N\to\infty} \hat{v}_N \le v^*$ w.p. 1 [^10].

#### Convergência Uniforme (Uniform Convergence)

Enquanto a convergência pontual garante a aproximação em cada ponto individualmente, a convergência uniforme garante que a aproximação ocorra de maneira similar em todo um conjunto de pontos $x$.

> **Propriedade 3 (Convergência Uniforme):** Sob condições adicionais suaves, a convergência de $f_N(x)$ para $f(x)$ é uniforme [^4].

O texto referencia a seção 7.2.5 [^4], e posteriormente os Teoremas 7.48 e 7.50 [^15], para condições específicas que garantem a convergência uniforme, mas esses detalhes não estão presentes no contexto fornecido. A convergência uniforme é particularmente importante para estabelecer a consistência dos estimadores SAA. Por exemplo, a Proposição 5.2 afirma que se $f_N(x)$ converge para $f(x)$ w.p. 1, uniformemente em $X$, então o valor ótimo SAA $\hat{v}_N$ converge para o valor ótimo verdadeiro $v^*$ w.p. 1 [^11]. Similarmente, o Teorema 5.3, que trata da consistência do conjunto de soluções ótimas $\hat{S}_N$, requer convergência uniforme de $f_N(x)$ em um conjunto compacto $C$ que contém o conjunto de soluções verdadeiras $S$ (ver [^13], suposição (iii)).

A Proposição 5.1 estabelece uma ligação importante entre um tipo de convergência pontual e a convergência uniforme em conjuntos compactos.

**Proposição 5.1.** *Sejam $f: X \to \mathbb{R}$ e $f_N: X \to \mathbb{R}$ uma sequência de funções de valor real (determinísticas). As duas propriedades seguintes são equivalentes:*\
*(i) para qualquer $x \in X$ e qualquer sequência $\{x_N\} \subset X$ convergindo para $x$, segue que $f_N(x_N)$ converge para $f(x)$, e*\
*(ii) a função $f(\cdot)$ é contínua em $X$ e $f_N(\cdot)$ converge para $f(\cdot)$ uniformemente em qualquer subconjunto compacto de $X$ [^8].*

*Prova.* Suponha que a propriedade (i) valha. Considere um ponto $\bar{x} \in X$, uma sequência $\{x_k\} \subset X$ convergindo para $\bar{x}$ e um número $\varepsilon > 0$. Tomando uma sequência com cada elemento igual a $x_1$, temos por (i) que $f_N(x_1) \to f(x_1)$. Portanto, existe $N_1$ tal que $|f_{N_1}(x_1) - f(x_1)| < \varepsilon/2$. Similarmente, existe $N_2 > N_1$ tal que $|f_{N_2}(x_2) - f(x_2)| < \varepsilon/2$, e assim por diante. Considere agora uma sequência, denotada $x'_N$, construída como segue: $x'_i = x_1, i = 1, ..., N_1$, $x'_i = x_2, i = N_1 + 1, ..., N_2$, etc. Temos que esta sequência $x'_N$ converge para $\bar{x}$ e, portanto, $|f_N(x'_N) - f(\bar{x})| < \varepsilon/2$ para todo $N$ suficientemente grande. Temos também que $|f_{N_k}(x'_{N_k}) - f(x_k)| < \varepsilon/2$, e logo $|f(x_k) - f(\bar{x})| < \varepsilon$ para todo $k$ suficientemente grande. Isso mostra que $f(x_k) \to f(\bar{x})$ e, portanto, $f(\cdot)$ é contínua em $\bar{x}$ [^9].

Agora, seja $C$ um subconjunto compacto de $X$. Argumentando por contradição, suponha que $f_N(\cdot)$ não converge para $f(\cdot)$ uniformemente em $C$. Então existe uma sequência $\{x_N\} \subset C$ e $\varepsilon > 0$ tal que $|f_N(x_N) - f(x_N)| \ge \varepsilon$ para todo $N$. Como $C$ é compacto, podemos assumir que $\{x_N\}$ converge para um ponto $\bar{x} \in C$. Temos
$$ |f_N(x_N) - f(x_N)| \le |f_N(x_N) - f(\bar{x})| + |f(x_N) - f(\bar{x})| \quad (5.4) $$
O primeiro termo no lado direito de (5.4) tende a zero por (i) e o segundo termo tende a zero pois $f(\cdot)$ é contínua, e portanto esses termos são menores que $\varepsilon/2$ para $N$ suficientemente grande. Isso gera a contradição desejada [^9].

Inversamente, suponha que a propriedade (ii) valha. Considere uma sequência $\{x_N\} \subset X$ convergindo para um ponto $\bar{x} \in X$. Podemos assumir que esta sequência está contida em um subconjunto compacto de $X$. Utilizando a desigualdade
$$ |f_N(x_N) - f(\bar{x})| \le |f_N(x_N) - f(x_N)| + |f(x_N) - f(\bar{x})| \quad (5.5) $$
e notando que o primeiro termo no lado direito desta desigualdade tende a zero por causa da convergência uniforme de $f_N$ para $f$ e o segundo termo tende a zero pela continuidade de $f$, obtemos que a propriedade (i) vale [^9]. $\blacksquare$

#### Normalidade Assintótica (Asymptotic Normality)

Além da convergência w.p. 1, o Teorema do Limite Central (CLT) fornece informações sobre a distribuição assintótica do erro de estimação $f_N(x) - f(x)$ para um $x$ fixo.

> **Propriedade 4 (Normalidade Assintótica Pontual):** Suponha que a amostra é iid e que a variância $\sigma^2(x) := \text{Var}[F(x, \xi)]$ é finita. Pelo CLT, temos que:
> $$ N^{1/2} [f_N(x) - f(x)] \xrightarrow{D} Y_x $$
> onde $\xrightarrow{D}$ denota convergência em distribuição e $Y_x$ tem distribuição normal com média 0 e variância $\sigma^2(x)$, i.e., $Y_x \sim N(0, \sigma^2(x))$ [^18].

Isso implica que, para $N$ grande, $f_N(x)$ tem distribuição aproximadamente normal com média $f(x)$ e variância $\sigma^2(x)/N$ [^18]. Esta propriedade permite a construção de intervalos de confiança (aproximados) para $f(x)$ usando $f_N(x)$ e uma estimativa da variância, $\hat{\sigma}^2(x) = \frac{1}{N-1} \sum_{j=1}^N [F(x, \xi^j) - f_N(x)]^2$ [^19]. O erro de estimação de $f(x)$ por $f_N(x)$ é estocasticamente da ordem de $O_p(N^{-1/2})$ [^20].

Resultados mais avançados, como o **Teorema do Limite Central Funcional (Functional CLT)**, estendem essa ideia. Sob condições mais fortes, como a continuidade Lipschitz de $F(x, \xi)$ (suposições A1 e A2 em [^24]), o processo $N^{1/2}(f_N - f)$, visto como um elemento aleatório no espaço $C(X)$ de funções contínuas em $X$ (equipado com a norma do supremo), converge em distribuição para um processo Gaussiano $Y$ com média zero e estrutura de covariância específica [^24]. Este resultado é fundamental para a análise assintótica de primeira ordem do valor ótimo SAA $\hat{v}_N$, como visto no Teorema 5.7 [^25, ^26], e também para análises de segunda ordem e da convergência dos estimadores $\hat{S}_N$ [^28, ^29, ^30].

### Conclusão

A função de aproximação por média amostral $f_N(x)$ desempenha um papel central na metodologia SAA. Suas propriedades estatísticas - ser um estimador não viesado de $f(x)$ [^5], convergir pontualmente w.p. 1 para $f(x)$ pela LLN [^2], e, sob condições adicionais, convergir uniformemente [^4] e satisfazer um CLT [^18] (e até mesmo um FCLT [^24]) - são os pilares que sustentam a validade teórica da abordagem SAA. A compreensão dessas propriedades é essencial para analisar a convergência dos estimadores SAA $\hat{v}_N$ e $\hat{S}_N$ para seus correspondentes verdadeiros $v^*$ e $S$, como explorado em detalhe em outras seções do texto [^6, ^10, ^11, ^13, ^25]. A taxa de convergência $O_p(N^{-1/2})$ do erro de estimação pontual [^20] também fornece uma base quantitativa para a análise de erro do método.

### Referências

[^1]: Page 155, Eq. (5.1), (5.2) and surrounding text.
[^2]: Page 156, Paragraph starting "By the Law...". Eq. (5.3).
[^3]: Page 156, Paragraph starting "As with data vector...". Paragraph starting "By the Law...".
[^4]: Page 156, Paragraph starting "By the Law...".
[^5]: Page 156, Paragraph starting "By the Law...".
[^6]: Page 156, Paragraph starting "By the Law...".
[^7]: Page 156, Paragraph starting "We can view...".
[^8]: Page 156, Proposition 5.1.
[^9]: Page 157, Proof of Proposition 5.1. Eq. (5.4), (5.5).
[^10]: Page 157, Section 5.1.1, Paragraph starting "In this section...". Eq. (5.6).
[^11]: Page 157, Proposition 5.2.
[^12]: Page 158, Proof of Proposition 5.2. Eq. (5.7).
[^13]: Page 158, Theorem 5.3.
[^14]: Page 158, Proof of Theorem 5.3. Eq. (5.8).
[^15]: Page 158, Paragraph starting "Recall that by Proposition 5.1...".
[^16]: Page 159, Theorem 5.4 and its Proof.
[^17]: Page 163, Section 5.1.2, Paragraph starting "Consistency...".
[^18]: Page 163, Section 5.1.2, Eq. (5.19) and surrounding text.
[^19]: Page 163, Section 5.1.2, Eq. (5.20), (5.21).
[^20]: Page 163, Section 5.1.2, Text after Eq. (5.21).
[^21]: Page 163, Section 5.1.2, Eq. (5.22) and surrounding text.
[^22]: Page 163, Proposition 5.6.
[^23]: Page 164, Proof of Proposition 5.6.
[^24]: Page 164, Paragraph starting "First Order Asymptotics...", Footnote 21.
[^25]: Page 165, Theorem 5.7.
[^26]: Page 165, Proof of Theorem 5.7.
[^27]: Page 165, Eq. (5.29) and surrounding text.
[^28]: Page 166, Section 5.1.3, Paragraph starting "We view $f_N$...".
[^29]: Page 167, Theorem 5.8.
[^30]: Page 168, Paragraph starting "One of the difficulties...". Eq. (5.38).
[^31]: Page 180, Section 5.3, Eq. (5.83), (5.84) and surrounding text.
[^32]: Page 181, Paragraph starting "By the results...".
[^33]: Page 181, Definition of $S^\epsilon$ and $\hat{S}_N^\epsilon$.

<!-- END -->