## Capítulo 5.1.1: Consistência dos Estimadores SAA

### Introdução

Como estabelecido anteriormente, o problema de programação estocástica (5.1) busca minimizar a função objetivo $f(x) := E[F(x, \xi)]$ sobre um conjunto $X$ [^1]. A abordagem de Aproximação por Média Amostral (SAA) substitui a esperança matemática por uma média amostral, levando ao problema SAA (5.2): $\min_{x \in X} \{\hat{f}_N(x) := \frac{1}{N} \sum_{j=1}^N F(x, \xi^j)\}$ [^2]. Denotamos por $v^*$ e $S$ o valor ótimo e o conjunto de soluções ótimas do problema verdadeiro (5.1), respectivamente, e por $\hat{v}_N$ e $\hat{S}_N$ o valor ótimo e o conjunto de soluções ótimas do problema SAA (5.2) para uma amostra de tamanho $N$ [^3].

Este capítulo foca nas propriedades estatísticas dos estimadores SAA $\hat{v}_N$ e $\hat{S}_N$, especificamente na sua **consistência**. A Lei dos Grandes Números (LLN) sugere que, sob condições de regularidade, a função objetivo SAA $\hat{f}_N(x)$ converge pontualmente para a função objetivo verdadeira $f(x)$ com probabilidade 1 (w.p. 1) quando $N \to \infty$ [^4]. Isso motiva a expectativa de que os estimadores SAA convirjam para seus correspondentes verdadeiros. Formalmente, diz-se que um estimador $\hat{\theta}_N$ de um parâmetro $\theta$ é **consistente** se $\hat{\theta}_N$ converge w.p. 1 para $\theta$ quando $N \to \infty$ [^5]. Investigaremos as condições sob as quais $\hat{v}_N$ e $\hat{S}_N$ são estimadores consistentes de $v^*$ e $S$.

### Consistência do Valor Ótimo ($\hat{v}_N$)

A primeira propriedade de convergência a ser considerada é a do valor ótimo $\hat{v}_N$. Para qualquer $x \in X$ fixo, temos que $\hat{v}_N = \inf_{y \in X} \hat{f}_N(y) \le \hat{f}_N(x)$. Se a LLN pontual se aplica, ou seja, $\hat{f}_N(x) \to f(x)$ w.p. 1 para cada $x \in X$, então tomando o limite superior em ambos os lados da desigualdade e minimizando sobre $x \in X$, obtemos $\limsup_{N \to \infty} \hat{v}_N \le \inf_{x \in X} f(x) = v^*$ w.p. 1 [^6]. Esta desigualdade (5.6) indica que, assintoticamente, o valor ótimo SAA não superestima o valor ótimo verdadeiro.

> **Equação (5.6):**
> $$ \limsup_{N\to\infty} \hat{v}_N \le v^* \quad \text{w.p. 1} $$
> [^6]

No entanto, para garantir a convergência completa, $\hat{v}_N \to v^*$ w.p. 1, é necessária uma condição mais forte do que a convergência pontual de $\hat{f}_N(x)$. A condição chave é a **convergência uniforme** de $\hat{f}_N(x)$ para $f(x)$ sobre o conjunto $X$.

> **Proposição 5.2:** Suponha que $\hat{f}_N(x)$ converge para $f(x)$ w.p. 1, quando $N \to \infty$, uniformemente em $X$. Então $\hat{v}_N$ converge para $v^*$ w.p. 1 quando $N \to \infty$.
> [^7]

*Prova.* A convergência uniforme w.p. 1 de $\hat{f}_N(x) = \hat{f}_N(x, \omega)$ para $f(x)$ significa que para qualquer $\epsilon > 0$ e quase todo $\omega \in \Omega$, existe $N^* = N^*(\epsilon, \omega)$ tal que a seguinte desigualdade vale para todo $N \ge N^*$ [^8]:
$$ \sup_{x \in X} |\hat{f}_N(x, \omega) - f(x)| \le \epsilon $$
Isso implica que $\hat{f}_N(x, \omega) \le f(x) + \epsilon$ e $f(x) \le \hat{f}_N(x, \omega) + \epsilon$ para todo $x \in X$. Minimizando ambos os lados sobre $x \in X$, obtemos $\hat{v}_N(\omega) \le v^* + \epsilon$ e $v^* \le \hat{v}_N(\omega) + \epsilon$. Juntas, essas desigualdades implicam $|\hat{v}_N(\omega) - v^*| \le \epsilon$ para todo $N \ge N^*$, o que completa a prova [^8]. $\blacksquare$

### Consistência das Soluções Ótimas ($\hat{S}_N$)

Para estabelecer a consistência dos estimadores SAA das *soluções* ótimas, $\hat{S}_N$, são necessárias condições ligeiramente mais fortes do que as usadas para a consistência do valor ótimo [^9]. A convergência do conjunto $\hat{S}_N$ para o conjunto $S$ é tipicamente medida pela **desviação** de $\hat{S}_N$ de $S$, denotada por $D(\hat{S}_N, S) := \sup_{y \in \hat{S}_N} \text{dist}(y, S)$, onde $\text{dist}(y, S) := \inf_{x \in S} ||y - x||$ [^9].

> **Teorema 5.3:** Suponha que existe um conjunto compacto $C \subset \mathbb{R}^n$ tal que:
> (i) O conjunto $S$ de soluções ótimas do problema verdadeiro (5.1) é não vazio e está contido em $C$ ($S \subset C$).
> (ii) A função $f(x)$ é finita e contínua em $C$.
> (iii) $\hat{f}_N(x)$ converge para $f(x)$ w.p. 1, quando $N \to \infty$, uniformemente em $x \in C$.
> (iv) w.p. 1 para $N$ suficientemente grande, o conjunto $\hat{S}_N$ é não vazio e $\hat{S}_N \subset C$.
> Então $\hat{v}_N \to v^*$ e $D(\hat{S}_N, S) \to 0$ w.p. 1 quando $N \to \infty$.
> [^9]

*Prova (Esboço).* As suposições (i) e (iv) permitem restringir os problemas verdadeiro e SAA ao conjunto compacto $X \cap C$. A convergência $\hat{v}_N \to v^*$ w.p. 1 segue da Proposição 5.2 [^10]. Para mostrar $D(\hat{S}_N(\omega), S) \to 0$ para quase todo $\omega$, argumentamos por contradição. Suponha que $D(\hat{S}_N, S) \not\to 0$. Como $X \cap C$ é compacto, podemos extrair uma subsequência e assumir que existe $\hat{x}_N \in \hat{S}_N$ tal que $\text{dist}(\hat{x}_N, S) \ge \epsilon > 0$ e $\hat{x}_N \to x^* \in X \cap C$. Segue que $x^* \notin S$, logo $f(x^*) > v^*$. Por outro lado, $\hat{v}_N = \hat{f}_N(\hat{x}_N)$. Usando a desigualdade triangular $|\hat{f}_N(\hat{x}_N) - f(x^*)| \le |\hat{f}_N(\hat{x}_N) - f(\hat{x}_N)| + |f(\hat{x}_N) - f(x^*)|$, o primeiro termo tende a zero pela convergência uniforme (iii) e o segundo pela continuidade de $f(x)$ (ii). Portanto, $\hat{v}_N \to f(x^*)$. Como já sabemos que $\hat{v}_N \to v^*$, isso leva a $v^* = f(x^*) > v^*$, uma contradição [^10]. $\blacksquare$

A condição $D(\hat{S}_N, S) \to 0$ w.p. 1 significa que, para qualquer seleção mensurável $\hat{x}_N \in \hat{S}_N$ de uma solução ótima do problema SAA, a distância de $\hat{x}_N$ ao conjunto $S$, $\text{dist}(\hat{x}_N, S)$, converge para 0 w.p. 1 [^11]. Se, adicionalmente, $S = \{\bar{x}\}$ for um singleton (solução ótima única), então $D(\hat{S}_N, S) \to 0$ implica que qualquer sequência de soluções ótimas $\hat{x}_N \in \hat{S}_N$ converge para $\bar{x}$ w.p. 1 [^11].

A suposição (iv) no Teorema 5.3, que garante que as soluções SAA permanecem dentro de um conjunto compacto $C$, é crucial. Ela é satisfeita, em particular, se o conjunto viável $X$ for fechado, as funções $\hat{f}_N(x)$ forem lower semicontinuous (l.s.c.), e para algum $\alpha > v^*$, os conjuntos de nível $\{x \in X : \hat{f}_N(x) \le \alpha\}$ forem uniformemente limitados w.p. 1. Esta última é frequentemente referida como a condição de **inf-compactness** [^12]. Condições que asseguram a convergência uniforme de $\hat{f}_N(x)$ para $f(x)$ (suposição (iii)) são dadas nos Teoremas 7.48 e 7.50 [^12].

### Consistência no Caso Convexo

Se o problema de otimização for convexo, é possível relaxar algumas das condições de regularidade exigidas nos teoremas anteriores, especialmente a necessidade de convergência uniforme sobre todo o domínio [^13]. Para isso, é útil considerar as funções estendidas $\tilde{F}(x, \xi) := F(x, \xi) + I_X(x)$, $\tilde{f}(x) := f(x) + I_X(x)$ e $\tilde{f}_N(x) := \hat{f}_N(x) + I_X(x)$, onde $I_X(x)$ é a função indicadora (0 se $x \in X$, $+\infty$ caso contrário) [^14]. A operação de penalização preserva a convexidade se $X$ for convexo [^14].

> **Teorema 5.4:** Suponha que:
> (i) A função integranda $F(x, \xi)$ é random lower semicontinuous (l.s.c.).
> (ii) Para quase todo $\xi \in \Xi$, a função $F(\cdot, \xi)$ é convexa.
> (iii) O conjunto $X$ é fechado e convexo.
> (iv) A função esperança $f(x)$ é l.s.c. e existe um ponto $\bar{x} \in X$ tal que $f(x) < +\infty$ para todo $x$ numa vizinhança de $\bar{x}$.
> (v) O conjunto $S$ de soluções ótimas do problema verdadeiro é não vazio e limitado.
> (vi) A LLN pontual vale para $\tilde{F}(x, \xi)$.
> Então $\hat{v}_N \to v^*$ e $D(\hat{S}_N, S) \to 0$ w.p. 1 quando $N \to \infty$.
> [^13]

A prova deste teorema utiliza conceitos de análise convexa, como a **epi-convergência**. Sob as hipóteses (i)-(iv) e (vi), pode-se mostrar que $\tilde{f}_N$ epi-converge para $\tilde{f}$ w.p. 1 (Teorema 7.49) [^15]. A epi-convergência, juntamente com a suposição de que $S$ é limitado (v), é suficiente para garantir a convergência dos valores ótimos e das soluções ótimas [^15]. Notavelmente, este teorema permite que $f(x)$ assuma o valor $+\infty$ para alguns $x \in X$, o que pode ocorrer, por exemplo, em programação estocástica de dois estágios se o problema de segundo estágio for inviável para alguns $x$ com probabilidade positiva [^16]. A otimalidade local implica otimalidade global no caso convexo, o que ajuda a contornar essa dificuldade [^16].

### Consistência com Conjuntos Viáveis Aleatórios ($X_N$)

Em algumas situações, o próprio conjunto viável $X$ pode não ser conhecido exatamente e é aproximado por um conjunto $X_N$ dependente da amostra [^17]. O problema SAA toma então a forma:
$$ \min_{x \in X_N} \hat{f}_N(x) $$
[^17]
Denotamos o valor ótimo e o conjunto de soluções ótimas deste problema por $\hat{v}_N$ e $\hat{S}_N$, respectivamente [^17]. A consistência neste caso requer condições adicionais sobre a convergência do conjunto $X_N$ para $X$.

> **Teorema 5.5:** Suponha que, além das hipóteses do Teorema 5.3 (ou adaptações apropriadas para o caso convexo baseado no Teorema 5.4), as seguintes condições valem:
> (a) (Convergência externa) Se $x_N \in X_N$ e $x_N \to x$ w.p. 1, então $x \in X$.
> (b) (Convergência interna) Para algum ponto $\bar{x} \in S$, existe uma sequência $x_N \in X_N$ tal que $x_N \to \bar{x}$ w.p. 1.
> Então $\hat{v}_N \to v^*$ e $D(\hat{S}_N, S) \to 0$ w.p. 1 quando $N \to \infty$.
> [^18]

*Prova (Esboço).* Considere $\hat{x}_N \in \hat{S}_N$. Por argumentos de compacidade (assumindo as soluções ótimas SAA contidas num compacto C, como em Teorema 5.3), podemos assumir $\hat{x}_N \to x^*$ w.p. 1. Como $\hat{x}_N \in X_N$, a condição (a) implica $x^* \in X$ [^19]. A convergência uniforme de $\hat{f}_N$ (ou epi-convergência) e a continuidade de $f$ implicam $\hat{v}_N = \hat{f}_N(\hat{x}_N) \to f(x^*)$ [^19]. Por outro lado, pela condição (b), existe $x_N \in X_N$ com $x_N \to \bar{x} \in S$. Então $\hat{v}_N \le \hat{f}_N(x_N) \to f(\bar{x}) = v^*$ [^19]. Juntando os limites, $f(x^*) \le v^*$. Como $x^* \in X$, devemos ter $f(x^*) \ge v^*$, logo $f(x^*) = v^*$ e $x^* \in S$. A convergência $\hat{v}_N \to v^*$ e $D(\hat{S}_N, S) \to 0$ seguem [^19]. $\blacksquare$

Um exemplo importante onde $X_N$ surge é quando o conjunto $X$ é definido por restrições de valor esperado (5.11)-(5.12): $X := \{x \in X_0 : g_i(x) \le 0, i = 1, ..., p\}$, com $g_i(x) := E[G_i(x, \xi)]$ [^20]. O conjunto SAA correspondente $X_N$ é definido substituindo $g_i(x)$ por suas aproximações SAA $\hat{g}_{iN}(x) := \frac{1}{N} \sum_{j=1}^N G_i(x, \xi^j)$ (5.13) [^20]. A condição (a) do Teorema 5.5 geralmente vale se $\hat{g}_{iN}$ convergir uniformemente para $g_i$ (que deve ser contínua) numa vizinhança de $x$ [^20]. A condição (b), no entanto, é mais delicada e tipicamente requer que alguma **qualificação de restrição** (constraint qualification - CQ) seja satisfeita para o problema verdadeiro no ponto $\bar{x} \in S$ [^21]. Para problemas convexos, a condição de **Slater** (existência de um ponto $x^*$ tal que $g_i(x^*) < 0$ para todas as restrições de desigualdade ativas) é uma CQ suficiente [^22].

Outro exemplo são as **restrições probabilísticas** (chance constraints) da forma $p(x) = \text{Pr}\{C(x, \xi) > 0\} \le \alpha$ (5.14) [^23]. Elas podem ser escritas como $E[1_{(0, \infty)}(C(x, \xi))] \le \alpha$ (usando (5.15)-(5.16)) e aproximadas via SAA como $\hat{p}_N(x) = \frac{1}{N} \sum_{j=1}^N 1_{(0, \infty)}(C(x, \xi^j)) \le \alpha$ (5.17) [^23]. A função indicadora $1_{(0, \infty)}(t)$ é descontínua em $t=0$, o que introduz dificuldades técnicas. No entanto, se a probabilidade do evento $C(x, \xi) = 0$ for zero, a função esperança $p(x)$ é contínua, e a convergência uniforme pode ser estabelecida (e.g., via Teorema 7.48) [^23]. A verificação da condição (b) pode requerer métodos ad hoc [^23].

### Conclusão

A consistência é uma propriedade fundamental dos estimadores SAA $\hat{v}_N$ e $\hat{S}_N$, garantindo que, com amostras suficientemente grandes, a solução do problema SAA se aproxima da solução do problema verdadeiro. Demonstramos que a consistência do valor ótimo $\hat{v}_N$ está intimamente ligada à convergência uniforme de $\hat{f}_N$ para $f$. A consistência das soluções ótimas $\hat{S}_N$ requer condições adicionais, como a permanência das soluções SAA em um conjunto compacto (inf-compactness) e, no caso de conjuntos viáveis aleatórios $X_N$, condições sobre a convergência de $X_N$ para $X$ e qualificações de restrição. Para problemas convexos, a teoria da epi-convergência permite relaxar algumas dessas condições. Embora a consistência assegure a convergência assintótica, ela não informa sobre a taxa de convergência ou a distribuição dos erros para um tamanho de amostra $N$ finito, tópicos que são explorados em seções subsequentes (e.g., 5.1.2 Asymptotics of the SAA Optimal Value).

### Referências

[^1]: Capítulo 5, p. 155, Eq. (5.1)
[^2]: Capítulo 5, p. 155, Eq. (5.2)
[^3]: Capítulo 5, p. 156, parágrafo 5
[^4]: Capítulo 5, p. 156, parágrafo 4
[^5]: Capítulo 5, p. 157, Seção 5.1.1, parágrafo 1
[^6]: Capítulo 5, p. 157, Eq. (5.6) e texto anterior
[^7]: Capítulo 5, p. 157, Proposição 5.2
[^8]: Capítulo 5, p. 158, Prova da Proposição 5.2
[^9]: Capítulo 5, p. 158, parágrafo 2 e Teorema 5.3
[^10]: Capítulo 5, p. 158, Prova do Teorema 5.3
[^11]: Capítulo 5, p. 158, último parágrafo
[^12]: Capítulo 5, p. 158, parágrafo após Prova do Teorema 5.3
[^13]: Capítulo 5, p. 159, Teorema 5.4
[^14]: Capítulo 5, p. 159, Eq. (5.9) e texto anterior
[^15]: Capítulo 5, p. 159, Prova do Teorema 5.4
[^16]: Capítulo 5, p. 160, parágrafo 2
[^17]: Capítulo 5, p. 160, Eq. (5.10) e texto anterior
[^18]: Capítulo 5, p. 160, Teorema 5.5
[^19]: Capítulo 5, p. 160, Prova do Teorema 5.5
[^20]: Capítulo 5, p. 161, Eq. (5.11)-(5.13) e texto seguinte
[^21]: Capítulo 5, p. 161, último parágrafo
[^22]: Capítulo 5, p. 162, parágrafo 1
[^23]: Capítulo 5, p. 162, Eq. (5.14)-(5.17) e texto seguinte

<!-- END -->