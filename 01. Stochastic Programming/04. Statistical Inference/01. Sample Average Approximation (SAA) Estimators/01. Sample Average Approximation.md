```portuguese
## O Método Sample Average Approximation (SAA) para Programação Estocástica

### Introdução

A programação estocástica lida com problemas de otimização onde alguns parâmetros são incertos, representados por variáveis aleatórias. Um problema central nesta área é a minimização do valor esperado de uma função objetivo que depende tanto das variáveis de decisão quanto das variáveis aleatórias, sujeito a um conjunto de restrições. Formalmente, consideramos o seguinte **problema estocástico** [^1]:
$$ \text{Min}_{x \in X} \{f(x) := E[F(x, \xi)]\} $$
Aqui, $x$ é o **vetor de decisão** pertencente a um **conjunto viável** $X$, que é um subconjunto não vazio e fechado de $\mathbb{R}^n$ [^1], [^2]. O vetor $\xi$ é um **vetor aleatório** que modela a incerteza, com sua distribuição de probabilidade $P$ suportada em um conjunto $\Xi \subset \mathbb{R}^d$ [^2]. A função $F: X \times \Xi \to \mathbb{R}$ representa o desempenho do sistema para uma decisão $x$ e uma realização $\xi$ da incerteza [^2]. A função $f(x)$ é o valor esperado de $F(x, \xi)$ [^1]. Assumimos que a função esperada $f(x)$ está bem definida e possui valor finito para todo $x \in X$, o que implica que $F(x, \xi)$ é finito para quase todo $\xi \in \Xi$ dado $x \in X$ [^3].

A principal dificuldade na resolução direta do problema (5.1) reside no cálculo ou otimização do **valor esperado** $E[F(x, \xi)]$, que geralmente envolve uma integral multidimensional sobre a distribuição de $\xi$. O método **Sample Average Approximation (SAA)** surge como uma abordagem poderosa e amplamente utilizada para contornar essa dificuldade. A ideia fundamental é substituir o valor esperado por uma **média amostral**, utilizando um conjunto de realizações (amostras) do vetor aleatório $\xi$ [^6], [^7].

### Conceitos Fundamentais

**Definição do Problema SAA**

Suponha que tenhamos acesso a uma amostra de $N$ realizações do vetor aleatório $\xi$, denotadas por $\xi^1, ..., \xi^N$ [^4]. Esta amostra pode ser constituída por dados históricos observados ou pode ser gerada computacionalmente através de técnicas de amostragem de Monte Carlo [^5]. Para qualquer vetor de decisão $x \in X$, podemos estimar o valor esperado $f(x)$ calculando a média dos valores $F(x, \xi^j)$ sobre a amostra [^6]. Isso leva à formulação do problema **Sample Average Approximation (SAA)** [^7]:
$$ \text{Min}_{x \in X} \{\hat{f}_N(x) := \frac{1}{N} \sum_{j=1}^N F(x, \xi^j)\} $$
O problema (5.2) é uma aproximação do problema original (5.1), onde a função objetivo esperada $f(x)$ é substituída pela função de média amostral $\hat{f}_N(x)$.

**Interpretação Empírica**

A função de média amostral $\hat{f}_N(x)$ pode ser interpretada como o valor esperado da função $F(x, \hat{\xi})$ em relação à **medida empírica** $P_N$ associada à amostra $\xi^1, ..., \xi^N$ [^8].

> A medida empírica $P_N$ é definida como $P_N := N^{-1} \sum_{j=1}^N \Delta(\xi^j)$, onde $\Delta(\xi^j)$ denota uma medida de massa unitária concentrada no ponto $\xi^j$ [^8]. Assim, podemos escrever:
> $$ \hat{f}_N(x) = E_{P_N}[F(x, \hat{\xi})] $$ (5.3) [^8]

Esta interpretação conecta o método SAA à teoria de medidas empíricas e fornece uma base teórica para analisar suas propriedades.

**Natureza do Problema SAA**

É crucial entender a natureza do problema SAA (5.2). A amostra $\xi^1, ..., \xi^N$ pode ser vista de duas maneiras: como uma sequência de vetores aleatórios ou como uma realização particular dessa sequência [^10]. O problema SAA em si é uma função da amostra considerada e, nesse sentido, é aleatório [^10]. No entanto, uma vez que uma *realização específica* da amostra é fixada (seja por observação histórica ou por geração computacional), o problema SAA (5.2) torna-se um problema de otimização determinístico (se $F$ e $X$ forem determinísticos dados $\xi^j$).

> Uma perspectiva alternativa, especialmente útil no contexto da programação estocástica, é considerar o problema SAA (para uma dada amostra) como um problema de programação estocástica com um número finito de **cenários** $\xi^1, ..., \xi^N$, onde cada cenário $\xi^j$ ocorre com probabilidade $1/N$ [^9], [^11].

Esta visão é particularmente relevante porque muitas técnicas de solução para programação estocástica são projetadas para problemas com um número finito de cenários.

**Propriedades da Amostra e Justificativa Assintótica**

Normalmente, assume-se que cada vetor aleatório $\xi^j$ na amostra possui a mesma distribuição marginal $P$ que o vetor de dados original $\xi$ [^12]. Se, adicionalmente, as realizações $\xi^j$ forem independentes entre si, dizemos que a amostra é **independentemente e identicamente distribuída (iid)** [^12].

A validade do método SAA como uma aproximação para o problema original (5.1) é fundamentada pela **Lei dos Grandes Números (LLN)**. Sob condições de regularidade apropriadas, a LLN garante que, para um $x$ fixo, a média amostral $\hat{f}_N(x)$ converge pontualmente para o valor esperado $f(x)$ com probabilidade 1 quando o tamanho da amostra $N$ tende ao infinito [^13]. Isso é particularmente verdadeiro se a amostra for iid [^13]. Além disso, a função $\hat{f}_N(x)$ é um **estimador não viesado** (unbiased estimator) de $f(x)$, ou seja, $E[\hat{f}_N(x)] = f(x)$ [^14].

**Objetivo da Análise**

Dada a convergência de $\hat{f}_N(x)$ para $f(x)$, é natural esperar que o **valor ótimo** $\hat{v}_N$ e o **conjunto de soluções ótimas** $\hat{S}_N$ do problema SAA (5.2) convirjam para seus correspondentes $v^*$ e $S$ do problema verdadeiro (5.1) à medida que $N \to \infty$ [^15], [^16]. A análise das propriedades estatísticas desses estimadores SAA ($\hat{v}_N$ e $\hat{S}_N$), como consistência e comportamento assintótico, é um tema central no estudo do método SAA e será abordada em seções subsequentes deste capítulo.

### Conclusão

O método Sample Average Approximation (SAA) oferece uma abordagem computacionalmente tratável para problemas de programação estocástica, substituindo o valor esperado na função objetivo por uma média amostral baseada em realizações do vetor de incerteza. Para uma amostra fixa, o problema SAA pode ser visto como um problema determinístico ou como um problema estocástico com um número finito de cenários equiprováveis. A Lei dos Grandes Números fornece a justificativa teórica para essa aproximação, assegurando que a função objetivo SAA converge para a função objetivo esperada verdadeira à medida que o tamanho da amostra aumenta. A análise subsequente se concentrará nas propriedades estatísticas dos estimadores de valor ótimo e soluções ótimas obtidos através do SAA, fundamentais para compreender a qualidade e a confiabilidade desta aproximação.

### Referências

[^1]: Consider the following stochastic programming problem: Min $f(x) := E[F(x, \xi)]$ over $x \in X$. (Eq. 5.1) [Page 155]
[^2]: Here $X$ is a nonempty closed subset of $\mathbb{R}^n$, $\xi$ is a random vector whose probability distribution $P$ is supported on a set $\Xi \subset \mathbb{R}^d$, and $F : X \times \Xi \to \mathbb{R}$. [Page 155]
[^3]: Unless stated otherwise, we assume in this chapter that the expectation function $f(x)$ is well defined and finite valued for all $x \in X$. This implies, of course, that for every $x \in X$ the value $F(x, \xi)$ is finite for a.e. $\xi \in \Xi$. [Page 155]
[^4]: Suppose that we have a sample $\xi^1, ..., \xi^N$ of $N$ realizations of the random vector $\xi$. [Page 155]
[^5]: This random sample can be viewed as historical data of $N$ observations of $\xi$, or it can be generated in the computer by Monte Carlo sampling techniques. [Page 155]
[^6]: For any $x \in X$ we can estimate the expected value $f(x)$ by averaging values $F(x, \xi^j)$, $j = 1, ..., N$. [Page 155]
[^7]: This leads to the so-called sample average approximation (SAA) Min $\hat{f}_N(x) := \frac{1}{N} \sum_{j=1}^N F(x, \xi^j)$ over $x \in X$. (Eq. 5.2) [Page 155]
[^8]: Let us observe that we can write the sample average function as the expectation $\hat{f}_N(x) = E_{P_N}[F(x, \hat{\xi})]$ taken with respect to the empirical distribution (measure) $P_N := N^{-1} \sum_{j=1}^N \Delta(\xi^j)$. (Eq. 5.3) [Page 156]
[^9]: Therefore, for a given sample, the SAA problem (5.2) can be considered as a stochastic programming problem with respective scenarios $\xi^1, ..., \xi^N$, each taken with probability $1/N$. [Page 156]
[^10]: As with data vector $\xi$, the sample $\xi^1, ..., \xi^N$ can be considered from two points of view: as a sequence of random vectors or as a particular realization of that sequence. Which of these two meanings will be used in a particular situation will be clear from the context. The SAA problem is a function of the considered sample and in that sense is random. [Page 156]
[^11]: For a particular realization of the random sample, the corresponding SAA problem is a stochastic programming problem with respective scenarios $\xi^1, ..., \xi^N$ each taken with probability $1/N$. [Page 156]
[^12]: We always assume that each random vector $\xi^j$ in the sample has the same (marginal) distribution $P$ as the data vector $\xi$. If, moreover, each $\xi^j$, $j=1,...,N$, is distributed independently of other sample vectors, we say that the sample is independently identically distributed (iid). [Page 156]
[^13]: By the Law of Large Numbers we have that, under some regularity conditions, $\hat{f}_N(x)$ converges pointwise w.p. 1 to $f(x)$ as $N \to \infty$. In particular, by the classical LLN this holds if the sample is iid. [Page 156]
[^14]: We also have that $E[\hat{f}_N(x)] = f(x)$, i.e., $\hat{f}_N(x)$ is an unbiased estimator of $f(x)$. [Page 156]
[^15]: Therefore, it is natural to expect that the optimal value and optimal solutions of the SAA problem (5.2) converge to their counterparts of the true problem (5.1) as $N \to \infty$. [Page 156]
[^16]: We denote by $v^*$ and $S$ the optimal value and the set of optimal solutions, respectively, of the true problem (5.1) and by $\hat{v}_N$ and $\hat{S}_N$ the optimal value and the set of optimal solutions, respectively, of the SAA problem (5.2). [Page 156]
<!-- END -->
```