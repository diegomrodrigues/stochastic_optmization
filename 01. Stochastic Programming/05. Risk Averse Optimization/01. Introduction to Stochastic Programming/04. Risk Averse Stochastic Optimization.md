## Risco Averso em Otimização Estocástica

### Introdução
Este capítulo explora a otimização estocástica com aversão ao risco, um tópico crucial quando as decisões precisam ser tomadas sob incerteza e as consequências de resultados ruins são particularmente indesejáveis. Como vimos anteriormente [^1], a otimização estocástica tradicional geralmente se concentra em otimizar o resultado *médio*. No entanto, essa abordagem pode ser inadequada quando a variabilidade dos resultados é significativa e o tomador de decisões tem aversão ao risco. Este capítulo se baseia nesses conceitos, introduzindo maneiras de incorporar preferências de risco no processo de otimização.

### Conceitos Fundamentais

Na otimização estocástica com aversão ao risco, comparamos resultados aleatórios considerando os valores esperados de suas transformações escalares. Formalmente, um resultado aleatório $Z_1$ é preferível a um resultado aleatório $Z_2$ se e somente se $E[u(Z_1)] < E[u(Z_2)]$ [^1], onde $u$ é uma função de transformação escalar que reflete as preferências do tomador de decisões. Essa função $u$ é crucial para incorporar a aversão ao risco no modelo de otimização.

A função $u(\cdot)$, referida como **função de disutilidade** [^2], é tipicamente assumida como não decrescente e convexa. A convexidade da função de disutilidade é um ponto chave, pois ela penaliza resultados ruins mais do que recompensa resultados bons. Isso está alinhado com o conceito de aversão ao risco, onde perdas potenciais têm maior peso do que ganhos potenciais.

> *Desde que u(·) é convexa, temos pela desigualdade de Jensen que $u(E[F(x, \omega)]) \le E[u(F(x, \omega))]$.* [^2]

Essa desigualdade implica que um resultado *certo* do valor esperado $E[F(x, \omega)]$ é pelo menos tão bom quanto o resultado *aleatório* $F(x, \omega)$. Em outras palavras, Jensen’s inequality demonstra que a aversão ao risco leva a uma preferência por soluções que reduzem a incerteza.

Em um problema de maximização, a função $u(\cdot)$ é considerada *côncava* (e ainda não decrescente) [^2]. Nesse caso, a desigualdade de Jensen se inverte, refletindo uma preferência por soluções que aumentam a incerteza.

**Dificuldades com a Abordagem de Utilidade Esperada**
Apesar de sua utilidade conceitual, a abordagem de utilidade esperada enfrenta desafios práticos [^2]:
- **Especificação da Função de Utilidade:** Elicitar a função de utilidade ou disutilidade apropriada é notoriamente difícil. Mesmo especialistas podem ter dificuldade em expressar suas preferências de risco de forma precisa.
- **Interpretabilidade:** Funções de utilidade escolhidas arbitrariamente podem levar a soluções que são difíceis de interpretar ou justificar na prática.

**Medidas de Risco como Alternativa Moderna**
Uma abordagem moderna para modelar a aversão ao risco em problemas de otimização envolve o uso de **medidas de risco** [^2]. Medidas de risco são funcionais que tomam como argumento a coleção inteira de realizações $Z(\omega) = F(x, \omega)$, $\omega \in \Omega$, e quantificam o risco associado a essa distribuição.

### Modelos de Média-Risco

A ideia central dos modelos de média-risco é caracterizar o resultado incerto $Z_x(\omega) = F(x, \omega)$ por duas características escalares: [^3]
- **Média $E[Z_x]$:** Descreve o resultado esperado.
- **Risco $D[Z_x]$:** Mede a incerteza ou dispersão do resultado.

Na abordagem de média-risco, procuramos soluções *eficientes*: aquelas que minimizam o risco para um dado nível de média, ou maximizam a média para um dado nível de risco. Isso permite que o problema seja formulado como um problema de otimização paramétrica, facilitando a análise de *trade-off* entre média e risco.

Para um coeficiente $c \ge 0$, formamos uma função objetivo composta [^3]:

$$\rho[Z] := E[Z] + cD[Z]$$

O coeficiente $c$ atua como o preço do risco. Assim, formulamos o problema:

$$\min_{x \in X} E[Z_x] + cD[Z_x]$$

Variando o valor de $c$, podemos gerar um conjunto amplo de soluções eficientes [^3].

**Deficiência da Variância como Medida de Risco**
Uma deficiência notável da variância como medida de risco é que ela trata excessos sobre a média da mesma forma que *shortfalls* [^3]. Em muitos problemas, estamos primariamente preocupados em evitar resultados *ruins* (abaixo de um certo limiar), e não em limitar a variabilidade para cima.

### Semidesvios

Semidesvios são uma classe importante de funcionais de risco que representam medidas de dispersão e focam em desvios em uma direção específica [^3]. O **semidesvio superior de ordem p** é definido como:

$$\sigma_p^+[Z] := \left( E\left[ (Z - E[Z])_+^p \right] \right)^{1/p}$$

onde $p \in [1, \infty)$ é um parâmetro fixo e $(x)_+ = \max(0, x)$ [^3].  É natural assumir que as variáveis aleatórias consideradas $Z: \Omega \rightarrow \mathbb{R}$ pertencem ao espaço $L_p(\Omega, \mathcal{F}, P)$, i.e., que elas têm momentos de ordem $p$ finitos. O modelo de média-risco correspondente tem a forma geral:

$$\min_{x \in X} E[Z_x] + c\sigma_p^+[Z_x]$$

O semidesvio superior é apropriado para problemas de minimização, onde $Z_x(\omega) = F(x, \omega)$ representa um custo. Ele penaliza o excesso de $Z_x$ sobre sua média.

Para problemas de maximização, onde $Z_x$ representa um ganho ou lucro, usamos o **semidesvio inferior**:

$$\sigma_p^-[Z] := \left( E\left[ (E[Z] - Z)_+^p \right] \right)^{1/p}$$

O modelo de média-risco resultante tem a forma:

$$\max_{x \in X} E[Z_x] - c\sigma_p^-[Z_x]$$

No caso especial de $p = 1$, os semidesvios de primeira ordem estão relacionados ao desvio absoluto médio:

$$\sigma_1(Z) := E|Z - E[Z]|$$

**Proposição 6.1** [^3]. A seguinte identidade vale:

$$\sigma_1^+[Z] = \sigma_1^-[Z] = \frac{1}{2}\sigma_1(Z), \forall Z \in L_1(\Omega, \mathcal{F}, P)$$

*Prova:* Seja $H(\cdot)$ a função de distribuição cumulativa (cdf) de $Z$ e $\mu := E[Z]$. Então,

$$\
\sigma_1^-[Z] = \int_{-\infty}^{\mu} (\mu - z) dH(z) = \int_{-\infty}^{\infty} (\mu - z) dH(z) - \int_{\mu}^{\infty} (\mu - z) dH(z) = \int_{\mu}^{\infty} (z - \mu) dH(z) = \sigma_1^+[Z]
$$
A primeira integral no lado direito é igual a 0 e, portanto, $\sigma_1^-[Z] = \sigma_1^+[Z]$. A identidade (6.10) segue agora da equação $\sigma_1[Z] = \sigma_1^-[Z] + \sigma_1^+[Z]$. $\blacksquare$

Isso implica que usar o desvio absoluto médio em vez do semidesvio em modelos de média-risco tem o mesmo efeito, apenas o parâmetro $c$ precisa ser reduzido pela metade.

### Desvios Médios Ponderados de Quantis

Seja $H_Z(z) = Pr(Z < z)$ a cdf da variável aleatória $Z$ e $\alpha \in (0, 1)$. O quantil $\alpha$ do lado esquerdo de $H_Z$ é definido como [^4]:

$$H_Z^{-1}(\alpha) := \inf\{t : H_Z(t) \ge \alpha\}$$

e o quantil $\alpha$ do lado direito como:

$$\sup\{t : H_Z(t) \le \alpha\}$$

Se $Z$ representa perdas, o quantil (do lado esquerdo) $H_Z^{-1}(1 - \alpha)$ também é chamado de *Value-at-Risk* (VaR) e denotado $V@R_{\alpha}(Z)$, i.e.,

$$V@R_{\alpha}(Z) = H_Z^{-1}(1 - \alpha) = \inf\{t : Pr(Z < t) \ge 1 - \alpha\} = \inf\{t : Pr(Z > t) \le \alpha\}$$

Seu significado é o seguinte: perdas maiores que $V@R_{\alpha}(Z)$ ocorrem com probabilidade que não excede $\alpha$.

O desvio médio ponderado de um quantil é definido como [^4]:

$$q_{\alpha}[Z] := E[\max\{(1 - \alpha)(H_Z^{-1}(\alpha) - Z), \alpha(Z - H_Z^{-1}(\alpha))\}]$$

O funcional $q_{\alpha}[Z]$ é bem definido e tem valor finito para todo $Z \in L_1(\Omega, \mathcal{F}, P)$. Pode ser facilmente mostrado que

$$q_{\alpha}[Z] = \min_t \{\phi(t) := E[\max\{(1 - \alpha)(t - Z), \alpha(Z - t)\}]\}$$

Na verdade, as derivadas do lado direito e do lado esquerdo da função $\phi(\cdot)$ são

$$\phi'_+(t) = (1 - \alpha)Pr[Z \le t] - \alpha Pr[Z > t]$$
$$\phi'_-(t) = (1 - \alpha)Pr[Z < t] - \alpha Pr[Z \ge t]$$

No $t$ ótimo, a derivada do lado direito é não negativa e a derivada do lado esquerdo é não positiva e, portanto,

$$Pr[Z < t] \le \alpha \le Pr[Z \le t]$$

Isso significa que todo quantil $\alpha$ é um minimizador em (6.15).

O funcional de risco $q_{\alpha}[\cdot]$ pode ser usado em modelos de média-risco, tanto no caso de minimização:

$$\min_{x \in X} E[Z_x] + c q_{1-\alpha}[Z_x]$$

e no caso de maximização:

$$\max_{x \in X} E[Z_x] - c q_{\alpha}[Z_x]$$

Usamos $1 - \alpha$ no problema de minimização e $\alpha$ no problema de maximização, porque em aplicações práticas estamos interessados nessas quantidades para $\alpha$ pequeno.

### Valor em Risco Médio

O modelo de desvio médio do quantil está intimamente relacionado ao conceito de *Valor em Risco Médio* [^5]. Suponha que $Z$ representa perdas e queremos satisfazer a restrição de chance:

$$V@R_{\alpha}[Z_x] \le 0$$

Lembre-se de que

$$V@R_{\alpha}[Z] = \inf\{t : Pr(Z < t) \ge 1 - \alpha\}$$

e, portanto, a restrição (6.18) é equivalente à restrição $Pr(Z_x < 0) \ge 1 - \alpha$. Vemos que $Pr(Z_x > 0) = E[\mathbb{1}_{(0, \infty)}(Z_x)]$, e portanto a restrição (6.18) também pode ser escrita como a restrição de valor esperado:

$$E[\mathbb{1}_{(0, \infty)}(Z_x)] \le \alpha$$

A fonte de dificuldades com restrições probabilísticas (de chance) é que a função de passo $\mathbb{1}_{(0, \infty)}(\cdot)$ não é convexa e, pior ainda, é descontínua em zero. Como resultado, as restrições de chance são frequentemente não convexas, mesmo que a função $x \rightarrow Z_x$ seja convexa quase certamente. Uma possibilidade é abordar esses problemas construindo uma aproximação convexa do valor esperado à esquerda de (6.19).

Seja $\psi: \mathbb{R} \rightarrow \mathbb{R}$ uma função não negativa, não decrescente e convexa tal que $\psi(z) \ge \mathbb{1}_{(0, \infty)}(z)$ para todo $z \in \mathbb{R}$. Observando que $\mathbb{1}_{(0, \infty)}(tz) = \mathbb{1}_{(0, \infty)}(z)$ para qualquer $t > 0$ e $z \in \mathbb{R}$, temos que $\psi(tz) \ge \mathbb{1}_{(0, \infty)}(z)$ e, portanto, a seguinte desigualdade vale:

$$\inf_{t>0} E[\psi(tZ)] \ge E[\mathbb{1}_{(0, \infty)}(Z)]$$

Consequentemente, a restrição

$$\inf_{t>0} E[\psi(tZ_x)] \le \alpha$$

é uma aproximação conservadora da restrição de chance (6.18) no sentido de que o conjunto viável definido por (6.20) está contido no conjunto viável definido por (6.18).

Claro, quanto menor a função $\psi(\cdot)$, melhor será essa aproximação. Deste ponto de vista, a melhor escolha de $\psi(\cdot)$ é tomar a função linear por partes $\psi(z) := [1 + z]_+$ para algum $\gamma > 0$. Como a restrição (6.20) é invariante em relação à mudança de escala de $\psi(\gamma z)$ para $\psi(z)$, temos que $\psi(z) := [1 + z]_+$ dá a melhor escolha de tal função. Para esta escolha de função $\psi(\cdot)$, temos que a restrição (6.20) é equivalente a

$$\inf_{t>0} \{tE[t^{-1} + Z]_+ - \alpha\} \le 0$$

ou equivalentemente

$$\inf_{t>0} \{a^{-1}E[Z + t^{-1}]_+ - t^{-1}\} \le 0$$

Agora, substituindo $t$ por $-t^{-1}$, obtemos a forma

$$\inf_{t<0} \{t + a^{-1}E[Z - t]_+\} \le 0$$

A quantidade

$$AV@R_{\alpha}(Z) := \inf_{t} \{t + \alpha^{-1}E[Z - t]_+\}$$

é chamado de *Valor em Risco Médio* de $Z$ (no nível $\alpha$). Note que $AV@R_{\alpha}(Z)$ é bem definido e tem valor finito para todo $Z \in L_1(\Omega, \mathcal{F}, P)$.

A função $\phi(t) := t + \alpha^{-1}E[Z - t]_+$ é convexa. Sua derivada em $t$ é igual a $1 + \alpha^{-1}[H_Z(t) - 1]$, desde que a cdf $H_Z(\cdot)$ seja contínua em $t$. Se $H_Z(\cdot)$ for descontínua em $t$, então as respectivas derivadas do lado direito e do lado esquerdo de $\phi(\cdot)$ são dadas pela mesma fórmula com $H_Z(t)$ entendida como os limites do lado direito e do lado esquerdo correspondentes. Portanto, o mínimo de $\phi(t)$, sobre $t \in \mathbb{R}$, é atingido no intervalo $[t^*, t^{**}]$, onde

$$t^* := \inf\{z: H_Z(z) \ge 1 - \alpha\} \text{ e } t^{**} := \sup\{z: H_Z(z) \le 1 - \alpha\}$$

são os respectivos quantis do lado esquerdo e do lado direito. Lembre-se de que o quantil do lado esquerdo $t^* = V@R_{\alpha}(Z)$.

Uma vez que o mínimo de $\phi(t)$ é atingido em $t^* = V@R_{\alpha}(Z)$, temos que $AV@R_{\alpha}(Z)$ é maior que $V@R_{\alpha}(Z)$ pela quantidade não negativa de $\alpha^{-1}E[Z - t^*]_+$. Portanto,

$$\inf_{t \in \mathbb{R}} \{t + \alpha^{-1}E[Z - t]_+\} \le 0 \text{ implica que } t^* \le 0$$

e, portanto, a restrição (6.21) é equivalente a $AV@R_{\alpha}(Z) \le 0$. Portanto, a restrição

$$AV@R_{\alpha}[Z_x] \le 0$$

é equivalente à restrição (6.21) e fornece uma aproximação conservadora da restrição de chance (6.18).

### Conclusão
Este capítulo forneceu uma visão geral da otimização estocástica com aversão ao risco, destacando a importância de incorporar as preferências de risco no processo de tomada de decisão. Exploramos a teoria da utilidade esperada, suas limitações e as vantagens de usar medidas de risco modernas, como modelos de média-risco e semidesvios. Finalmente, discutimos como as medidas de risco estão relacionadas a restrições de chance ambíguas e como o conceito de valor em risco médio pode ser usado para aproximar conservadoramente restrições de chance.

### Referências
[^1]: Página 253 do texto original.
[^2]: Página 254 do texto original.
[^3]: Página 255 do texto original.
[^4]: Página 256 do texto original.
[^5]: Página 257 do texto original.
<!-- END -->