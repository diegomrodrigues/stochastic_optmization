## Capítulo 2: Problemas de Dois Estágios
### Seção 2.1.2: Avaliação do Custo de Recurso Esperado para Distribuições Discretas

#### Introdução

Como estabelecido na Seção 2.1.1, problemas de programação linear estocástica de dois estágios são formulados como `Min c^T x + E[Q(x, ξ)]` sujeito a `Ax = b, x ≥ 0` [^1], onde `Q(x, ξ)` representa o valor ótimo do problema de segundo estágio, definido como `Min q^T y` sujeito a `Tx + Wy = h, y ≥ 0` [^2]. A função `Q(x, ξ)` é conhecida como a **função de custo de recurso**. A avaliação do termo de expectativa `E[Q(x, ξ)]`, denominado **custo de recurso esperado**, é central para a resolução do problema. Esta seção aprofunda a análise e formulação do custo de recurso esperado, `φ(x) := E[Q(x, ξ)]` [^4], especificamente para o caso em que o vetor aleatório `ξ := (q, h, T, W)` [^2] possui uma distribuição de probabilidade discreta com suporte finito.

#### Conceitos Fundamentais: O Equivalente Determinístico

Quando o vetor aleatório `ξ` possui um **suporte finito**, significa que `ξ` pode assumir apenas um número finito de realizações, `K`, denominadas **cenários** [^3]. Denotamos essas realizações por `ξ<0xE2><0x82><0x96> = (q<0xE2><0x82><0x96>, h<0xE2><0x82><0x96>, T<0xE2><0x82><0x96>, W<0xE2><0x82><0x96>)` para `k = 1, ..., K`, cada uma com uma probabilidade associada `p<0xE2><0x82><0x96>` (positiva) [^3]. Neste cenário, o operador de expectativa `E[·]` se simplifica para uma soma ponderada sobre todos os cenários possíveis. O custo de recurso esperado `E[Q(x, ξ)]` pode ser expresso explicitamente como:

$$
E[Q(x, ξ)] = \sum_{k=1}^{K} p_k Q(x, ξ_k)
$$ [^5]

onde `Q(x, ξ<0xE2><0x82><0x96>)` é o valor ótimo do problema de segundo estágio para o cenário `k`:

$$
Q(x, ξ_k) = \min_{y_k} \{ q_k^T y_k \mid T_k x + W_k y_k = h_k, y_k \ge 0 \}
$$

Para um vetor de decisão de primeiro estágio `x` fixo, o cálculo do custo de recurso esperado `E[Q(x, ξ)]` é equivalente a encontrar o valor ótimo do seguinte problema de programação linear:

$$
\min_{y_1, ..., y_K} \sum_{k=1}^{K} p_k q_k^T y_k \\
\text{s.t. } T_k x + W_k y_k = h_k, \quad k = 1, ..., K, \\
y_k \ge 0, \quad k = 1, ..., K.
$$ [^7]

É importante notar a estrutura deste problema: as variáveis de decisão são os vetores de segundo estágio `y₁, ..., y<0xE2><0x82><0x96>`, um para cada cenário, e as restrições acoplam cada `y<0xE2><0x82><0x96>` ao `x` fixo e aos dados do cenário `k`.

> **Tratamento de Inviabilidade:** Se, para um dado `x`, o problema de segundo estágio for inviável para pelo menos um cenário `k` (i.e., `Q(x, ξ<0xE2><0x82><0x96>) = +∞`), então, por convenção (`+∞ + (-∞) = +∞` [^8]), a soma ponderada `E[Q(x, ξ)]` será `+∞`. Consequentemente, o problema de otimização (2.14) [^7] torna-se inviável [^8].

A principal vantagem da representação discreta é que o problema estocástico original de dois estágios (2.1) [^1] pode ser reformulado como um único problema de programação linear determinístico de grande escala [^9]. Isso é feito substituindo o termo de custo de recurso esperado pela sua forma de soma ponderada e incluindo as variáveis e restrições de segundo estágio para todos os cenários explicitamente. O **problema equivalente determinístico (EDP)** resultante é:

$$
\min_{x, y_1, ..., y_K} c^T x + \sum_{k=1}^{K} p_k q_k^T y_k \\
\text{s.t. } Ax = b, \\
T_k x + W_k y_k = h_k, \quad k = 1, ..., K, \\
x \ge 0, \\
y_k \ge 0, \quad k = 1, ..., K.
$$ [^10]

Este EDP possui uma estrutura característica: as variáveis de primeiro estágio `x` são acopladas às restrições de primeiro estágio `Ax = b` e também a todas as restrições de segundo estágio `T<0xE2><0x82><0x96> x + W<0xE2><0x82><0x96> y<0xE2><0x82><0x96> = h<0xE2><0x82><0x96>`. As variáveis de segundo estágio `y<0xE2><0x82><0x96>` aparecem apenas nas restrições correspondentes ao seu próprio cenário `k`. A função objetivo minimiza o custo de primeiro estágio mais a média ponderada dos custos de segundo estágio sobre todos os cenários.

#### Propriedades da Função de Custo de Recurso Esperado `φ(x)`

As propriedades da função de custo de recurso esperado `φ(x)` para distribuições discretas derivam diretamente das propriedades da programação linear paramétrica [^11]. Como vimos na Proposição 2.1 [^18], para um dado `ξ`, a função `Q(·, ξ)` é convexa e, sob certas condições (conjunto dual não vazio e viabilidade para algum `x`), ela é **polyhedral** [^19].

> **Proposição 2.3 (Resumida):** Suponha que a distribuição de probabilidade de `ξ` tenha suporte finito `Ξ = {ξ₁, ..., ξ<0xE2><0x82><0x96>}` e que o custo de recurso esperado `φ(·)` tenha um valor finito em pelo menos um ponto `x ∈ ℝⁿ`. Então, a função `φ(·)` é **polyhedral** [^12].

A demonstração [^14] baseia-se no fato de que, como `φ(x)` é finito, todos os `Q(x, ξ<0xE2><0x82><0x96>)` devem ser finitos. Pela Proposição 2.2 [^20], cada função `Q(·, ξ<0xE2><0x82><0x96>)` é polyhedral. Uma combinação linear com pesos positivos (`p<0xE2><0x82><0x96> > 0`) de funções polyhedral também é polyhedral [^14]. Além disso, o domínio da função `φ` é a interseção dos domínios das funções de custo de recurso individuais: `dom φ = ∩<0xE2><0x82><0x96>=₁<0xE1><0xB5><0x83> dom Q(·, ξ<0xE2><0x82><0x96>)` [^14].

Para qualquer `x₀ ∈ dom φ`, o **subdiferencial** de `φ` em `x₀` é dado pela soma ponderada dos subdiferenciais das funções de custo de recurso individuais:

$$
\partial \phi(x_0) = \sum_{k=1}^{K} p_k \partial Q(x_0, \xi_k)
$$ [^13]

A fórmula (2.16) [^13] segue de (2.17) [^21] (que expressa a derivada direcional de `φ` como a soma ponderada das derivadas direcionais de `Q(·, ξ<0xE2><0x82><0x96>)`) por argumentos de dualidade [^14]. Como as funções `Q(·, ξ<0xE2><0x82><0x96>)` são polyhedral, não há necessidade de condições de regularidade adicionais (como as do teorema de Moreau-Rockafellar) para que (2.16) seja válida [^14].

Recordando a Proposição 2.2 [^20] e a fórmula (2.18) [^16], se `Q(x₀, ξ<0xE2><0x82><0x96>)` é finito, o subdiferencial `∂Q(x₀, ξ<0xE2><0x82><0x96>)` é caracterizado em termos das soluções ótimas do problema dual de segundo estágio correspondente:

$$
\partial Q(x_0, \xi_k) = -T_k^T \mathcal{D}(x_0, \xi_k)
$$ [^15][^16]

onde `D(x₀, ξ<0xE2><0x82><0x96>) := arg max_{π} {π^T(h<0xE2><0x82><0x96> - T<0xE2><0x82><0x96> x₀) | W<0xE2><0x82><0x96>^T π ≤ q<0xE2><0x82><0x96>}` é o conjunto das soluções ótimas do problema dual (2.3) [^22] para o cenário `k` [^15].

Segue-se que a função de custo esperado `φ` é diferenciável em `x₀` se e somente se, para cada cenário `ξ = ξ<0xE2><0x82><0x96>`, `k = 1, ..., K`, o conjunto `D(x₀, ξ<0xE2><0x82><0x96>)` for um singleton, ou seja, o problema dual de segundo estágio correspondente tiver uma solução ótima única [^17].

#### Conclusão

A análise de problemas de programação estocástica de dois estágios simplifica consideravelmente quando o vetor de dados aleatórios `ξ` possui um suporte finito. Neste caso, o custo de recurso esperado `E[Q(x, ξ)]` torna-se uma soma finita ponderada dos custos de recurso para cada cenário. Crucialmente, o problema estocástico original pode ser transformado em um **problema equivalente determinístico** de programação linear, embora de grande escala. Esta formulação permite a aplicação de algoritmos de otimização determinística padrão. Além disso, a função de custo de recurso esperado `φ(x)` herda a propriedade de ser **polyhedral**, e seu subdiferencial pode ser calculado pela soma ponderada dos subdiferenciais dos problemas de segundo estágio individuais, facilitando a derivação de condições de otimalidade, como explorado na Seção 2.1.4 [^23].

#### Referências

[^1]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 27, Equation (2.1).
[^2]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 27, Equation (2.2) and surrounding text.
[^3]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Section 2.1.2, First paragraph.
[^4]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Equation (2.12).
[^5]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Equation (2.13).
[^6]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Second paragraph.
[^7]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Equation (2.14).
[^8]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Third paragraph.
[^9]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Fourth paragraph.
[^10]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Equation (2.15).
[^11]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Fifth paragraph.
[^12]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Proposition 2.3.
[^13]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 30, Equation (2.16).
[^14]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 31, Proof of Proposition 2.3.
[^15]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 28, Proposition 2.2, Equation (2.7).
[^16]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 31, Equation (2.18).
[^17]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 31, Paragraph following Equation (2.18).
[^18]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 28, Proposition 2.1.
[^19]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 28, Proposition 2.1 and surrounding text.
[^20]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 28, Proposition 2.2.
[^21]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 31, Equation (2.17).
[^22]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 28, Equation (2.3).
[^23]: Ruszczyński, A., & Shapiro, A. (2009). *Stochastic Programming*. Handbooks in Operations Research and Management Science, Vol. 10, Chapter 2, Page 38, Section 2.1.4.

<!-- END -->