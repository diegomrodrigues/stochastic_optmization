## O Subdiferencial da Função de Custo de Recurso Esperado

### Introdução

Este capítulo aprofunda a análise das propriedades da função de custo de recurso esperado em problemas de otimização estocástica linear de dois estágios. Como introduzido na Seção 2.1.1 [^1], o problema geral busca minimizar uma função objetivo composta por um custo de primeiro estágio, $c^Tx$, e o valor esperado do custo ótimo do segundo estágio, $\\phi(x) = \\mathbb{E}[Q(x, \\xi)]$ [^1, ^6]. A função $Q(x, \\xi)$ representa o valor ótimo do problema de segundo estágio para uma decisão $x$ de primeiro estágio e uma realização $\\xi$ das variáveis aleatórias [^1]:
$$ Q(x, \\xi) = \\min_{y \\ge 0} \\{ q^T y \\mid Wy = h - Tx \\} $$
onde $\\xi := (q, h, T, W)$ encapsula os dados aleatórios do segundo estágio [^1]. A função $Q(\\cdot, \\xi)$ é convexa para qualquer $\\xi$ [^3]. A compreensão das propriedades diferenciais, ou mais geralmente, das propriedades do subdiferencial de $\\phi(x)$, é fundamental para o desenvolvimento e análise de algoritmos de otimização para resolver problemas de programação estocástica de dois estágios. Este capítulo foca na caracterização do **subdiferencial** $\\partial \\phi(x)$ da função de custo de recurso esperado, explorando sua conexão intrínseca com as soluções ótimas do problema dual do segundo estágio.

### Conceitos Fundamentais

#### O Subdiferencial de $Q(x, \\xi)$

Antes de analisar a função esperada $\\phi(x)$, é instrutivo caracterizar o subdiferencial da função de custo do segundo estágio $Q(x, \\xi)$ para uma realização fixa $\\xi$. O problema dual do segundo estágio (2.2) é dado por [^2]:
$$ \\max_{\\pi} \\{ \\pi^T (h - Tx) \\mid W^T \\pi \\le q \\} $$
Seja $\\Pi(q) := \\{ \\pi \\mid W^T \\pi \\le q \\}$ o conjunto de soluções factíveis para o problema dual [^2]. A **Proposition 2.2** [^4] estabelece uma relação fundamental entre o subdiferencial de $Q(\\cdot, \\xi)$ e as soluções ótimas do problema dual. Supondo que para um dado $x_0$ e $\\xi$, o valor $Q(x_0, \\xi)$ é finito, então $Q(\\cdot, \\xi)$ é subdiferenciável em $x_0$ e seu subdiferencial é dado por:

> $$ \\partial Q(x_0, \\xi) = -T^T D(x_0, \\xi) $$
> onde $D(x_0, \\xi) := \\arg \\max_{\\pi \\in \\Pi(q)} \\{ \\pi^T (h - Tx_0) \\}$ é o conjunto das soluções ótimas do problema dual (2.3) [^4].

Este resultado pode ser derivado observando que $Q(x, \\xi) = s_q(h - Tx)$, onde $s_q(\\cdot)$ é a função suporte do conjunto $\\Pi(q)$ [^2]. A função $s_q(\\cdot)$ é a conjugada da função indicadora $I_{\\Pi(q)}(\\cdot)$, e pelo teorema de Fenchel-Moreau, $\\partial s_q(x_0) = \\arg \\max_{\\pi \\in \\Pi(q)} \\{ \\pi^T x_0 \\}$ [^5]. A fórmula (2.7) segue então pela regra da cadeia para subdiferenciais [^5]. O conjunto $D(x_0, \\xi)$ é um poliedro convexo, fechado e não vazio quando $Q(x_0, \\xi)$ é finito [^2]. A função $Q(\\cdot, \\xi)$ é também poliédrica se o conjunto $\\Pi(q)$ for não vazio e o problema (2.2) for factível para pelo menos um $x$ [^3].

#### O Subdiferencial de $\\phi(x)$ no Caso Discreto

Consideremos agora o caso em que o vetor aleatório $\\xi$ possui uma distribuição de probabilidade com suporte finito, $\\Xi = \\{\\xi_1, \\dots, \\xi_K\\}$, com probabilidades $p_k > 0$ para $k=1, \\dots, K$ [^6]. Neste cenário, a função de custo de recurso esperado é uma soma ponderada:
$$ \\phi(x) = \\mathbb{E}[Q(x, \\xi)] = \\sum_{k=1}^K p_k Q(x, \\xi_k) $$
Como visto na **Proposition 2.3** [^7], se $\\phi(\\cdot)$ assume um valor finito em pelo menos um ponto $x \\in \\mathbb{R}^n$, então $\\phi(\\cdot)$ é uma função convexa e poliédrica, pois é uma combinação linear com pesos positivos de funções poliédricas $Q(\\cdot, \\xi_k)$ [^8]. A poliédricidade de $\\phi$ garante que o subdiferencial existe em todos os pontos do seu domínio. Aplicando a regra de soma para subdiferenciais (um caso particular do teorema de Moreau-Rockafellar, que não exige condições de regularidade adicionais aqui devido à poliédricidade das funções $Q_k(\\cdot) := Q(\\cdot, \\xi_k)$ [^8]), obtemos o subdiferencial de $\\phi$ em $x_0 \\in \\text{dom } \\phi$:

> $$ \\partial \\phi(x_0) = \\sum_{k=1}^K p_k \\partial Q(x_0, \\xi_k) $$ [^7]

Substituindo a expressão para $\\partial Q(x_0, \\xi_k)$ dada pela Proposition 2.2 (equação (2.18) [^8]), chegamos à caracterização explícita do subdiferencial da função de custo esperado no caso discreto:

> $$ \\partial \\phi(x_0) = - \\sum_{k=1}^K p_k T_k^T D(x_0, \\xi_k) $$ [^17]
> onde $D(x_0, \\xi_k)$ é o conjunto de soluções ótimas do k-ésimo problema dual do segundo estágio: $D(x_0, \\xi_k) = \\arg \\max \\{ \\pi^T (h_k - T_k x_0) \\mid W_k^T \\pi \\le q_k \\}$ [^17].

Esta fórmula (2.36) [^17] confirma a intuição fundamental: o subdiferencial $\\partial \\phi(x_0)$ é o negativo do conjunto das soluções ótimas duais ($\\pi_k \\in D(x_0, \\xi_k)$), transformadas pela transposta da matriz de tecnologia ($T_k^T$) e agregadas através da média ponderada pelas probabilidades dos cenários ($p_k$). Cada elemento $g \\in \\partial \\phi(x_0)$ é da forma $g = - \\sum_{k=1}^K p_k T_k^T \\pi_k$ para algum conjunto de soluções ótimas duais $\\pi_k \\in D(x_0, \\xi_k)$ para $k=1, \\dots, K$ [^18]. Esta informação é crucial para algoritmos de otimização, como métodos de subgradiente ou métodos de decomposição tipo Benders, que dependem do cálculo de (sub)gradientes de $\\phi$.

#### O Subdiferencial de $\\phi(x)$ no Caso Geral

Quando a distribuição de $\\xi$ é geral (não necessariamente discreta), a análise torna-se mais complexa, requerendo conceitos de análise convexa e teoria da medida [^9]. Primeiramente, é necessário garantir que a expectativa $\\phi(x) = \\mathbb{E}[Q(x, \\xi)]$ esteja bem definida [^10]. Condições suficientes envolvem a propriedade de **recurso fixo** (matriz $W$ determinística) e momentos finitos para os dados aleatórios, como estabelecido na **Proposition 2.6** e **Proposition 2.7** [^12, ^13]. Sob a hipótese de recurso fixo e condições de integrabilidade como $\\mathbb{E}[\\|q\\| \\|h\\|] < \\infty$ e $\\mathbb{E}[\\|q\\| \\|T\\|] < \\infty$ (condição (2.28) [^12]), a função $\\phi(x)$ é bem definida, convexa, semicontínua inferiormente e Lipschitz contínua em seu domínio [^13]. O domínio de $\\phi$ é um conjunto convexo e fechado dado por:
$$ \\text{dom } \\phi = \\{ x \\in \\mathbb{R}^n \\mid h - Tx \\in \\text{pos } W \\text{ w.p. 1} \\} $$ [^13]
onde 'w.p. 1' significa 'com probabilidade 1' [^13].

A **Proposition 2.8** [^15] generaliza a fórmula do subdiferencial para distribuições gerais, sob a suposição que $\\phi(\\cdot)$ é própria e seu domínio tem interior não vazio. Para $x_0 \\in \\text{dom } \\phi$:

> $$ \\partial \\phi(x_0) = - \\mathbb{E}[T^T D(x_0, \\xi)] + N_{\\text{dom } \\phi}(x_0) $$ [^15]
> onde $D(x, \\xi) = \\arg \\max_{\\pi \\in \\Pi(q)} \\{ \\pi^T (h - Tx) \\}$ [^15] e $N_{\\text{dom } \\phi}(x_0)$ é o cone normal ao domínio de $\\phi$ no ponto $x_0$.

A expressão $\\mathbb{E}[T^T D(x_0, \\xi)]$ representa o valor esperado do conjunto transformado das soluções ótimas duais. Este termo é a generalização natural da soma ponderada vista no caso discreto. O termo adicional $N_{\\text{dom } \\phi}(x_0)$ aparece porque, no caso geral, $x_0$ pode estar na fronteira do domínio de $\\phi$. Este cone normal é {0} se $x_0$ está no interior do domínio de $\\phi$ [^15]. A condição de **recurso relativamente completo** (i.e., $X \\subset \\text{dom } \\phi$, onde $X$ é o conjunto factível do primeiro estágio) [^10, ^20] ou a hipótese de $T$ ser determinística [^21, ^22] são casos especiais onde o termo do cone normal pode ser simplificado ou omitido nas condições de otimalidade [^20, ^21]. Por exemplo, se $T$ é determinístico e as hipóteses da Proposition 2.7 são satisfeitas, o cone normal é $N_{\\text{dom } \\phi}(x) = -T^T(\\Pi_0 \\cap L^\\perp)$ [^22], e pode ser mostrado que o termo $N_{\\text{dom } \\phi}(x_0)$ é absorvido na expressão esperada, resultando em $\\partial \\phi(x_0) = - T^T \\mathbb{E}[D(x_0, \\xi)]$ [^22].

#### Propriedades e Differentiabilidade

A função $\\phi(x)$ é diferenciável em $x_0$ se e somente se $x_0$ pertence ao interior do domínio de $\\phi$ e o conjunto de soluções ótimas duais $D(x_0, \\xi)$ é um singleton (conjunto unitário) com probabilidade 1 [^15]. Neste caso, o gradiente é único e coincide com o subdiferencial: $\\nabla \\phi(x_0) = - \\mathbb{E}[T^T \\pi(x_0, \\xi)]$, onde $\\pi(x_0, \\xi)$ é a única solução dual ótima [^15]. A **Proposition 2.9** [^16] fornece uma condição suficiente para a diferenciabilidade contínua de $\\phi$ no interior de seu domínio: se as hipóteses da Proposition 2.7 são satisfeitas e a distribuição condicional de $h$, dados $(T, q)$, é absolutamente contínua para quase todo $(T, q)$, então $\\phi$ é continuamente diferenciável em $\\text{int}(\\text{dom } \\phi)$ [^16]. Isso ocorre porque a continuidade da distribuição de $h$ garante que as faces do poliedro dual $\\Pi(q)$ raramente conterão $h-Tx$, levando a uma solução dual única w.p. 1 [^16].

#### Extensões

Os conceitos apresentados para problemas lineares de dois estágios podem ser estendidos. Para **problemas poliédricos de dois estágios** (Seção 2.2) [^23], onde $f_1(x)$ e $f_2(y, \\omega)$ são funções poliédricas, a estrutura se mantém. A função de custo do segundo estágio $Q(x, \\omega)$ ainda é poliédrica e seu subdiferencial é dado por $\\partial Q(x, \\omega) = -T(\\omega)^T D(x, \\omega)$, onde $D(x, \\omega)$ é o conjunto de soluções ótimas do problema dual apropriado (2.46) [^26]. A função esperada $\\phi(x) = \\mathbb{E}[Q(x, \\omega)]$ também é poliédrica no caso discreto, com $\\partial \\phi(x_0) = \\sum p_k \\partial Q(x_0, \\omega_k)$ [^27]. No caso geral com recurso fixo, $\\partial \\phi(x_0) = -\\mathbb{E}[T^T D(x_0, \\omega)] + N_{\\text{dom } \\phi}(x_0)$ [^29]. Para **problemas gerais convexos de dois estágios** (Seção 2.3) [^32], sob condições de convexidade e regularidade apropriadas, resultados análogos podem ser derivados usando a teoria de dualidade convexa. O subdiferencial da função valor $\\vartheta(\\chi, \\omega)$ do problema (2.71) é o conjunto de soluções ótimas duais $D(\\chi, \\omega)$ (Proposition 2.22) [^33], e o subdiferencial da função $F(x, \\omega)$ (valor ótimo do segundo estágio incluindo termos dependentes de x) é dado por $\\partial F(x, \\omega) = \\nabla c(x) + \\nabla T_\\omega(x)^T D(\\chi, \\omega)$ (assumindo diferenciabilidade de $c$ e $T_\\omega$) [^33]. O subdiferencial da função esperada $f(x) = \\mathbb{E}[F(x, \\omega)]$ é $\\partial f(\\bar{x}) = \\nabla c(\\bar{x}) + \\int_\\Omega \\nabla T_\\omega(\\bar{x})^T D(T(\\bar{x}, \\omega), \\omega) dP(\\omega) + N_{\\text{dom } f}(\\bar{x})$ (equação (2.77)) [^34].

### Conclusão

A caracterização do subdiferencial $\\partial \\phi(x)$ da função de custo de recurso esperado é um resultado central na programação estocástica de dois estágios. Demonstramos, com base no texto fornecido [^1]-[^34], que $\\partial \\phi(x)$ está intimamente ligado às soluções ótimas $\\pi(\\xi)$ do problema dual do segundo estágio. Especificamente, $\\partial \\phi(x)$ é dado pelo valor esperado (ou soma ponderada no caso discreto) do negativo dessas soluções duais transformadas por $-T^T$, possivelmente com um termo adicional do cone normal se $x$ estiver na fronteira do domínio.

> $$ \\partial \\phi(x) \\approx - \\mathbb{E}[T^T D(x, \\xi)] $$

Esta relação não é apenas teoricamente elegante, mas também de imensa importância prática. Ela fornece a base para uma variedade de algoritmos de otimização projetados para problemas estocásticos, incluindo métodos de subgradiente, métodos de agregação de cortes (como o algoritmo de Benders estocástico ou L-shaped method), e abordagens baseadas em decomposição dual. As condições de otimalidade para o problema de dois estágios, como as apresentadas nos Teoremas 2.10, 2.11, 2.12, 2.18, 2.19 e Proposição 2.24 [^18, ^20, ^21, ^30, ^31, ^34], invariavelmente envolvem o subdiferencial $\\partial \\phi(x)$, destacando seu papel fundamental na teoria e na prática da programação estocástica.

### Referências

[^1]: Page 27
[^2]: Page 28
[^3]: Page 28, Proposition 2.1
[^4]: Page 28, Proposition 2.2
[^5]: Page 29
[^6]: Page 30
[^7]: Page 30, Proposition 2.3
[^8]: Page 31
[^9]: Page 32, Section 2.1.3
[^10]: Page 33
[^11]: Page 34
[^12]: Page 35, Proposition 2.6
[^13]: Page 35, Proposition 2.7
[^14]: Page 36
[^15]: Page 37, Proposition 2.8
[^16]: Page 37, Proposition 2.9
[^17]: Page 38, Equation (2.36)
[^18]: Page 38, Theorem 2.10
[^19]: Page 39
[^20]: Page 40, Theorem 2.11
[^21]: Page 40, Theorem 2.12
[^22]: Page 41
[^23]: Page 42, Section 2.2
[^24]: Page 42, Section 2.2.1
[^25]: Page 43
[^26]: Page 44, Proposition 2.14
[^27]: Page 45, Proposition 2.15
[^28]: Page 45
[^29]: Page 46, Proposition 2.17
[^30]: Page 47, Theorem 2.18
[^31]: Page 47, Theorem 2.19
[^32]: Page 48, Section 2.3
[^33]: Page 51, Proposition 2.22, Corollary 2.23
[^34]: Page 52, Proposition 2.24
[^35]: Page 53
[^36]: Page 54
[^37]: Page 55
[^38]: Page 56
[^39]: Page 57
[^40]: Page 58
[^41]: Page 59

<!-- END -->