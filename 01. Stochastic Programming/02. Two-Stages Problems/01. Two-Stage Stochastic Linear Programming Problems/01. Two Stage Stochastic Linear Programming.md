## Capítulo 2: Problemas de Dois Estágios

### Seção 2.1.2: O Custo de Recurso Esperado para Distribuições Discretas

#### Introdução

Como estabelecido na Seção 2.1.1, problemas de programação linear estocástica de dois estágios envolvem uma decisão de primeiro estágio $x$ e uma decisão de segundo estágio $y$, ajustada após a observação da realização de dados incertos $\\xi$ [^1]. O objetivo fundamental é minimizar a soma do custo de primeiro estágio $c^T x$ e o valor esperado do custo ótimo do problema de segundo estágio, $E[Q(x, \\xi)]$ [^1], onde $Q(x, \\xi)$ representa o valor ótimo do problema de segundo estágio para uma dada decisão $x$ e realização $\\xi$ [^1]. Nesta seção, aprofundaremos a análise da função de custo de recurso esperado, $\\phi(x) := E[Q(x, \\xi)]$ [^10], especificamente para o caso em que o vetor aleatório $\\xi$ segue uma distribuição de probabilidade discreta com suporte finito. Este cenário é de grande importância prática e teórica, pois muitos problemas estocásticos são modelados ou aproximados usando um número finito de cenários possíveis.

#### Conceitos Fundamentais

**Definição e Formulação da Esperança**

Consideremos a função de valor esperado do custo de recurso:
$$\
\\phi(x) := E[Q(x, \\xi)]
$$\
[^10]
A expectativa $E[\\cdot]$ é tomada com respeito à distribuição de probabilidade do vetor aleatório $\\xi$ [^10]. Assumimos aqui que a distribuição de $\\xi$ possui **suporte finito** [^11]. Isso significa que $\\xi$ pode assumir apenas um número finito de realizações distintas, denominadas **cenários** [^11]. Seja $\\Xi = \\{\\xi_1, \\dots, \\xi_K\\}$ o conjunto finito de cenários possíveis para $\\xi$, onde cada cenário $\\xi_k = (q_k, h_k, T_k, W_k)$ ocorre com uma probabilidade (positiva) associada $p_k$, tal que $\\sum_{k=1}^K p_k = 1$ [^11]. Neste caso, a função de custo esperado $\\phi(x)$ pode ser expressa como a soma ponderada dos custos de recurso para cada cenário:
$$\
E[Q(x, \\xi)] = \\sum_{k=1}^K p_k Q(x, \\xi_k)
$$\
[^12]
onde $Q(x, \\xi_k)$ é o valor ótimo do problema de segundo estágio (2.2) [^1] correspondente ao cenário $k$:
$$\
Q(x, \\xi_k) = \\min_{y_k \\in \\mathbb{R}^m} \\{ q_k^T y_k \\mid T_k x + W_k y_k = h_k, y_k \\ge 0 \\}
$$\

É importante notar que, se para um dado $x$ e algum cenário $\\xi_k \\in \\Xi$, o problema de segundo estágio correspondente for infactível, então, por definição, $Q(x, \\xi_k) = +\\infty$ [^1]. Consequentemente, se $Q(x, \\xi_k) = +\\infty$ para pelo menos um $k$ com $p_k > 0$, a soma em (2.13) resultará em $+\\infty$, ou seja, $E[Q(x, \\xi)] = +\\infty$ [^13]. Assumimos aqui a convenção de que $+\\infty + (-\\infty) = +\\infty$ [^13], embora a situação onde $Q(x, \\xi_k) = -\\infty$ (problema de segundo estágio ilimitado) seja considerada patológica e deva ser evitada na modelagem [^1].

**Interpretação como um Problema de Otimização Agregado**

Para uma decisão de primeiro estágio $x$ *fixa*, o cálculo do valor esperado $E[Q(x, \\xi)]$ é equivalente a encontrar o valor ótimo do seguinte problema de programação linear:
$$\
\\begin{aligned}\n\\min_{y_1, \\dots, y_K} \\quad & \\sum_{k=1}^K p_k q_k^T y_k \\\\\n\\text{s.t.} \\quad & T_k x + W_k y_k = h_k, \\quad k = 1, \\dots, K \\\\\n& y_k \\ge 0, \\quad k = 1, \\dots, K\n\\end{aligned}\n$$\
[^13]
Este problema (2.14) agrega as decisões de segundo estágio $y_k$ para todos os cenários $k=1, \\dots, K$. Se, para algum $k$, o sistema $T_k x + W_k y_k = h_k, y_k \\ge 0$ não possuir solução (ou seja, o $k$-ésimo problema de segundo estágio é infactível), então o problema agregado (2.14) é infactível, e seu valor ótimo é, por definição, $+\\infty$, o que é consistente com a fórmula da soma ponderada (2.13) [^13].

**Formula Determinística Equivalente**

A formulação do problema de dois estágios completo (2.1) [^1], sob a hipótese de distribuição discreta, pode ser reescrita como um único problema de programação linear de grande escala, conhecido como **equivalente determinístico**:
$$\
\\begin{aligned}\n\\min_{x, y_1, \\dots, y_K} \\quad & c^T x + \\sum_{k=1}^K p_k q_k^T y_k \\\\\n\\text{s.t.} \\quad & T_k x + W_k y_k = h_k, \\quad k = 1, \\dots, K \\\\\n& Ax = b \\\\\n& x \\ge 0 \\\\\n& y_k \\ge 0, \\quad k = 1, \\dots, K\n\\end{aligned}\n$$\
[^14]
Este problema (2.15) otimiza simultaneamente as variáveis de primeiro estágio $x$ e as variáveis de segundo estágio $y_k$ para todos os cenários $k$. As restrições $T_k x + W_k y_k = h_k$ acoplam as decisões de primeiro e segundo estágio para cada cenário, enquanto as restrições $Ax = b, x \\ge 0$ aplicam-se diretamente à decisão de primeiro estágio $x$ [^14]. A estrutura deste problema é frequentemente explorada por algoritmos de decomposição especializados.

**Propriedades da Função de Custo Esperado $\\phi(x)$**

As propriedades da função de custo de recurso esperado $\\phi(x)$ derivam diretamente das propriedades da função $Q(x, \\xi)$ e da estrutura da esperança sobre um suporte finito.

> **Proposição 2.3.** Suponha que a distribuição de probabilidade de $\\xi$ tenha suporte finito $\\Xi = \\{\\xi_1, \\dots, \\xi_K\\}$ e que a função de custo de recurso esperado $\\phi(\\cdot)$ tenha um valor finito em pelo menos um ponto $x \\in \\mathbb{R}^n$. Então a função $\\phi(\\cdot)$ é **polyhedral**. [^15]

*Prova.* Como $\\phi(x)$ é finita em algum ponto, todos os valores $Q(x, \\xi_k)$, para $k = 1, \\dots, K$, devem ser finitos nesse ponto [^17]. Pela Proposição 2.1 [^2], cada função $Q(\\cdot, \\xi_k)$ é convexa e, se certas condições de factibilidade forem satisfeitas, polyhedral [^2]. Como $\\phi(x)$ é uma combinação linear com pesos positivos $p_k > 0$ de funções polyhedral $Q(\\cdot, \\xi_k)$ (dado que $\\phi(x) = \\sum p_k Q(x, \\xi_k)$ [^12]), segue-se que $\\phi(\\cdot)$ também é polyhedral [^17]. Além disso, o domínio de $\\phi$, denotado por $\\text{dom } \\phi$, é a interseção dos domínios das funções individuais $Q_k(\\cdot) := Q(\\cdot, \\xi_k)$, i.e., $\\text{dom } \\phi = \\cap_{k=1}^K \\text{dom } Q_k$ [^17]. $\\blacksquare$

A natureza polyhedral de $\\phi(x)$ implica que ela é convexa e contínua em seu domínio.

**Subdiferencial do Custo Esperado**

Sendo $\\phi(x)$ uma função convexa (e polyhedral sob as condições da Proposição 2.3), seu **subdiferencial** em um ponto $x_0 \\in \\text{dom } \\phi$ é um conjunto bem definido. As propriedades de subdiferenciação de $\\phi(x)$ decorrem das propriedades de $Q(x, \\xi)$ e do teorema de Moreau-Rockafellar sobre a subdiferenciação de somas de funções convexas [^17].

> Para qualquer $x_0 \\in \\text{dom } \\phi$, o subdiferencial de $\\phi$ em $x_0$ é dado por:
> $$\
> \\partial \\phi(x_0) = \\sum_{k=1}^K p_k \\partial Q(x_0, \\xi_k)\n> $$\
> [^16]

Aqui, $\\partial Q(x_0, \\xi_k)$ é o subdiferencial da função de custo de recurso do $k$-ésimo cenário, avaliada em $x_0$. Expandindo o conceito apresentado na Proposição 2.2 [^3], se $Q(x_0, \\xi_k)$ é finito, temos:
$$\
\\partial Q(x_0, \\xi_k) = -T_k^T D(x_0, \\xi_k)
$$\
[^19]
onde $D(x_0, \\xi_k)$ é o conjunto das soluções ótimas do problema dual de segundo estágio (2.3) [^3] para o cenário $\\xi_k$:
$$\
D(x_0, \\xi_k) := \\arg \\max_{\\pi_k} \\{ \\pi_k^T (h_k - T_k x_0) \\mid W_k^T \\pi_k \\le q_k \\}
$$\
[^19]
A fórmula (2.16) estabelece que o subdiferencial da função de custo esperado é a média ponderada (pelas probabilidades $p_k$) dos subdiferenciais das funções de custo de cada cenário [^16]. Esta propriedade é crucial para derivar condições de otimalidade para o problema de dois estágios, como veremos na Seção 2.1.4 [^24]. Note que, como as funções $Q_k$ são polyhedral, não há necessidade de condições de regularidade adicionais (como qualificação de restrições) para que a fórmula (2.16), um caso particular do teorema de Moreau-Rockafellar, seja válida [^17].

**Diferenciabilidade**

Da fórmula do subdiferencial (2.16) e da caracterização de $\\partial Q(x_0, \\xi_k)$ em (2.18), segue-se uma condição para a diferenciabilidade da função de custo esperado $\\phi(x)$. A função $\\phi$ é diferenciável em $x_0$ se, e somente se, para *cada* cenário $\\xi = \\xi_k$, $k=1, \\dots, K$, o conjunto $D(x_0, \\xi_k)$ das soluções ótimas duais do segundo estágio for um singleton, ou seja, a solução ótima dual para cada problema de segundo estágio for única [^20]. Neste caso, o gradiente $\\nabla \\phi(x_0)$ é a expressão única resultante da soma em (2.16).

#### Conclusão

A análise do custo de recurso esperado $E[Q(x, \\xi)]$ para distribuições de probabilidade discretas com suporte finito revela propriedades estruturais importantes. A função $\\phi(x) = \\sum p_k Q(x, \\xi_k)$ herda a natureza polyhedral das funções de custo individuais $Q(x, \\xi_k)$, sob condições brandas [^15]. Isso permite a formulação do problema estocástico original como um equivalente determinístico linear de grande escala (2.15) [^14]. Além disso, o subdiferencial de $\\phi(x)$ pode ser convenientemente expresso como a soma ponderada dos subdiferenciais dos custos de recurso de cada cenário (2.16) [^16], um resultado fundamental que depende das soluções ótimas duais dos problemas de segundo estágio [^19]. Essas caracterizações formam a base para o desenvolvimento de condições de otimalidade (Seção 2.1.4) e algoritmos eficientes para resolver problemas de programação linear estocástica de dois estágios com incerteza discreta.

#### Referências

[^1]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 27.
[^2]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 28, Proposition 2.1.
[^3]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 28, Proposition 2.2, Equation (2.7).
[^4]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 29, Proof of Proposition 2.2.
[^5]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 29, Equation (2.9).
[^6]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 29, "*Directly from the definition (2.4) we see that dom $s_q = \\text{pos } W$. Therefore, dom $Q(\\cdot, \\xi) = \\{x : h - Tx \\in \\text{pos } W\\}$*".
[^7]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 29, Equation (2.10).
[^8]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 29, Equation (2.11).
[^9]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 29.
[^10]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 30, Equation (2.12).
[^11]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 30.
[^12]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 30, Equation (2.13).
[^13]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 30, Equation (2.14) and surrounding text.
[^14]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 30, Equation (2.15).
[^15]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 30, Proposition 2.3.
[^16]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 30, Equation (2.16).
[^17]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 31, Proof of Proposition 2.3.
[^18]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 31, Equation (2.17).
[^19]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 31, Equation (2.18).
[^20]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 31.
[^21]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 31, Example 2.4.
[^22]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 32, Example 2.4 continued.
[^23]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 32, Equation (2.23).
[^24]: Ruszczyński, A., & Shapiro, A. (2009). Chapter 2: Two-Stage Problems. In *Stochastic Programming*. Page 32, Equation below (2.23).
<!-- END -->