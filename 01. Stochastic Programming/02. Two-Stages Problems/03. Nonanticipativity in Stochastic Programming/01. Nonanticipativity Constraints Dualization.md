## Capítulo 2.4: Dualização das Restrições de Não-Antecipatividade em Programação Estocástica de Dois Estágios

### Introdução

Como estabelecido nas seções anteriores que discutiram problemas de programação estocástica de dois estágios, tanto lineares [^1], [^2], quanto poliédricos [^16], [^17] e gerais [^22], uma característica fundamental é a natureza sequencial da tomada de decisão sob incerteza. As decisões do primeiro estágio, representadas pelo vetor **x**, devem ser tomadas *antes* da realização das variáveis aleatórias do segundo estágio, denotadas por **ξ** ou **ω**. Isso implica que **x** não pode depender da informação futura que ainda não está disponível. Esta propriedade crucial é conhecida como **não-antecipatividade**.

Uma abordagem poderosa para analisar a estrutura e desenvolver métodos de solução para esses problemas, especialmente em otimização de grande escala, envolve a relaxação temporária da restrição de não-antecipatividade e sua posterior reintrodução explícita através de restrições matemáticas. A Seção 2.4 do texto de referência [^26], [^27] introduz esta perspectiva. Este capítulo aprofunda a formulação dessas **restrições de não-antecipatividade** e explora em detalhe o processo de **dualização** associado a elas, tanto para o caso de distribuições discretas (cenários finitos) quanto para distribuições gerais. Analisaremos como a aplicação de multiplicadores de Lagrange a essas restrições leva a uma formulação dual, revelando estruturas importantes e estabelecendo conexões entre as soluções primais e duais através de condições de ponto de sela [^28], [^29], [^31], [^32].

### Conceitos Fundamentais

#### Formulação de Cenários e Restrições de Não-Antecipatividade

Para obter uma visão adicional sobre a estrutura dos problemas de dois estágios, podemos considerar a formulação baseada em cenários, especialmente útil quando o vetor aleatório **ξ** possui um suporte finito, ou seja, um número finito de realizações possíveis **ξk** (cenários), k = 1, ..., K, com probabilidades associadas pk > 0 [^4], [^26].

Inicialmente, podemos relaxar o problema original (por exemplo, (2.61) [^22]) permitindo que a decisão do primeiro estágio dependa do cenário k. Isso leva a um problema relaxado onde buscamos encontrar vetores **xk** para cada cenário k [^27]:
$$ \underset{x_1,...,x_K}{\text{Min}} \sum_{k=1}^{K} p_k F(x_k, \omega_k) \quad \text{sujeito a } x_k \in X, k=1,...,K \quad (2.80) $$
Aqui, *F(xk, ωk)* representa o valor da função objetivo para o cenário k, que pode incluir o custo do primeiro estágio e o valor ótimo esperado do segundo estágio (ou o valor ótimo do segundo estágio diretamente, se *F* for definida como em (2.90) [^30]). Este problema (2.80) é separável, decompondo-se em K problemas menores independentes, um para cada cenário [^27].

No entanto, o problema (2.80) não modela adequadamente um processo de decisão de dois estágios, pois as decisões **xk** podem depender da realização **ωk** [^27]. Para corrigir isso, introduzimos a **restrição de não-antecipatividade**, que força todas as realizações do vetor de decisão do primeiro estágio a serem iguais:
$$ (x_1, ..., x_K) \in \mathcal{L} \quad (2.82) $$
onde $\mathcal{L}$ é o subespaço linear definido como [^27]:
$$ \mathcal{L} := \{ \mathbf{x} = (x_1, ..., x_K) \in \mathbb{R}^{nK} : x_1 = x_2 = \dots = x_K \} $$
Esta restrição garante que a decisão do primeiro estágio não dependa da realização dos dados aleatórios [^27]. O problema original (2.61) é, portanto, equivalente a [^27]:
$$ \underset{x_1,...,x_K}{\text{Min}} \sum_{k=1}^{K} p_k F(x_k, \omega_k) \quad \text{s.t. } x_1 = \dots = x_K, \quad x_k \in X, k=1,...,K \quad (2.83) $$

Existem formas alternativas e convenientes de expressar a restrição de não-antecipatividade (2.82) [^27]. Uma delas é exigir que cada **xk** seja igual à sua média esperada [^27]:
$$ x_k = \sum_{i=1}^{K} p_i x_i, \quad k=1,...,K \quad (2.84) $$
Considerando o espaço vetorial $\mathcal{X} := \mathbb{R}^n \times \dots \times \mathbb{R}^n$ (K vezes) equipado com o produto escalar $\langle \mathbf{x}, \mathbf{y} \rangle := \sum_{i=1}^{K} p_i x_i^T y_i$ [^27], podemos definir o operador linear $\mathbf{P} : \mathcal{X} \to \mathcal{X}$ como [^28]:
$$ \mathbf{P}\mathbf{x} := \left( \sum_{i=1}^{K} p_i x_i, \dots, \sum_{i=1}^{K} p_i x_i \right) $$
Pode-se verificar que **P** é o operador de projeção ortogonal de $\mathcal{X}$ sobre o subespaço de não-antecipatividade $\mathcal{L}$ [^28]. Com isso, a restrição (2.84) pode ser escrita compactamente como [^28]:
$$ \mathbf{x} = \mathbf{P}\mathbf{x} $$
Outra forma algebricamente equivalente, útil em métodos numéricos, é o sistema esparso de equações [^28]:
$$ x_1 = x_2, \quad x_2 = x_3, \quad \dots, \quad x_{K-1} = x_K \quad (2.87) $$

#### Dualização via Multiplicadores de Lagrange (Caso Discreto)

A dualização do problema relaxado (2.80) com respeito às restrições de não-antecipatividade (2.84) envolve a introdução de multiplicadores de Lagrange $\lambda_k \in \mathbb{R}^n$ para cada uma das K restrições [^28]. A função Lagrangiana é dada por [^28]:
$$ L(\mathbf{x}, \boldsymbol{\lambda}) := \sum_{k=1}^{K} p_k F(x_k, \omega_k) + \sum_{k=1}^{K} p_k \lambda_k^T \left( x_k - \sum_{i=1}^{K} p_i x_i \right) $$
Utilizando a notação do operador de projeção **P**, e notando que $\mathbf{I} - \mathbf{P}$ também é uma projeção ortogonal (sobre o espaço ortogonal a $\mathcal{L}$), a Lagrangiana pode ser escrita como $\langle \boldsymbol{\lambda}, (\mathbf{I} - \mathbf{P})\mathbf{x} \rangle = \langle (\mathbf{I} - \mathbf{P})\boldsymbol{\lambda}, \mathbf{x} \rangle$ [^28]. Uma forma equivalente, após rearranjo, é [^29]:
$$ L(\mathbf{x}, \boldsymbol{\lambda}) = \sum_{k=1}^{K} p_k F(x_k, \omega_k) + \sum_{k=1}^{K} p_k \left( \lambda_k - \sum_{j=1}^{K} p_j \lambda_j \right)^T x_k $$
Observa-se que adicionar um vetor constante a todos os multiplicadores $\lambda_k$ não altera o valor da Lagrangiana, pois o termo $\lambda_k - \sum p_j \lambda_j$ é invariante a tais deslocamentos [^29]. Portanto, sem perda de generalidade, podemos impor a condição [^29]:
$$ \sum_{j=1}^{K} p_j \lambda_j = 0 $$
Esta condição é equivalente a $\mathbf{P}\boldsymbol{\lambda} = 0$, onde $\boldsymbol{\lambda} = (\lambda_1, ..., \lambda_K)$ [^29]. Sob esta condição, a Lagrangiana simplifica para [^29]:
$$ L(\mathbf{x}, \boldsymbol{\lambda}) = \sum_{k=1}^{K} p_k (F(x_k, \omega_k) + \lambda_k^T x_k) $$
A dualização do problema (2.80) em relação às restrições de não-antecipatividade (2.84) leva ao seguinte problema dual [^29]:
$$ \underset{\boldsymbol{\lambda}}{\text{Max}} \{ D(\boldsymbol{\lambda}) := \inf_{\mathbf{x} \in X^K} L(\mathbf{x}, \boldsymbol{\lambda}) \} \quad \text{s.t. } \mathbf{P}\boldsymbol{\lambda} = 0 \quad (2.88) $$
A função Lagrangiana $L(\mathbf{x}, \boldsymbol{\lambda})$ sob a condição $\mathbf{P}\boldsymbol{\lambda} = 0$ é separável em K componentes [^29]:
$$ L(\mathbf{x}, \boldsymbol{\lambda}) = \sum_{k=1}^{K} p_k L_k(x_k, \lambda_k), \quad \text{onde } L_k(x_k, \lambda_k) := F(x_k, \omega_k) + \lambda_k^T x_k $$
Consequentemente, a função objetivo dual $D(\boldsymbol{\lambda})$ também é separável [^29]:
$$ D(\boldsymbol{\lambda}) = \sum_{k=1}^{K} p_k D_k(\lambda_k), \quad \text{onde } D_k(\lambda_k) := \inf_{x_k \in X} L_k(x_k, \lambda_k) $$
Portanto, o cálculo do valor da função dual $D(\boldsymbol{\lambda})$ pode ser realizado resolvendo K subproblemas independentes, um para cada cenário k [^29], [^30]. Por exemplo, no caso do problema linear de dois estágios (2.15) [^4], $D_k(\lambda_k)$ é o valor ótimo do problema [^30]:
$$ \underset{x_k, y_k}{\text{Min}} (c + \lambda_k)^T x_k + q_k^T y_k \quad \text{s.t. } Ax_k = b, \quad T_k x_k + W_k y_k = h_k, \quad x_k \ge 0, y_k \ge 0 $$

#### Relação Primal-Dual e Pontos de Sela (Caso Discreto)

A teoria geral da dualidade afirma que o valor ótimo do problema primal (2.61), ou equivalentemente (2.83), é maior ou igual ao valor ótimo do problema dual (2.88) (dualidade fraca) [^29]. Sob certas condições de regularidade, esses valores ótimos são iguais (dualidade forte) [^29].

> **Caixa de Destaque 1: Dualidade Forte**
> Em particular, se o problema de dois estágios é linear (como (2.15)) e as restrições de não-antecipatividade são lineares, não há *gap* de dualidade entre o problema primal (2.61) e seu dual (2.88), a menos que ambos os problemas sejam inviáveis [^29].

Suponha que não haja *gap* de dualidade e que o valor ótimo comum seja finito. Seja $\boldsymbol{\bar{\lambda}} = (\bar{\lambda}_1, ..., \bar{\lambda}_K)$ uma solução ótima do problema dual (2.88). Então, o conjunto de soluções ótimas do problema primal original (2.61) está contido no conjunto de soluções ótimas do problema [^30]:
$$ \underset{\mathbf{x} \in X^K}{\text{Min}} \sum_{k=1}^{K} p_k L_k(x_k, \bar{\lambda}_k) \quad (2.89) $$
Note que o problema (2.89) é separável. Se ele possuir uma solução ótima única $\mathbf{\bar{x}} = (\bar{x}_1, ..., \bar{x}_K)$, então essa solução deve satisfazer a restrição de não-antecipatividade, ou seja, $\mathbf{\bar{x}} \in \mathcal{L}$ ($ \bar{x}_1 = \dots = \bar{x}_K$), e $\bar{x}_k$ (para qualquer k) é a solução ótima única do problema primal original (2.61) [^30]. No entanto, a inclusão pode ser estrita; o conjunto de soluções de (2.89) pode ser maior que o conjunto de soluções de (2.61) [^30].

#### Dualização para Distribuições Gerais

A abordagem de dualização pode ser estendida para o caso geral onde a distribuição de probabilidade dos dados aleatórios **ω** não é necessariamente discreta [^30]. Seja $\mathcal{X}$ um espaço linear decomponível de mapeamentos mensuráveis de $\Omega$ para $\mathbb{R}^n$, por exemplo, $\mathcal{X} = L_p(\Omega, \mathcal{F}, P; \mathbb{R}^n)$ para algum $p \in [1, +\infty]$ [^30]. O espaço dual é $\mathcal{X}^* = L_q(\Omega, \mathcal{F}, P; \mathbb{R}^n)$ com $1/p + 1/q = 1$ [^31]. A forma bilinear é dada por $\langle \lambda, x \rangle = E[\lambda(\omega)^T x(\omega)]$ [^31].

O subespaço de não-antecipatividade $\mathcal{L}$ é definido como o conjunto de mapeamentos em $\mathcal{X}$ que são constantes quase em todo lugar [^30]:
$$ \mathcal{L} := \{ x \in \mathcal{X} : x(\omega) = \bar{x} \text{ para algum } \bar{x} \in \mathbb{R}^n \text{ a.e. } \omega \in \Omega \} $$
O problema primal pode ser escrito como [^30]:
$$ \underset{x \in \mathcal{L}}{\text{Min}} E[F(x(\omega), \omega)] \quad (2.91) $$
onde $F(x, \omega)$ inclui a restrição $x \in X$. A Lagrangiana associada à restrição $x \in \mathcal{L}$ (ou equivalentemente $x - Px = 0$, onde $P$ é a projeção $E[\cdot]$) é [^31]:
$$ L(x, \lambda) := E[F(x(\omega), \omega)] + \langle \lambda, x - Px \rangle = E[F(x(\omega), \omega)] + \langle \lambda - P^*\lambda, x \rangle $$
onde $P^*$ é o operador adjunto $E[\cdot]$ [^31]. Impondo a condição $P^*\lambda = 0$ (ou seja, $E[\lambda] = 0$), a Lagrangiana simplifica para [^31]:
$$ L(x, \lambda) = E[F(x(\omega), \omega) + \lambda(\omega)^T x(\omega)] \quad \text{para } E[\lambda]=0 \quad (2.92) $$
O problema dual correspondente é [^31]:
$$ \underset{\lambda \in \mathcal{X}^*}{\text{Max}} \{ D(\lambda) := \inf_{x \in \mathcal{X}} L(x, \lambda) \} \quad \text{s.t. } E[\lambda] = 0 \quad (2.93) $$
Pelo princípio da intercambialidade (Teorema 7.80 [^31]), a função dual pode ser calculada como [^31]:
$$ D(\lambda) = E[D_\omega(\lambda(\omega))], \quad \text{onde } D_\omega(\lambda) := \inf_{x \in \mathbb{R}^n} \{ F(x, \omega) + \lambda^T x \} \quad (2.94) $$
Note que $D_\omega(\lambda)$ está relacionado à função conjugada de $F(\cdot, \omega)$, denotada $F_\omega^*$, por $D_\omega(\lambda) = -F_\omega^*(-\lambda)$ [^31].

#### Condições de Ponto de Sela (Caso Geral)

Novamente, pela teoria geral, o valor ótimo primal (2.90) é maior ou igual ao valor ótimo dual (2.93) [^32]. Igualdade (ausência de *gap* de dualidade) e existência de soluções ótimas $\bar{x} \in \mathcal{L}$ e $\bar{\lambda} \in \mathcal{X}^*$ com $E[\bar{\lambda}]=0$ ocorrem se, e somente se, $(\bar{x}, \bar{\lambda})$ for um **ponto de sela** da Lagrangiana (2.92) [^32]. Um ponto $(\bar{x}, \bar{\lambda})$ é um ponto de sela se [^32]:
$$ \bar{x} \in \underset{x \in \mathcal{X}}{\text{arg min}} L(x, \bar{\lambda}) \quad \text{e} \quad \bar{\lambda} \in \underset{\lambda \in \mathcal{X}^*, E[\lambda]=0}{\text{arg max}} L(\bar{x}, \lambda) \quad (2.95) $$
Usando novamente o princípio da intercambialidade (Teorema 7.80 referenciado em [^32]), a primeira condição em (2.95) é equivalente a [^32]:
$$ \bar{x}(\omega) = \bar{x} \in \mathbb{R}^n \quad \text{e} \quad \bar{x} \in \underset{x \in \mathbb{R}^n}{\text{arg min}} \{ F(x, \omega) + \bar{\lambda}(\omega)^T x \} \quad \text{a.e. } \omega \in \Omega \quad (2.96) $$
Assumindo que o problema é convexo, ou seja, $X$ é convexo e $F(\cdot, \omega)$ é uma função convexa para quase todo $\omega$ [^32], a condição de minimização em (2.96) é equivalente a $\bar{\lambda}(\omega) \in -\partial F_\omega(\bar{x})$ para quase todo $\omega \in \Omega$ [^32]. Combinando com a segunda condição em (2.95), $E[\bar{\lambda}]=0$, um ponto de sela existe se, e somente se, existe $\bar{x} \in \mathbb{R}^n$ tal que [^32]:
$$ 0 \in E[\partial F_\omega(\bar{x})] \quad (2.97) $$

> **Teorema 2.25 (Resumido) [^32]:** Suponha que $F(x, \omega)$ seja *random lower semicontinuous*, $X$ seja convexo e fechado, e $F(\cdot, \omega)$ seja convexa a.e. $\omega$. Então, não há *gap* de dualidade entre (2.90) e (2.93) e ambos os problemas têm soluções ótimas se, e somente se, existe $\bar{x} \in \mathbb{R}^n$ satisfazendo a condição (2.97). Nesse caso, $\bar{x}$ é uma solução ótima de (2.90) e qualquer seleção mensurável $\bar{\lambda}(\omega) \in -\partial F_\omega(\bar{x})$ com $E[\bar{\lambda}]=0$ é uma solução ótima de (2.93).

Sob condições adicionais de regularidade, a existência de uma solução ótima primal garante a ausência de *gap* de dualidade.

> **Teorema 2.26 (Resumido) [^32]:** Suponha as condições (i)-(iii) do Teorema 2.26 e que o problema (2.90) possua uma solução ótima $\bar{x}$ tal que $\bar{x} \in \text{int}(\text{dom } f)$, onde $f(x) = E[F(x, \omega)]$. Então, não há *gap* de dualidade entre (2.90) e (2.93), o problema dual (2.93) tem uma solução ótima $\bar{\lambda}$, e o mapeamento constante $x(\omega) = \bar{x}$ é uma solução ótima para o problema $\text{Min}_{x \in \mathcal{X}} E[F(x(\omega), \omega) + \bar{\lambda}(\omega)^T x(\omega)]$.

A condição $\bar{x} \in \text{int}(\text{dom } f)$ implica que $f(x) < +\infty$ para todo $x$ em uma vizinhança de $\bar{x}$, o que é ligeiramente mais forte que a condição de *relatively complete recourse* [^33].

### Conclusão

As restrições de não-antecipatividade são essenciais para a modelagem correta de problemas de decisão sequencial sob incerteza, garantindo que as decisões tomadas em um estágio não dependam de informações futuras ainda não reveladas. A abordagem de relaxar o problema original e reintroduzir explicitamente essas restrições permite uma análise mais profunda através da dualização.

Demonstramos como atribuir multiplicadores de Lagrange às diferentes formas das restrições de não-antecipatividade (discretas ou contínuas) leva a problemas duais com estruturas interessantes, notavelmente a separabilidade por cenário no caso discreto. A função dual resultante pode ser calculada resolvendo subproblemas independentes ou através da função conjugada no caso geral.

As condições de ponto de sela da Lagrangiana estabelecem a ligação fundamental entre as soluções primais e duais. Sob condições de convexidade e regularidade (como a solução primal estar no interior do domínio da função de valor esperado ou a ausência de *gap* de dualidade em problemas lineares), a dualidade forte se mantém. A condição chave $0 \in E[\partial F_\omega(\bar{x})]$ caracteriza a otimalidade primal em termos de subgradientes esperados e garante a existência de multiplicadores duais ótimos com média zero. Essa perspectiva dual é não apenas teoricamente importante, mas também a base para algoritmos de decomposição eficientes para resolver problemas de programação estocástica de grande escala.

### Referências

[^1]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 27. "Min cᵀx + E[Q(x,ξ)] s.t. Ax = b, x ≥ 0,"
[^2]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 27. "Min qᵀy s.t. Tx + Wy = h, y ≥ 0."
[^3]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 28. "Max πᵀ(h – Tx) s.t. Wᵀπ ≤ q."
[^4]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 30. "Suppose that the distribution of ξ has finite support. That is, ξ has a finite number of realizations (called scenarios) ξk = (qk, hk, Tk, Wk) with respective (positive) probabilities pk, k = 1, . . ., K, i.e., Ξ = {ξ1, ..., ξK}."
[^5]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 30. "The whole two stage-problem is equivalent to the following large-scale linear programming problem: Min cᵀx + Σ pk qkᵀyk s.t. Tkx + Wkyk = hk, k = 1,...,K, Ax = b, x ≥ 0, yk ≥ 0, k = 1,...,K." (Eq. 2.15)
[^6]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 31. Description of subgradient calculation using dual solutions. (Eq. 2.18)
[^7]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 32. "Let us denote by M(x0, ξ) the set of optimal solutions of this problem satisfying the condition μη₀ = 0."
[^8]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 33. "The function Q(x, ·) is measurable as the optimal value of a linear programming problem."
[^9]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 33. "The two-stage problem (2.1)–(2.2) is said to have fixed recourse if the matrix W is fixed (not random)."
[^10]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 33. "Moreover, we say that the recourse is complete if the system Wy = x and y ≥ 0 has a solution for every x."
[^11]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 33. "It is said that the recourse is relatively complete if for every x in the set X = {x : Ax = b, x ≥ 0}, the feasible set of the second-stage problem (2.2) is nonempty for almost everywhere (a.e.) ω ∈ Ω."
[^12]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 34. Discussion on support function sq(·) and Hoffman\'s lemma. (Eq. 2.25, 2.26)
[^13]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 35. Proposition 2.6 and its proof relating E[Q(x, ξ)+] finiteness to feasibility condition h - Tx ∈ pos W w.p. 1 under fixed recourse. (Eq. 2.28, 2.29)
[^14]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 35. Proposition 2.7 stating properties (convexity, lsc, Lipschitz) of the expected recourse function φ(x) under fixed recourse and non-empty dual feasible set Π(q). (Eq. 2.30)
[^15]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 36. Lipschitz continuity derivation for φ(x). (Eq. 2.32, 2.33)
[^16]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 42. "Let us consider a slightly more general formulation of a two-stage stochastic programming problem, Min f1(x) + E[Q(x, ω)], where Q(x, ω) is the optimal value of the second-stage problem..." (Eq. 2.44)
[^17]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 42. "...Min f2(y, ω) s.t. T(ω)x + W(ω)y = h(ω)." (Eq. 2.45)
[^18]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 43. "Consider the Lagrangian of the second-stage problem (2.45): L(y, π; x, ω) := f2(y, ω) + πᵀ(h(ω) – T(ω)x – W(ω)y)."
[^19]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 44. Proposition 2.14 describing subgradient of polyhedral Q(·, ω). (Eq. 2.47)
[^20]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 45. Discussion on fixed recourse for polyhedral problems. (Eq. 2.51, 2.52)
[^21]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 46. Proposition 2.17 stating properties of expected recourse cost φ(x) for polyhedral case with fixed recourse. (Eq. 2.56, 2.57)
[^22]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 48. "In a general way, two-stage stochastic programming problems can be written in the following form: Min {f(x) := E[F(x, ω)]}, where F(x, ω) is the optimal value of the second-stage problem Min g(x, y, ω)." (Eq. 2.61, 2.62)
[^23]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 49. Theorem 2.20 (Interchangeability Principle). (Eq. 2.66)
[^24]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 50. Definition of convex multifunction Gω(x). (Eq. 2.69, 2.70)
[^25]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 51. Proposition 2.21 on duality gap and subdifferentiability of optimal value function θ(·, ω).
[^26]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 52. "An additional insight into the structure and properties of two-stage problems can be gained by introducing the concept of nonanticipativity."
[^27]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 53. "Let us relax the first-stage problem by replacing vector x with K vectors x1, x2, ..., xK, one for each scenario... Min Σ pk F(xk, ωk) subject to xk ∈ X... (2.80)... This can be fixed by introducing the additional constraint (x1, ..., xK) ∈ L, (2.82) where L := {x = (x1, ..., xK) : x1 = ··· = xK}... referred to as the nonanticipativity constraint... problem (2.80) becomes Min Σ pk F(xk, ωk) s.t. x1 = ··· = xK... (2.83)... A way to write the nonanticipativity constraint is to require that xk = Σ pi xi, k = 1, ..., K, (2.84)... Consider the space X equipped with the scalar product <x, y> := Σ pi xᵀi yi (2.85)."
[^28]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 54. "Define linear operator P: X → X as Px := (Σ pi xi, ..., Σ pi xi)... Constraint (2.84) can be compactly written as x = Px... P is the orthogonal projection operator... onto its subspace L... Another way to algebraically express nonanticipativity... is to write the system of equations x1 = x2, ..., xK-1 = xK. (2.87)... We discuss now a dualization of problem (2.80) with respect to the nonanticipativity constraints (2.84). Assigning to these nonanticipativity constraints Lagrange multipliers λk ∈ Rⁿ... we can write the Lagrangian L(x, λ) := Σ pk F(xk, ωk) + Σ pk λᵀk (xk - Σ pi xi)... Note that since P is an orthogonal projection, I - P is also an orthogonal projection... hence Σ pk λᵀk (xk - Σ pi xi) = <λ, (I - P)x> = <(I - P)λ, x>."
[^29]: Ruszczyński, A., & Shapiro, A. (2009). Two-Stage Problems. *Stochastic Programming*, Chapter 2, page 55. "Therefore, the above Lagrangian can be written in the following equivalent form: L(x, λ) = Σ pk F(xk, ωk) + (Σ pk (λk - Σ pj λj)ᵀ xk)... with no loss of generality we can assume that Σ pj λj = 0... or, equivalently, that Pλ = 0. Dualization of problem (2.80) with respect to the nonanticipativity constraints takes the form of the following problem: Max {D(λ) := inf L(x, λ)} s.t. Pλ = 0. (2.88)... By general duality theory we have that the optimal value of problem (2.61) is greater than or equal to the optimal value of problem (2.88)... if the two-stage problem is linear... there is no duality gap between problem (2.61) and its dual problem (2.88) unless both problems are infeasible... Under the condition Pλ = 0, the Lagrangian can be written simply as L(x, λ) = Σ pk (F(xk, ωk) + λᵀk xk