## Dualidade da Não-Antecipatividade para Distribuições Gerais em Programação Estocástica

### Introdução

A programação estocástica fornece um framework robusto para a tomada de decisão sob incerteza, onde algumas ou todas as variáveis do problema são aleatórias. Um conceito central, particularmente em problemas multiestágio, é o da **não-antecipatividade**. Esta restrição impõe que as decisões tomadas em um determinado estágio não podem depender das realizações futuras das variáveis aleatórias, garantindo assim que as decisões sejam implementáveis em tempo real. Como vimos na formulação para cenários discretos [^27, ^28], a não-antecipatividade pode ser tratada através de restrições explícitas que forçam a igualdade das variáveis de decisão correspondentes a diferentes cenários. A dualização dessas restrições revela estruturas importantes e leva a métodos de decomposição [^28, ^29].

Este capítulo aprofunda a análise da não-antecipatividade, estendendo a abordagem de dualização para o caso de **distribuições de probabilidade gerais**, não necessariamente discretas. Exploraremos como, no caso geral, as restrições de não-antecipatividade podem ser elegantemente expressas em termos de um **subespaço linear** de mapeamentos mensuráveis [^30, ^31]. Consequentemente, o problema dual associado a essas restrições envolve um **operador de projeção** atuando sobre o espaço dual, fornecendo uma ferramenta poderosa para a análise teórica e o desenvolvimento de algoritmos [^31].

### Conceitos Fundamentais

#### Formulação em Espaços Funcionais

Consideremos um problema de programação estocástica de dois estágios na forma geral, como apresentado em (2.61) [^26], que buscamos minimizar uma função objetivo esperada. Para analisar a não-antecipatividade no contexto de distribuições gerais, é conveniente reformular o problema (2.61) ou, mais especificamente, a forma (2.90) [^30], em um espaço funcional apropriado. Seja `(Ω, F, P)` um espaço de probabilidade. Introduzimos um **espaço linear decomponível** `X` de mapeamentos mensuráveis `x: Ω → Rⁿ`, onde `Rⁿ` é o espaço da variável de decisão do primeiro estágio [^30]. Um exemplo típico para `X` é o espaço de Lebesgue `Lp(Ω, F, P; Rⁿ)` para algum `p ∈ [1, +∞]` [^30, ^31].

A essência da não-antecipatividade no primeiro estágio é que a decisão `x` não pode depender da realização `ω ∈ Ω` da incerteza futura. Matematicamente, isso significa que o mapeamento `x(ω)` deve ser constante em quase toda parte (a.e.) em `Ω` [^30]. Esta condição define o **subespaço de não-antecipatividade** `L` dentro de `X`:\n$$ L := \\{x \\in X : x(ω) = \\bar{x} \\text{ para algum } \\bar{x} \\in Rⁿ \\text{ a.e. } ω \\in Ω\\} $$\nO problema estocástico original (2.90), `Min {f(x) := E[ F(x, w)]}` onde `x ∈ Rⁿ` e `F` pode incluir restrições como `x ∈ X` [^30], pode ser escrito de forma equivalente no espaço funcional como:\n$$ \\text{Min}_{x \\in X} \\quad E[F(x(ω), ω)] \\quad \\text{s.t.} \\quad x \\in L $$\nonde `F(x(ω), ω)` é interpretado como `F(x, ω)` quando `x(ω)` é constante `x`, e pode incorporar restrições sobre `x` através de `F(x, ω) = F(x, ω) + Ix(x)` [^30].

#### Espaços Duais e Operadores de Projeção

Para desenvolver a teoria da dualidade, consideramos o espaço dual `X*` de `X`. Se `X = Lp(Ω, F, P; Rⁿ)` com `p ∈ [1, +∞)`, seu dual é `X* = Lq(Ω, F, P; Rⁿ)` onde `1/p + 1/q = 1` [^31]. Definimos a forma bilinear (produto escalar) que pareia `λ ∈ X*` e `x ∈ X` como:\n$$ (\\lambda, x) := E [\\lambda^T x] = \\int_{\\Omega} \\lambda(\\omega)^T x(\\omega) dP(\\omega) $$\n[^31]. É crucial introduzir o **operador de projeção** `P : X \\to L` que mapeia um elemento `x ∈ X` para sua componente constante esperada [^31]:\n$$ [Px](\\omega) := E[x] = \\int_{\\Omega} x(\\omega') dP(\\omega') $$\n[^31]. Claramente, o subespaço `L` é o conjunto de todos os `x ∈ X` tais que `x = Px` [^31].

O operador adjunto `P^* : X^* \\to L^*`, onde `L^*` é o subespaço de `X^*` consistindo de mapeamentos constantes a.e., é dado por [^31]:\n$$ [P^*\\lambda](\\omega) := E[\\lambda] = \\int_{\\Omega} \\lambda(\\omega') dP(\\omega') $$\n[^31]. A relação de adjunção é verificada por `(λ, Px) = E[\\lambda^T E[x]] = E[\\lambda]^T E[x] = E[E[\\lambda]^T x] = (P^*\\lambda, x)` [^31].

#### Formulação Lagrangiana e o Problema Dual

A restrição de não-antecipatividade `x ∈ L` pode ser escrita como `x - Px = 0`. Podemos associar um multiplicador de Lagrange `λ ∈ X*` a esta restrição. O **Lagrangiano** para o problema (2.91) é [^31]:\n$$ L(x, \\lambda) := E[F(x(ω), ω)] + (\\lambda, x - Px) $$\nUsando a propriedade de adjunção `(λ, x - Px) = (λ - P^*\\lambda, x)`, podemos reescrever o Lagrangiano. De forma crucial, se impusermos a condição `P^*\\lambda = 0`, que equivale a `E[\\lambda] = 0`, o termo do multiplicador se simplifica [^31]:\n$$ L(x, \\lambda) = E[F(x(ω), ω)] + (\\lambda, x) = E[F(x(ω), ω) + \\lambda(\\omega)^T x(\\omega)] \\quad \\text{para } E[\\lambda] = 0 $$\n[^31, ^32]. Esta simplificação é análoga à observada no caso de cenários finitos, onde assumimos `Pλ = 0` (com `P` sendo a projeção naquele contexto) [^29].

Isto leva diretamente à formulação do **problema dual** associado à não-antecipatividade [^31]:\n$$ \\text{Max}_{\\lambda \\in X^*} \\quad \\{ D(\\lambda) := \\inf_{x \\in X} L(x, \\lambda) \\} \\quad \\text{s.t.} \\quad E[\\lambda] = 0 $$\n[^31, ^32]. A função objetivo dual `D(λ)` pode ser analisada usando o princípio da intercambialidade (como o Teorema 7.80 referenciado em [^31, ^33]), sob condições apropriadas:\n$$ D(\\lambda) = \\inf_{x \\in X} E[F(x(ω), ω) + \\lambda(\\omega)^T x(ω)] = E\\left[ \\inf_{x \\in R^n} \\{ F(x, ω) + \\lambda(\\omega)^T x \\} \\right] $$\nA expressão interna `inf_{x \\in R^n} \\{ F(x, ω) + \\lambda(\\omega)^T x \\}` define uma função `D_{\\lambda(ω)}` para cada `ω`. Reconhecemos esta expressão como relacionada à função conjugada de `F(·, ω)`, denotada por `F_ω^*`. Especificamente [^31]:\n$$ \\inf_{x \\in R^n} \\{ F(x, ω) + \\lambda(\\omega)^T x \\} = - \\sup_{x \\in R^n} \\{ -\\lambda(\\omega)^T x - F(x, ω) \\} = -F_ω^*(-\\lambda(\\omega)) $$\nPortanto, a função dual pode ser expressa como o valor esperado da conjugada [^31]:\n$$ D(\\lambda) = E[-F_ω^*(-\\lambda(\\omega))] = E[D_{\\lambda(ω)}] $$\n

#### Teoria da Dualidade e Condições de Otimalidade

A teoria geral da dualidade estabelece que o valor ótimo do problema dual (2.93) é sempre menor ou igual ao valor ótimo do problema primal (2.91) (dualidade fraca). A ausência de um *gap* de dualidade e a existência de soluções ótimas para ambos os problemas estão intrinsecamente ligadas à existência de um ponto de sela para o Lagrangiano (2.92) [^32].

> **Teorema 2.25** [^32]: Suponha que a função `F(x, ω)` seja *random lower semicontinuous*, o conjunto `X` (definido implicitamente pelas restrições em `F`) seja convexo e fechado, e para a.e. `ω ∈ Ω` a função `F(·, ω)` seja convexa. Então, não há *duality gap* entre os problemas (2.90) e (2.93) e ambos os problemas possuem soluções ótimas se, e somente se, existe `x ∈ Rⁿ` satisfazendo a condição:\n> $$ 0 \\in E [\\partial F_ω(\\bar{x})] $$\n> (2.97) [^32]. Neste caso, `x` é uma solução ótima de (2.90) e uma seleção mensurável `λ(ω) ∈ -∂F_ω(\\bar{x})` tal que `E[λ] = 0` é uma solução ótima de (2.93).

Aqui, `∂F_ω(\\bar{x})` denota o subdiferencial da função `F(·, ω)` no ponto `\\bar{x}`. A condição (2.97) é fundamental, pois conecta a otimalidade primal à existência de um multiplicador dual com média zero. Ela representa a condição de otimalidade de primeira ordem para o problema primal (2.90) expressa em termos esperados.

O **Teorema 2.26** [^32] fornece condições suficientes para garantir a existência de uma solução dual ótima `λ` e a ausência de *gap* de dualidade. Uma condição chave é a existência de uma solução primal ótima `x` que esteja no interior do domínio efetivo da função objetivo esperada `f(x) = E[F(x, ω)]` (i.e., `x ∈ int(dom f)`). Sob esta condição de regularidade (e as hipóteses de convexidade e semicontinuidade), a relação `E[∂F_ω(\\bar{x})] = ∂f(\\bar{x})` (ou uma inclusão, dependendo das hipóteses exatas, veja Teorema 7.47 em [^32]) é válida, e a otimalidade `0 ∈ ∂f(\\bar{x})` implica a condição (2.97).

### Conclusão

A dualização da restrição de não-antecipatividade para distribuições gerais de probabilidade, utilizando o formalismo de espaços funcionais, oferece uma perspectiva unificada e poderosa. A representação da não-antecipatividade como um subespaço linear `L` e a introdução dos operadores de projeção `P` e seu adjunto `P^*` permitem formular um problema dual bem definido `Max {D(λ) | E[λ] = 0}` [^31]. A função dual `D(λ)` pode ser calculada através da integração de um problema de otimização paramétrico relacionado à função conjugada `F_ω^*` [^31].

Os resultados da teoria da dualidade, encapsulados no Teorema 2.25 [^32], estabelecem a conexão entre as soluções primais e duais e fornecem condições de otimalidade cruciais na forma `0 ∈ E[∂F_ω(x)]` [^32]. Esta abordagem não apenas enriquece a compreensão teórica dos problemas de programação estocástica multiestágio, mas também fundamenta o desenvolvimento de métodos computacionais avançados baseados em decomposição dual.

### Referências

[^1]: (p. 27) Min cᵀx + E[Q(x,ξ)] s.t. Ax = b, x ≥ 0, where Q(x, ξ) = Min qᵀy s.t. Tx + Wy = h, y ≥ 0. Here ξ := (q, h, T, W) are the data of the second-stage problem.
[^2]: (p. 28) The second-stage problem (2.2) is a linear programming problem. Its dual problem can be written in the form Max πᵀ(h – Tx) s.t. Wᵀπ ≤ q. (2.3)
[^3]: (p. 28) Π(q) := {π : Wᵀπ ≤ q} (2.5)
[^4]: (p. 28) sq(x) = sup_{π∈Π(q)} πᵀχ (2.6)
[^5]: (p. 28) Proposition 2.1. For any given ξ, the function Q(·,ξ) is convex. Moreover, if the set {π : Wᵀπ ≤ q} is nonempty and problem (2.2) is feasible for at least one x, then the function Q(·, ξ) is polyhedral.
[^6]: (p. 28) Proposition 2.2. Suppose that for given x = x₀ and ξ ∈ Ξ, the value Q(x₀, ξ) is finite. Then Q(·, ξ) is subdifferentiable at x₀ and ∂Q(x₀, ξ) = −TᵀD(x₀, ξ), where D(x, ξ) := arg max_{π∈Π(q)} πᵀ(h - Tx) is the set of optimal solutions of the dual problem (2.3). (2.7)
[^7]: (p. 29) The positive hull of a matrix W is defined as pos W := {x: x = Wy, y ≥ 0}. (2.9)
[^8]: (p. 29) dom Q(·, ξ) = {x : h − Tx ∈ pos W}.
[^9]: (p. 29) The recession cone of Π(q) is equal to Π₀ := Π(0) = {π : Wᵀπ ≤ 0}. (2.10)
[^10]: (p. 29) Π₀* = pos W. (2.11)
[^11]: (p. 30) φ(x) := E[Q(x, ξ)]. (2.12)
[^12]: (p. 30) Suppose that the distribution of ξ has finite support Ξ = {ξ₁,..., ξ<0xE2><0x82><0x9A>}. Then E[Q(x, ξ)] = ∑_{k=1}^K p_k Q(x, ξ_k). (2.13)
[^13]: (p. 30) Proposition 2.3. Suppose that the probability distribution of ξ has finite support Ξ = {ξ₁,..., ξ<0xE2><0x82><0x9A>} and that the expected recourse cost φ(·) has a finite value in at least one point x ∈ Rⁿ. Then the function φ(·) is polyhedral, and for any x₀ ∈ dom φ, ∂φ(x₀) = ∑_{k=1}^K p_k ∂Q(x₀, ξ_k). (2.16)
[^14]: (p. 31) The subdifferential ∂Q(x₀, ξ_k) ... is described in Proposition 2.2. ... ∂Q(x₀, ξ_k) = -T_k^T arg max_{π} {πᵀ(h_k - T_k x₀) : W_k^T π ≤ q_k}. (2.18)
[^15]: (p. 32) Example 2.4 (Capacity Expansion). Min ∑ c_{ij} x_{ij} + E[Q(x, ξ)]. (2.23) Subdifferential calculation using (2.16): ∂f(x₀) = c + ∑_{k=1}^K p_k ∂Q(x₀, ξ^k).
[^16]: (p. 33) The two-stage problem (2.1)–(2.2) is said to have fixed recourse if the matrix W is fixed (not random).
[^17]: (p. 33) It is said that the recourse is relatively complete if for every x in the set X = {x: Ax = b, x ≥ 0}, the feasible set of the second-stage problem (2.2) is nonempty for almost everywhere (a.e.) ω ∈ Ω. That is, ... Q(x, ξ(ω)) < +∞ w.p. 1.
[^18]: (p. 33) The following condition is sufficient for relatively complete recourse: for every x ∈ X the inequality Q(x, ξ) < +∞ holds true for all ξ ∈ Ξ. (2.24)
[^19]: (p. 34) By Hoffman's lemma ... there exists a constant κ, ... such that ... Π(q) ⊂ Π(q₀) + κ ||q - q₀|| B. (2.25)
[^20]: (p. 34) It follows from (2.25) that if the set Π(q₀) is nonempty, then s_q(x) ≤ s_{q₀}(x) + κ ||q - q₀ || ||x||. (derived from 2.26 with general q0)
[^21]: (p. 35) Proposition 2.6. Suppose that the recourse is fixed and E[||q|| ||h||] < +∞ and E[||q|| ||T||] < +∞. (2.28). Consider a point x ∈ Rⁿ. Then E[Q(x, ξ)+] is finite iff the following condition holds w.p. 1: h - Tx ∈ pos W. (2.29)
[^22]: (p. 35) Proposition 2.7. Suppose that (i) the recourse is fixed, (ii) for a.e. q the set Π(q) is nonempty, and (iii) condition (2.28) holds. Then the expectation function φ(x) is well defined and φ(x) > −∞ for all x ∈ Rⁿ. Moreover, φ is convex, lower semicontinuous and Lipschitz continuous on dom φ, and its domain is a convex closed subset of Rⁿ given by dom φ = {x ∈ Rⁿ : h − Tx ∈ pos W w.p.1}. (2.30)
[^23]: (p. 36) Formula (2.30) means that a point x belongs to dom φ iff the probability of the event {h -Tx ∈ pos W} is one. ... Consequently x belongs to dom φ iff for every (h, T) ∈ Σ it follows that h - Tx ∈ pos W. Therefore, we can write formula (2.30) in the form dom φ = ∩_{(h,T)∈ Σ} {x: h − Tx ∈ pos W}. (2.33)
[^24]: (p. 37) Proposition 2.8. Suppose that the expectation function φ(·) is proper and its domain has a nonempty interior. Then for any x₀ ∈ dom φ, ∂φ(x₀) = −E [TᵀD(x₀, ξ)] + N_{dom φ}(x₀), where D(x, ξ) := arg max_{π∈Π(q)} πᵀ(h - Tx). (2.34)
[^25]: (p. 38) Theorem 2.10. Let x be a feasible solution... x is an optimal solution ... iff there exist π_k ∈ D(x, ξ_k), k = 1, ..., K, and μ ∈ Rᵐ such that ∑_{k=1}^K p_k T_k^T π_k + A^T μ ≤ c, xᵀ(c - ∑_{k=1}^K p_k T_k^T π_k – A^T μ) = 0. (2.37)
[^26]: (p. 42, 48) General two-stage formulation: Min f₁(x) + E[Q(x, ω)] (2.44) or Min {f(x) := E[ F(x, w)]} (2.61), where Q(x, ω) or F(x, ω) is the value of the second-stage problem Min f₂(y, ω) s.t. T(ω)x + W(ω)y = h(ω) (2.45) or Min g(x, y, ω) s.t. y ∈ G(x,ω) (2.62).
[^27]: (p. 53) Relax problem (2.61) by replacing x with K vectors x₁, ..., xK. Min ∑ p_k F(x_k, ω_k) subject to x_k ∈ X, k = 1, ..., K. (2.80). This can be fixed by introducing the additional constraint (x₁, ..., xK) ∈ L, where L := {x = (x₁, ..., xK) : x₁ = ··· = xK} is a linear subspace... (2.82). The constraint (2.82) can be written in different forms... nonanticipativity constraint.
[^28]: (p. 53, 54) A way to write the nonanticipativity constraint is to require that x_k = ∑_{i=1}^K p_i x_i, k = 1, ..., K (2.84). Define linear operator P: X → X as Px := (∑ p_i x_i, ..., ∑ p_i x_i). Constraint (2.84) can be compactly written as x = Px. P is the orthogonal projection operator ... onto its subspace L. (2.85) defines scalar product. Another way to algebraically express nonanticipativity... x₁ = x₂, ..., x_{K-1}=x_K. (2.87). Dualization of Nonanticipativity Constraints: Assign Lagrange multipliers λ_k ... Lagrangian L(x, λ) := ∑ p_k F(x_k, ω_k) + ∑ p_k λ_k^T (x_k - ∑ p_i x_i).
[^29]: (p. 55) Assume ∑ p_j λ_j = 0, or Pλ = 0. Dualization of problem (2.80) with respect to the nonanticipativity constraints takes the form: Max {D(λ) := inf L(x, λ)} s.t. Pλ = 0. (2.88). Under the condition Pλ = 0, the Lagrangian can be written simply as L(x, λ) = ∑ p_k (F(x_k, ω_k) + λ_k^T x_k). Lagrangian can be split into K components: L(x, λ) = ∑ p_k L_k(x_k, λ_k), where L_k(x_k, λ_k) := F(x_k, ω_k) + λ_k^T x_k. It follows that D(λ) = ∑ p_k D_k(λ_k), where D_k(λ_k) := inf_{x_k ∈ X} L_k(x_k, λ_k).
[^30]: (p. 56) Nonanticipativity Duality for General Distributions. Write problem (2.61) in the form Min {f(x) := E[ F(x, w)]} (2.90). Let X be a linear decomposable space of measurable mappings from Ω to Rⁿ. Use X := Lp(Ω, F, P; Rⁿ). Write problem (2.90) in the equivalent form Min E[F(x(ω), ω)] s.t. x ∈ L (2.91), where L is a linear subspace of X formed by mappings x : Ω → Rⁿ which are constant almost everywhere, i.e., L := {x ∈ X : x(ω) = x for some x ∈ Rⁿ}.
[^31]: (p. 57) Consider the dual X* := Lq(Ω, F, P; Rⁿ). Define scalar product (λ, x) := E [λᵀx] = ∫ λ(ω)ᵀx(ω)dP(ω). Consider the projection operator P : X → L defined as [Px](ω) = E[x]. Clearly L is formed by such x ∈ X that Px = x. Note that (λ, Px) = E [λ]ᵀ E [x] = (P*λ, x), where P* is a projection operator [P*λ](ω) = E[λ] from X* onto its subspace formed by constant a.e. mappings. Lagrangian: L(x, λ) := E[F(x(ω), ω)] + E [λᵀ(x - E[x])]. Note that E [λᵀ(x - E[x])] = (λ, x - Px) = (λ - P*λ, x). Set P*λ = 0, in which case L(x, λ) = E [F(x(ω), ω) + λ(ω)ᵀx(ω)] for E[λ] = 0. (2.92). Dual problem: Max {D(λ) := inf L(x, λ)} s.t. E[λ] = 0. (2.93). By interchangeability principle (Theorem 7.80): inf_{x∈X} E[F(x, ω) + λ(ω)ᵀx(ω)] = E[inf_{x∈Rⁿ}(F(x, ω) + λ(ω)ᵀx(ω))]. Consequently, D(λ) = E[D_{λ(ω)}], where D_{λ(ω)} := inf_{x∈Rⁿ} (λ(ω)ᵀx + F(x, ω)) = sup_{x∈Rⁿ} (-λ(ω)ᵀx - F(x, ω)) = -F_ω^*(-λ(ω)). (2.94)
[^32]: (p. 58) Optimal value of (2.91) ≥ optimal value of (2.93). No duality gap and both have optimal solutions x, λ iff (x, λ) is a saddle point of L(x, λ) defined in (2.92). First condition in saddle point (x ∈ arg min L(x, λ)) equivalent to x(ω) = x and x ∈ arg min_{x∈Rⁿ} {F(x, ω) + λ(ω)ᵀx} a.e. ω ∈ Ω (2.96). Second condition (λ ∈ arg max L(x, λ) s.t. E[λ]=0). Assume problem is convex. Second condition in (2.96) holds iff λ(ω) ∈ -∂F_ω(x) for a.e. ω ∈ Ω. Together with E[λ] = 0 this means 0 ∈ E [∂F_ω(x)]. (2.97). Theorem 2.25. Suppose F(x, ω) is random lower semicontinuous, X is convex/closed, F(·, ω) is convex. Then no duality gap between (2.90) and (2.93) and both have optimal solutions iff there exists x ∈ Rⁿ satisfying (2.97). In that case, x is optimal for (2.90) and a measurable selection λ(ω) ∈ -∂F_ω(x) such that E[λ] = 0 is optimal for (2.93). Theorem 2.26. Suppose (i) F random lower semicontinuous, (ii) X convex/closed, (iii) F(·, ω) convex, (iv) problem (2.90) has optimal solution x such that x ∈ int(dom f). Then no duality gap, dual (2.93) has optimal solution λ.
[^33]: (p. 59) Example 2.27 (Capacity Expansion Continued). Define λ_{ij}(ξ) = max{0, μ_i(ξ)-μ_j(ξ)-q_{ij}} - ∫ max{0, μ_i(ξ')-μ_j(ξ')-q_{ij}} P(dξ'). E[λ] = 0 by construction. Value of Perfect Information. Consider relaxation Min E[F(x(ω), ω)] (2.98). Obtained by removing nonanticipativity constraint from (2.91). By interchangeability (Thm 7.80), optimal value = E [inf_{x∈Rⁿ} F(x, ω)].
[^34]: (p. 60) inf E[F(x, ω)] ≥ E [inf F(x, ω)] (2.100). EVPI := inf E[F(x, ω)] - E [inf F(x, ω)]. EVPI ≥ 0. EVPI = 0 iff F(x, ω) = inf F(x, ω) for a.e. ω ∈ Ω (2.102).

<!-- END -->