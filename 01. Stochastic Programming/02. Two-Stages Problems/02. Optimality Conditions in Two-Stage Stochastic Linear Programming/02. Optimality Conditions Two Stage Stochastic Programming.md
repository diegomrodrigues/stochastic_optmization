## Capítulo 2: Condições de Otimalidade para Distribuições Gerais em Programação Linear Estocástica de Dois Estágios

### Introdução

Como explorado anteriormente, a programação linear estocástica de dois estágios busca otimizar decisões tomadas em um primeiro estágio, antes da realização de incertezas, considerando o impacto dessas decisões nos custos ótimos do segundo estágio, que ocorrem após a revelação dos dados aleatórios. O problema canônico assume a forma:

$$\
\text{Min}_{x \in \mathbb{R}^n} \quad c^T x + \mathbb{E}[Q(x, \xi)] \\
\text{s.t.} \quad Ax = b, x \geq 0,
$$

onde $Q(x, \xi)$ é o valor ótimo do problema de segundo estágio [^1]:

$$\
Q(x, \xi) = \text{Min}_{y \in \mathbb{R}^m} \quad q^T y \\
\text{s.t.} \quad Tx + Wy = h, y \geq 0.
$$

Aqui, $\xi := (q, h, T, W)$ representa os dados do problema de segundo estágio, dos quais alguns ou todos os elementos podem ser aleatórios [^1]. A função $\phi(x) := \mathbb{E}[Q(x, \xi)]$ é conhecida como a **função de custo de recurso esperado** [^4].

Para o caso em que o vetor aleatório $\xi$ possui uma distribuição de probabilidade com **suporte finito**, $\Xi = \{\xi_1, ..., \xi_K\}$, as condições de otimalidade foram estabelecidas no Teorema 2.10 [^12]. Estas condições envolvem a existência de multiplicadores de Lagrange $\pi_k$ para cada cenário $k$, associados às restrições do problema dual de segundo estágio, e um multiplicador $\mu$ para as restrições de primeiro estágio, satisfazendo [^12]:

$$\
\sum_{k=1}^K p_k T_k^T \pi_k + A^T \mu \leq c, \\
\bar{x}^T \left( c - \sum_{k=1}^K p_k T_k^T \pi_k - A^T \mu \right) = 0,
$$

onde $\pi_k \in D(\bar{x}, \xi_k)$, sendo $D(x, \xi_k)$ o conjunto de soluções ótimas do problema dual (2.3) para o cenário $\xi_k$ [^12]. Essas condições derivam da caracterização do subdiferencial da função de custo esperado $\phi(\cdot)$, que no caso discreto é dada por $\partial \phi(x_0) = \sum_{k=1}^K p_k \partial Q(x_0, \xi_k)$ [^4], onde $\partial Q(x_0, \xi_k) = -T_k^T D(x_0, \xi_k)$ [^5].

No entanto, quando lidamos com **distribuições gerais** para os dados $\xi$, a análise se torna mais complexa. Condições adicionais são necessárias para garantir propriedades cruciais como a subdiferenciabilidade da função de custo esperado $\phi(\cdot)$ e a existência de multiplicadores de Lagrange que permitam a aplicação das condições de otimalidade [^14]. Este capítulo foca precisamente nessas condições para distribuições gerais, estendendo a análise para além do caso discreto. Investigaremos as propriedades da função $\phi(\cdot)$ e derivaremos as condições necessárias e suficientes para a otimalidade, destacando o papel de funções mensuráveis que representam os multiplicadores de Lagrange no espaço de probabilidade subjacente [^14].

### Conceitos Fundamentais

#### Propriedades da Função de Custo Esperado para Distribuições Gerais

A análise de otimalidade para distribuições gerais depende fundamentalmente das propriedades da função de custo esperado $\phi(x) = \mathbb{E}[Q(x, \xi)]$. Para que $\phi(x)$ seja bem definida, precisamos garantir que $Q(x, \cdot)$ seja mensurável e que a expectativa seja finita (ou pelo menos que $\mathbb{E}[Q(x, \xi)^+]$ ou $\mathbb{E}[(-Q(x, \xi))^+]$ seja finita) [^7]. A função $Q(x, \cdot)$ é, de fato, mensurável como o valor ótimo de um problema de programação linear [^7].

Condições adicionais sobre a estrutura do problema são frequentemente impostas para garantir propriedades mais fortes de $\phi(\cdot)$, como convexidade e continuidade. Uma condição importante é a de **recurso fixo**, onde a matriz $W$ é determinística [^7]. Sob a condição de recurso fixo e assumindo que $\mathbb{E}[\|q\| \|h\|] < +\infty$ e $\mathbb{E}[\|q\| \|T\|] < +\infty$ (condição (2.28)) [^9], e que para quase todo $q$ o conjunto dual factível $\Pi(q) = \{\pi : W^T \pi \leq q\}$ é não vazio [^9], a função de custo esperado $\phi(x)$ é bem definida, $\phi(x) > -\infty$ para todo $x \in \mathbb{R}^n$, convexa, semicontínua inferiormente e Lipschitz contínua em seu domínio [^9]. O domínio de $\phi$ é dado por:

> **Definição (Domínio de $\phi$ sob Recurso Fixo):**
>
> $$ \text{dom } \phi = \{x \in \mathbb{R}^n : h - Tx \in \text{pos } W \text{ w.p. } 1\} $$ [^9], [^10].
> Onde $\text{pos } W := \{z: z = Wy, y \geq 0\}$ é o cone poliédrico convexo gerado pelas colunas de $W$ [^3]. Esta condição (2.30) significa que o problema de segundo estágio deve ser factível com probabilidade 1.

#### Subdiferencial da Função de Custo Esperado

A caracterização das condições de otimalidade requer o cálculo do subdiferencial $\partial \phi(x)$. Para distribuições gerais, sob certas condições, o subdiferencial pode ser expresso em termos da expectativa dos subdiferenciais de $Q(x, \xi)$.

> **Proposição 2.8 (Adaptada):** Suponha que a função de custo esperado $\phi(\cdot)$ seja própria e que seu domínio tenha interior não vazio. Então, para qualquer $x_0 \in \text{dom } \phi$:
>
> $$ \partial \phi(x_0) = -\mathbb{E} [T^T D(x_0, \xi)] + N_{\text{dom } \phi}(x_0) $$ [^11].
> Onde $D(x, \xi) := \text{arg max}_{\pi \in \Pi(q)} \pi^T (h - Tx)$ é o conjunto de soluções ótimas do problema dual (2.3) [^2], [^11], e $N_{\text{dom } \phi}(x_0)$ é o cone normal ao domínio de $\phi$ em $x_0$. A expectativa $\mathbb{E}[\cdot]$ é tomada sobre a distribuição de $\xi = (q, h, T, W)$.

Esta fórmula (2.34) generaliza a expressão do caso discreto (2.16). Note a presença do termo do cone normal $N_{\text{dom } \phi}(x_0)$, que captura as restrições implícitas no domínio da função de custo esperado. A existência da expectativa $\mathbb{E} [T^T D(x_0, \xi)]$ requer condições de integrabilidade apropriadas.

#### Condições de Otimalidade para Distribuições Gerais

As condições de otimalidade para o problema de dois estágios (2.1)-(2.2) com distribuições gerais podem ser formuladas usando o subdiferencial $\partial \phi(x)$ e o cone normal ao conjunto factível $X := \{x : Ax = b, x \geq 0\}$. A condição geral de otimalidade para minimizar $c^T x + \phi(x)$ sobre $x \in X$ é [^12]:

$$ 0 \in c + \partial \phi(\bar{x}) + N_X(\bar{x}) $$

onde $N_X(\bar{x})$ é o cone normal a $X$ em $\bar{x}$ e $\bar{x}$ é uma solução ótima. Substituindo a expressão para $\partial \phi(\bar{x})$ de (2.34) e sob condições técnicas adicionais, obtemos o resultado central.

> **Teorema 2.11:** Seja $\bar{x}$ uma solução factível do problema (2.1)–(2.2), i.e., $\bar{x} \in X$. Suponha que a função de custo esperado $\phi(\cdot)$ seja própria, que $\text{int}(\text{dom } \phi) \cap X$ seja não vazio, e que a condição técnica $N_{\text{dom } \phi}(\bar{x}) \subset N_X(\bar{x})$ seja satisfeita. Então, $\bar{x}$ é uma solução ótima do problema (2.1)–(2.2) se e somente se existem uma **função mensurável** $\pi(\omega) \in D(\bar{x}, \xi(\omega))$, $\omega \in \Omega$, e um vetor $\mu \in \mathbb{R}^m$ (onde $m$ é o número de linhas de $A$) tais que:
>
> $$ \mathbb{E}[T^T \pi] + A^T \mu \leq c, $$
> $$ \bar{x}^T (c - \mathbb{E}[T^T \pi] - A^T \mu) = 0. $$ [^14]

Este teorema é a generalização direta do Teorema 2.10 para distribuições contínuas ou mistas. Os principais elementos a notar são:
1.  A existência de uma **função mensurável** $\pi(\omega)$ que representa os multiplicadores de Lagrange do segundo estágio para cada realização $\xi(\omega)$. Isso contrasta com o conjunto finito de vetores $\pi_k$ no caso discreto. $\pi(\omega)$ é uma seleção mensurável do conjunto de soluções ótimas duais $D(\bar{x}, \xi(\omega))$.
2.  As condições de otimalidade envolvem a **expectativa** dos termos relacionados aos multiplicadores de segundo estágio, $\mathbb{E}[T^T \pi]$.
3.  A necessidade de **condições técnicas adicionais**. A condição $N_{\text{dom } \phi}(\bar{x}) \subset N_X(\bar{x})$ é crucial para eliminar o termo $N_{\text{dom } \phi}(\bar{x})$ da condição de otimalidade geral (derivada de (2.41) no contexto original) [^14]. Esta condição é satisfeita, por exemplo, se $\bar{x} \in \text{int}(\text{dom } \phi)$ (pois $N_{\text{dom } \phi}(\bar{x}) = \{0\}$) ou no caso de **recurso relativamente completo**, onde $X \subset \text{dom } \phi$ [^14]. Se a condição de recurso relativamente completo não for satisfeita, a análise pode requerer levar em conta o cone normal ao domínio de $\phi(\cdot)$, o que geralmente exige técnicas de análise funcional mais avançadas [^14].

$\blacksquare$ *(A prova segue da condição geral $0 \in c + \partial \phi(\bar{x}) + N_X(\bar{x})$ usando a caracterização do subdiferencial (2.34) e a condição $N_{\text{dom } \phi}(\bar{x}) \subset N_X(\bar{x})$ para simplificar a expressão $0 \in c - \mathbb{E}[T^T \pi] + N_{\text{dom } \phi}(\bar{x}) + N_X(\bar{x})$ para $0 \in c - \mathbb{E}[T^T \pi] + N_X(\bar{x})$, que é então reescrita usando a definição de cone normal $N_X(\bar{x}) = \{A^T \mu - h : h \geq 0, h^T \bar{x} = 0\}$ como as condições do teorema [^14], [^13])*

#### Caso Especial: Matriz T Determinística

Uma simplificação importante ocorre quando a matriz de tecnologia $T$ é determinística (não aleatória).

> **Teorema 2.12:** Seja $\bar{x}$ uma solução factível do problema (2.1)–(2.2). Suponha que as premissas da Proposição 2.7 sejam satisfeitas (em particular, recurso fixo e condição (2.28)), que $\text{int}(\text{dom } \phi) \cap X$ seja não vazio, e que a matriz $T$ seja determinística. Então, $\bar{x}$ é uma solução ótima do problema (2.1)–(2.2) se e somente se existem uma função mensurável $\pi(\omega) \in D(\bar{x}, \xi(\omega))$, $\omega \in \Omega$, e um vetor $\mu \in \mathbb{R}^m$ tais que:
>
> $$ T^T \mathbb{E}[\pi] + A^T \mu \leq c, $$
> $$ \bar{x}^T (c - T^T \mathbb{E}[\pi] - A^T \mu) = 0. $$ [^14]

Neste caso, como $T$ é determinístico, a expectativa $\mathbb{E}[T^T \pi]$ simplifica para $T^T \mathbb{E}[\pi]$ [^15]. A prova deste teorema envolve mostrar que, sob essas condições, o termo do cone normal $N_{\text{dom } \phi}(\bar{x})$ pode ser incorporado na expectativa. Especificamente, mostra-se que $N_{\text{dom } \phi}(\bar{x}) = -T^T (\Pi_0 \cap L^\perp)$, onde $\Pi_0 = \{\pi : W^T \pi \leq 0\}$ é o cone de recessão de $\Pi(q)$ e $L$ é um subespaço linear relacionado ao domínio [^15]. Elementos de $\Pi_0 \cap L^\perp$ pertencem ao cone de recessão de $D(\bar{x}, \xi)$ para todo $\xi$, permitindo que o termo $N_{\text{dom } \phi}(\bar{x})$ seja absorvido em $-T^T \mathbb{E}[D(\bar{x}, \xi)]$ [^15].

$\blacksquare$ *(A prova detalhada encontra-se na referência [^15])*

### Conclusão

A transição das condições de otimalidade de problemas de programação linear estocástica de dois estágios com distribuições discretas para distribuições gerais introduz complexidades significativas. Enquanto o caso discreto envolve somas finitas e um conjunto finito de multiplicadores duais $\pi_k$, o caso geral requer a consideração de expectativas e a existência de uma **função mensurável de multiplicadores duais** $\pi(\omega)$.

Demonstramos, com base no Teorema 2.11 [^14], que sob condições apropriadas (incluindo a propriedade da função de custo esperado $\phi(\cdot)$ e uma condição técnica sobre os cones normais), a otimalidade é caracterizada por desigualdades envolvendo $\mathbb{E}[T^T \pi]$ e o multiplicador de primeiro estágio $\mu$. Essas condições generalizam as condições KKT para o contexto estocástico com distribuições gerais. A condição técnica $N_{\text{dom } \phi}(\bar{x}) \subset N_X(\bar{x})$ é crucial e é satisfeita em casos importantes como otimalidade no interior do domínio ou recurso relativamente completo. O caso especial com matriz $T$ determinística (Teorema 2.12 [^14]) simplifica as condições, trocando $\mathbb{E}[T^T \pi]$ por $T^T \mathbb{E}[\pi]$. A compreensão dessas condições é essencial para o desenvolvimento de algoritmos e a análise teórica de problemas estocásticos com estruturas de dados mais gerais.

### Referências

[^1]: Capítulo 2, Seção 2.1.1, p. 27
[^2]: Capítulo 2, Proposição 2.2, p. 28
[^3]: Capítulo 2, Seção 2.1.1, p. 29
[^4]: Capítulo 2, Seção 2.1.2, p. 30
[^5]: Capítulo 2, Proposição 2.2 e (2.18), pp. 28, 31
[^6]: Capítulo 2, Seção 2.1.3, p. 32
[^7]: Capítulo 2, Seção 2.1.3, p. 33
[^8]: Capítulo 2, Seção 2.1.3, p. 34
[^9]: Capítulo 2, Proposição 2.7, p. 35
[^10]: Capítulo 2, Proposição 2.7 e (2.30), pp. 35, 36
[^11]: Capítulo 2, Proposição 2.8 e (2.34), p. 37
[^12]: Capítulo 2, Seção 2.1.4, Teorema 2.10 e (2.37), (2.38), p. 38
[^13]: Capítulo 2, Seção 2.1.4, (2.39), p. 39
[^14]: Capítulo 2, Seção 2.1.4, Teorema 2.11, Teorema 2.12 e discussão, p. 40
[^15]: Capítulo 2, Prova do Teorema 2.12, p. 41
<!-- END -->