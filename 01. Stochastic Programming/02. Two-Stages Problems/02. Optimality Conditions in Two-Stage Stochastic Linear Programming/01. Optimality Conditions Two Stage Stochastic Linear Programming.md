## Capítulo 3: Condições de Otimalidade e Dualidade para Programação Linear Estocástica de Dois Estágios com Distribuições Discretas

### Introdução

Em continuidade à nossa análise de problemas de programação estocástica de dois estágios, este capítulo foca nas condições que caracterizam uma solução ótima para o caso específico, mas fundamental, de **programação linear estocástica de dois estágios (two-stage stochastic linear programming)** quando o vetor aleatório $\\xi$ possui uma distribuição de probabilidade discreta com suporte finito. Como vimos anteriormente [^1, ^2], o problema pode ser formulado como:
$$ \\text{Min}_{x \\in \\mathbb{R}^n} \\quad c^T x + \\mathbb{E}[Q(x, \\xi)] $$
$$ \\text{s.t.} \\quad Ax = b, x \\ge 0 $$
onde $Q(x, \\xi)$ é o valor ótimo do problema de segundo estágio:
$$ Q(x, \\xi) = \\text{Min}_{y \\in \\mathbb{R}^m} \\quad q^T y $$
$$ \\text{s.t.} \\quad Tx + Wy = h, y \\ge 0 $$
Aqui, $\\xi := (q, h, T, W)$ representa os dados do problema de segundo estágio, que podem ser aleatórios [^3]. Quando a distribuição de $\\xi$ tem suporte finito $\\Xi = \\{\\xi_1, ..., \\xi_K\\}$ com probabilidades $p_k > 0$, $k = 1, ..., K$, a função de custo esperado, ou **expected recourse function**, $\\phi(x) := \\mathbb{E}[Q(x, \\xi)]$, torna-se [^17]:
$$ \\phi(x) = \\sum_{k=1}^K p_k Q(x, \\xi_k) $$
O problema de otimização (2.1) pode então ser reescrito como (2.35) [^46]:
$$ \\text{Min}_{x} \\quad c^T x + \\sum_{k=1}^K p_k Q(x, \\xi_k) $$
$$ \\text{s.t.} \\quad Ax = b, x \\ge 0 $$
Como estabelecido na Proposição 2.3 [^20], sob a condição de que $\\phi(\\cdot)$ tenha um valor finito em pelo menos um ponto $x \\in \\mathbb{R}^n$, a função $\\phi(\\cdot)$ é **polyhedral** (e, portanto, convexa). Este capítulo irá explorar as condições necessárias e suficientes para que um vetor de decisão de primeiro estágio $\\bar{x}$ seja ótimo para este problema. Faremos uso extensivo dos conceitos de **subgradient** da função de recurso esperada $\\phi(x)$ e do **normal cone** ao conjunto viável $X = \\{x : Ax = b, x \\ge 0\\}$ [^48]. Adicionalmente, derivaremos o problema **dual** associado, utilizando a formulação Lagrangiana do problema extenso equivalente, fornecendo uma perspectiva complementar e ferramentas para análise.

### Conceitos Fundamentais

#### Subdiferencial da Função de Recurso Esperada

A caracterização das condições de otimalidade depende crucialmente da noção de subdiferencial da função $\\phi(x)$. Expandindo o conceito apresentado na Proposição 2.2 [^9], o subdiferencial da função de valor do segundo estágio $Q(\\cdot, \\xi)$ em um ponto $x_0$ onde $Q(x_0, \\xi)$ é finito é dado por (2.7):
$$ \\partial Q(x_0, \\xi) = -T^T \\mathcal{D}(x_0, \\xi) $$
onde $\\mathcal{D}(x, \\xi)$ é o conjunto das soluções ótimas $\\pi$ do problema dual do segundo estágio (2.3) [^4, ^10]:
$$ \\mathcal{D}(x, \\xi) := \\text{arg max}_{\\pi} \\{ \\pi^T (h - Tx) : W^T \\pi \\le q \\} $$
Para o caso de distribuições discretas, a Proposição 2.3 [^21] estabelece que o subdiferencial da função de recurso esperada $\\phi(x)$ em $x_0 \\in \\text{dom } \\phi$ é a soma ponderada dos subdiferenciais das funções de valor do segundo estágio para cada cenário $\\xi_k$:
$$ \\partial \\phi(x_0) = \\sum_{k=1}^K p_k \\partial Q(x_0, \\xi_k) = \\sum_{k=1}^K p_k (-T_k^T \\mathcal{D}(x_0, \\xi_k)) $$
Esta fórmula (2.16) [^21] segue de argumentos de dualidade e do teorema de Moreau-Rockafellar, aplicado à soma de funções poliédricas (convexas), não necessitando de condições de regularidade adicionais [^22]. Cada $\\partial Q(x_0, \\xi_k)$ é dado por (2.18) [^23]:
$$ \\partial Q(x_0, \\xi_k) = -T_k^T \\text{arg max}_{\\pi} \\{ \\pi^T (h_k - T_k x_0) : W_k^T \\pi \\le q_k \\} $$

#### Condições de Otimalidade

As condições de otimalidade para o problema (2.35) podem ser derivadas da teoria geral de otimização convexa. Seja $\\bar{x}$ uma solução viável, i.e., $\\bar{x} \\in X = \\{x : Ax = b, x \\ge 0\\}$ [^48], tal que $\\phi(\\bar{x})$ é finito. Uma condição necessária e suficiente para $\\bar{x}$ ser uma solução ótima é que o vetor zero pertença à soma do gradiente (ou subdiferencial) da função objetivo $c^T x + \\phi(x)$ e o cone normal ao conjunto viável $X$ em $\\bar{x}$, denotado por $N_X(\\bar{x})$ [^51]. Matematicamente, temos (2.38):
$$ 0 \\in c + \\partial \\phi(\\bar{x}) + N_X(\\bar{x}) $$
O **normal cone** $N_X(\\bar{x})$ ao conjunto poliédrico $X$ em $\\bar{x}$ é o conjunto de vetores $v$ tais que $v^T (x - \\bar{x}) \\le 0$ para todo $x \\in X$. Para $X$ definido por $Ax = b, x \\ge 0$, ele pode ser caracterizado como [^52]:
$$ N_X(\\bar{x}) = \\{A^T \\mu - h : h \\ge 0, h^T \\bar{x} = 0, \\mu \\in \\mathbb{R}^m \\} $$
onde $\\mu$ são os multiplicadores associados às restrições de igualdade $Ax=b$ e $h$ são os multiplicadores associados às restrições de não-negatividade $x \\ge 0$, satisfazendo a condição de **complementary slackness** $h^T \\bar{x} = 0$.

Substituindo a expressão para $\\partial \\phi(\\bar{x})$ (2.16) [^21] e a caracterização de $N_X(\\bar{x})$ (2.39) [^52] na condição geral (2.38), obtemos as condições de otimalidade detalhadas, formalizadas no Teorema 2.10.

> **Theorem 2.10.** [^49] Seja $\\bar{x}$ uma solução viável do problema (2.1)–(2.2) com distribuição discreta, i.e., $\\bar{x} \\in X$ e $\\phi(\\bar{x})$ é finito. Então $\\bar{x}$ é uma solução ótima se, e somente se, existem vetores $\\pi_k \\in \\mathcal{D}(\\bar{x}, \\xi_k)$ para $k = 1, ..., K$, e um vetor $\\mu \\in \\mathbb{R}^m$ (associado a $Ax=b$) tais que as seguintes condições (2.37) [^50] são satisfeitas:
> 1.  (Viabilidade Dual) $\\sum_{k=1}^K p_k T_k^T \\pi_k + A^T \\mu \\le c$
> 2.  (Complementary Slackness) $\\bar{x}^T (c - \\sum_{k=1}^K p_k T_k^T \\pi_k - A^T \\mu) = 0$

*Prova.* A condição $0 \\in c + \\partial \\phi(\\bar{x}) + N_X(\\bar{x})$ [^51] é equivalente à existência de $g \\in \\partial \\phi(\\bar{x})$ e $v \\in N_X(\\bar{x})$ tais que $c + g + v = 0$. Usando (2.16) [^21], existe $g = -\\sum_{k=1}^K p_k T_k^T \\pi_k$ com $\\pi_k \\in \\mathcal{D}(\\bar{x}, \\xi_k)$. Usando (2.39) [^52], existe $v = A^T \\mu - h$ com $h \\ge 0$ e $h^T \\bar{x} = 0$. Substituindo em $c+g+v=0$, obtemos $c - \\sum_{k=1}^K p_k T_k^T \\pi_k + A^T \\mu - h = 0$, ou seja, $c - \\sum_{k=1}^K p_k T_k^T \\pi_k + A^T \\mu = h$. Como $h \\ge 0$, isso implica a primeira condição $\\sum_{k=1}^K p_k T_k^T \\pi_k + A^T \\mu \\le c$. Multiplicando por $\\bar{x}^T \\ge 0$, temos $\\bar{x}^T (c - \\sum_{k=1}^K p_k T_k^T \\pi_k - A^T \\mu) = \\bar{x}^T h$. Como $h^T \\bar{x} = 0$, obtemos a segunda condição de complementary slackness $\\bar{x}^T (c - \\sum_{k=1}^K p_k T_k^T \\pi_k - A^T \\mu) = 0$. Estas duas relações são equivalentes às condições (2.37) [^50]. $\\blacksquare$

As condições do Teorema 2.10 são análogas às condições de Karush-Kuhn-Tucker (KKT) para problemas de otimização com restrições. Elas exigem que, na solução ótima $\\bar{x}$, exista um conjunto de multiplicadores duais $\\pi_k$ (soluções ótimas dos problemas duais de segundo estágio) e $\\mu$ (multiplicadores das restrições de primeiro estágio) que satisfaçam a viabilidade dual e a condição de folga complementar.

#### Dualidade via Formulação Extensa

Uma perspectiva alternativa para derivar as condições de otimalidade e entender a estrutura dual do problema é considerar a formulação como um único problema de programação linear de grande escala, frequentemente chamado de **deterministic equivalent problem** [^19, ^53]. Para o caso discreto, este problema é dado por (2.40):
$$ \\text{Min}_{x, y_1, ..., y_K} \\quad c^T x + \\sum_{k=1}^K p_k q_k^T y_k $$
$$ \\text{s.t.} \\quad Ax = b $$
$$ \\quad T_k x + W_k y_k = h_k, \\quad k = 1, ..., K $$
$$ \\quad x \\ge 0, \\quad y_k \\ge 0, \\quad k = 1, ..., K $$
Podemos construir o **Lagrangian** associado a este problema introduzindo multiplicadores duais $\\mu$ para as restrições $Ax=b$ e $\\pi_k$ para as restrições $T_k x + W_k y_k = h_k$. O Lagrangian é [^54]:
$$ L(x, y_1, ..., y_K; \\mu, \\pi_1, ..., \\pi_K) = c^T x + \\sum_{k=1}^K p_k q_k^T y_k - \\mu^T (Ax - b) - \\sum_{k=1}^K p_k \\pi_k^T (T_k x + W_k y_k - h_k) $$
Note que, por conveniência e para alinhar com a derivação anterior, os multiplicadores $\\pi_k$ foram escalados por $p_k$ na referência [^54], mas a forma final do dual e das condições de otimalidade é consistente. Reagrupando os termos:
$$ L = (c^T - \\mu^T A - \\sum_{k=1}^K p_k \\pi_k^T T_k) x + \\sum_{k=1}^K p_k (q_k^T - \\pi_k^T W_k) y_k + \\mu^T b + \\sum_{k=1}^K p_k \\pi_k^T h_k $$
O problema **dual** é obtido maximizando o ínfimo do Lagrangian em relação às variáveis primais $(x \\ge 0, y_k \\ge 0)$. Para que o ínfimo seja finito, os coeficientes de $x$ e $y_k$ devem ser não-negativos (ou melhor, as expressões transpostas devem ser $\\ge 0$ se $x, y_k$ forem vetores coluna):
$$ c - A^T \\mu - \\sum_{k=1}^K p_k T_k^T \\pi_k \\ge 0 \\implies \\sum_{k=1}^K p_k T_k^T \\pi_k + A^T \\mu \\le c $$
$$ q_k - W_k^T \\pi_k \\ge 0 \\implies W_k^T \\pi_k \\le q_k, \\quad k = 1, ..., K $$
Sob estas condições, o ínfimo é alcançado quando os termos em $x$ e $y_k$ são zero, resultando no problema dual [^55]:
$$ \\text{Max}_{\\mu, \\pi_1, ..., \\pi_K} \\quad b^T \\mu + \\sum_{k=1}^K p_k h_k^T \\pi_k $$
$$ \\text{s.t.} \\quad \\sum_{k=1}^K p_k T_k^T \\pi_k + A^T \\mu \\le c $$
$$ \\quad W_k^T \\pi_k \\le q_k, \\quad k = 1, ..., K $$
As condições de otimalidade de KKT para o par primal-dual (2.40) e seu dual derivado acima incluem:
1.  Viabilidade Primal: $\\bar{x}, \\bar{y}_k$ satisfazem as restrições de (2.40).
2.  Viabilidade Dual: $\\bar{\\mu}, \\bar{\\pi}_k$ satisfazem as restrições do problema dual.
3.  Complementary Slackness:
    *   $\\bar{x}^T (c - \\sum_{k=1}^K p_k T_k^T \\bar{\\pi}_k - A^T \\bar{\\mu}) = 0$
    *   $\\bar{y}_k^T (q_k - W_k^T \\bar{\\pi}_k) = 0, \\quad k = 1, ..., K$

Observamos que a condição de viabilidade dual $W_k^T \\bar{\\pi}_k \\le q_k$ [^56], juntamente com a condição de folga complementar $\\bar{y}_k^T (q_k - W_k^T \\bar{\\pi}_k) = 0$ e a viabilidade primal $T_k \\bar{x} + W_k \\bar{y}_k = h_k, \\bar{y}_k \\ge 0$, implica que $\\bar{\\pi}_k$ é uma solução ótima para o problema dual do segundo estágio (2.3) para o cenário $k$, ou seja, $\\bar{\\pi}_k \\in \\mathcal{D}(\\bar{x}, \\xi_k)$ [^10]. As outras condições de KKT, $\\sum p_k T_k^T \\bar{\\pi}_k + A^T \\bar{\\mu} \\le c$ e $\\bar{x}^T (c - \\sum p_k T_k^T \\bar{\\pi}_k - A^T \\bar{\\mu}) = 0$, coincidem exatamente com as condições (2.37) do Teorema 2.10 [^50]. Isso confirma a equivalência das abordagens via subdiferencial/cone normal e via dualidade do problema extenso.

### Conclusão

Este capítulo detalhou as condições de otimalidade para problemas de programação linear estocástica de dois estágios com distribuições discretas. Demonstramos que essas condições podem ser elegantemente formuladas utilizando o subdiferencial da função de custo esperado e o cone normal ao conjunto viável de primeiro estágio [^51]. O resultado central, expresso no Teorema 2.10 [^49], fornece um conjunto de desigualdades e condições de folga complementar que devem ser satisfeitas por uma solução ótima $\\bar{x}$ e seus multiplicadores duais associados $\\pi_k$ e $\\mu$ [^50].

Além disso, exploramos a derivação dessas condições através da perspectiva da dualidade, construindo o Lagrangian associado ao problema determinístico equivalente de grande escala [^54] e formulando o problema dual correspondente [^55]. Essa abordagem não apenas confirma as condições de otimalidade, mas também elucida a estrutura dual do problema e o significado dos multiplicadores. As condições de otimalidade aqui apresentadas são fundamentais para o desenvolvimento e a análise de algoritmos de solução para programação linear estocástica de dois estágios.

### Referências

[^1]: (2.1) Formulação geral do problema de dois estágios.
[^2]: (2.2) Definição do problema de segundo estágio $Q(x, \\xi)$.
[^3]: Definição do vetor de dados aleatórios $\\xi := (q, h, T, W)$.
[^4]: (2.3) Problema dual do segundo estágio.
[^5]: (2.4) Função $s_q(x)$ relacionada a $Q(x, \\xi)$.
[^6]: (2.5) Conjunto viável dual $\\Pi(q)$.
[^7]: (2.6) Relação de $s_q(x)$ com a função suporte de $\\Pi(q)$.
[^8]: Proposição 2.1: Convexidade e poliédricidade de $Q(\\cdot, \\xi)$.
[^9]: (2.7) Fórmula do subdiferencial $\\partial Q(x_0, \\xi)$.
[^10]: Definição de $\\mathcal{D}(x, \\xi)$ como conjunto de soluções ótimas duais.
[^11]: Prova da Proposição 2.2 via funções conjugadas.
[^12]: (2.9) Definição de positive hull, pos W.
[^13]: Relação dom $Q(\\cdot, \\xi) = \\{x : h - Tx \\in \\text{pos } W\\}$.
[^14]: (2.10) Definição do cone de recessão $\\Pi_0$.
[^15]: (2.11) Relação polar $\\Pi_0^* = \\text{pos } W$.
[^16]: (2.12) Definição da função de recurso esperada $\\phi(x)$.
[^17]: (2.13) Fórmula de $\\phi(x)$ para distribuições discretas.
[^18]: (2.14) Problema LP equivalente para calcular $\\mathbb{E}[Q(x, \\xi)]$ dado $x$.
[^19]: (2.15) Formulação LP extensa (deterministic equivalent) para o problema de dois estágios.
[^20]: Proposição 2.3: Poliédricidade de $\\phi(\\cdot)$ para distribuições discretas.
[^21]: (2.16) Fórmula do subdiferencial $\\partial \\phi(x_0)$ para distribuições discretas.
[^22]: Prova da Proposição 2.3.
[^23]: (2.18) Repetição da fórmula do subdiferencial $\\partial Q(x_0, \\xi_k)$.
[^24]: Subdiferencial para o Exemplo 2.4 (Capacity Expansion).
[^25]: Discussão sobre mensurabilidade e definição da expectativa.
[^26]: Definição de fixed recourse.
[^27]: Definição de complete recourse.
[^28]: Definição de simple recourse.
[^29]: Definição de relatively complete recourse.
[^30]: (2.24) Condição suficiente para relatively complete recourse.
[^31]: Relação entre $h - Tx \\in \\text{pos } W$ e finitude de $Q(x, \\xi)$.
[^32]: Exemplo 2.5.
[^33]: (2.25) Aplicação do Lema de Hoffman.
[^34]: (2.26) Limite superior para a função suporte $s_q(\\cdot)$.
[^35]: (2.27) Continuidade Lipschitz de $s_q(\\cdot)$.
[^36]: (2.28) Condições de momento para Proposição 2.6.
[^37]: (2.29) Condição $h - Tx \\in \\text{pos } W$ w.p. 1.
[^38]: Proposição 2.7: Propriedades de $\\phi(x)$ sob fixed recourse.
[^39]: (2.30) Definição de dom $\\phi$ sob fixed recourse.
[^40]: (2.31) Limite inferior para $s_q(h-Tx)$.
[^41]: (2.32) Condição $h - Tx \\in \\text{pos } W$ e $h - Tx' \\in \\text{pos } W$ w.p. 1.
[^42]: (2.33) Caracterização de dom $\\phi$ usando o suporte da distribuição.
[^43]: (2.34) Fórmula do subdiferencial $\\partial \\phi(x_0)$ para distribuições gerais.
[^44]: Condição de diferenciabilidade de $\\phi$.
[^45]: Proposição 2.9: Diferenciabilidade contínua sob condições de continuidade absoluta.
[^46]: (2.35) Formulação do problema com distribuições discretas.
[^47]: (2.36) Repetição da fórmula do subdiferencial $\\partial \\phi(x_0)$ para o caso discreto.
[^48]: Definição do conjunto viável $X = \\{x : Ax = b, x \\ge 0\\}$.
[^49]: Teorema 2.10: Condições de otimalidade para o caso discreto.
[^50]: (2.37) Condições explícitas do Teorema 2.10 (viabilidade dual e folga complementar).
[^51]: (2.38) Condição geral de otimalidade $0 \\in c + \\partial \\phi(\\bar{x}) + N_X(\\bar{x})$.
[^52]: (2.39) Caracterização do cone normal $N_X(\\bar{x})$.
[^53]: (2.40) Formulação LP extensa usada na derivação dual.
[^54]: Construção do Lagrangian para o problema (2.40).
[^55]: Derivação do problema dual do problema (2.40).
[^56]: Condições de otimalidade reescritas a partir do dual de (2.40).
[^57]: Teorema 2.11: Condições de otimalidade para distribuições gerais.
[^58]: Condição $N_{\\text{dom}\\phi}(\\bar{x}) \\subset N_X(\\bar{x})$.
[^59]: (2.41) Condição de otimalidade simplificada sob $N_{\\text{dom}\\phi}(\\bar{x}) \\subset N_X(\\bar{x})$.
[^60]: Teorema 2.12: Simplificação para T determinístico.
[^61]: Cálculo de $N_{\\text{dom}\\phi}(\\bar{x})$ para T determinístico e fixed recourse.
[^62]: Teorema 2.18: Condições de otimalidade para problemas poliédricos com suporte finito.
[^63]: Teorema 2.19: Condições de otimalidade para problemas poliédricos com distribuições gerais (fixed recourse).
[^64]: Dualização das restrições de não-antecipatividade.
[^65]: (2.88) Problema dual obtido pela dualização da não-antecipatividade.

<!-- END -->