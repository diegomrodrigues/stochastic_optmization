## Modelos para Aprendizagem de Probabilidades com Priors Não-Gaussianos

### Introdução
Este capítulo explora os modelos para aprendizado de probabilidades, onde o objetivo é estimar a probabilidade de ocorrência de um evento, sendo a probabilidade de sucesso *p* o valor verdadeiro desconhecido [^49]. Em continuidade aos tópicos anteriores sobre *Updating for Non-Gaussian Priors*, abordaremos como diferentes distribuições podem ser utilizadas para representar nossas crenças iniciais e como estas crenças são atualizadas à medida que novas observações são feitas [^34].

### Conceitos Fundamentais

**Modelos para Aprendizagem de Probabilidades:**
Em muitos problemas, o objetivo é aprender a probabilidade de que um certo evento ocorra, em vez do valor econômico do evento [^49]. Por exemplo, em um contexto médico, as observações podem ser simplesmente se um certo tratamento médico é bem-sucedido ou não. Tal observação pode ser modelada como uma variável aleatória de Bernoulli, que é igual a 1 (sucesso) com probabilidade *p*, e 0 (fracasso) com probabilidade 1 – *p* [^49]. A probabilidade de sucesso *p* é o valor verdadeiro desconhecido neste caso [^49].

**Distribuição Beta:**
Assumimos que *p* vem de uma distribuição beta com parâmetros $\\alpha$ e $\\beta$ [^49]. A densidade beta é dada por:
$$\nf(x|\\alpha, \\beta) = 
\\begin{cases}
\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1} & \\text{se } 0 < x < 1 \\\\
0 & \\text{caso contrário}
\\end{cases}
$$\
Onde $\\alpha$ e $\\beta$ são sempre inteiros [^49].

**Estimativa a Priori:**
Nossa estimativa a priori de *p*, usando $\\alpha = \\alpha^0$ e $\\beta = \\beta^0$, é dada por:
$$\nE(p) = \\frac{\\alpha^0}{\\alpha^0 + \\beta^0}
$$\
Assim, $\\alpha^0$ e $\\beta^0$ são pesos que, quando normalizados, nos dão as probabilidades de sucesso e fracasso, respectivamente [^49]. Se $\\alpha^0$ é grande em relação a $\\beta^0$, isso significa que acreditamos que o sucesso é mais provável do que o fracasso [^49].

**Atualização Bayesiana:**
A propriedade de conjugação se mantém e os parâmetros evoluem de acordo com as equações:
$$\\alpha^{n+1} = \\alpha^n + W_{n+1}$$\
$$\\beta^{n+1} = \\beta^n + (1 - W_{n+1})$$\
Onde as observações $W_n$ são 1 ou 0, indicando sucesso ou fracasso [^50]. Vemos que os parâmetros $\\alpha^n$ e $\\beta^n$ acompanham aproximadamente o número de sucessos e fracassos em *n* observações [^50]. Por exemplo, o parâmetro $\\alpha^n$ é o número de sucessos em *n* observações, mais uma constante a priori $\\alpha^0$ [^50].

**Interpretação dos Priors:**
Os valores a priori $\\alpha^0$ e $\\beta^0$ podem ser vistos como uma medida de nossa confiança em nossa estimativa de *p* [^50]. Valores altos de $\\alpha^0$ e $\\beta^0$ mostram que estamos muito confiantes em nossa estimativa a priori e, portanto, essa estimativa não mudará muito [^50]. Baixos valores de $\\alpha^0$ e $\\beta^0$ mostram que temos pouco conhecimento a priori sobre *p*, e nossa estimativa a priori pode ser facilmente alterada por apenas algumas observações [^51].

**Generalização Multivariada:**
O modelo beta-Bernoulli pode ser facilmente generalizado para um cenário multivariado [^51]. Suponha que, em vez de um simples valor 0/1, cada observação possa ser classificada como pertencente a uma de *K* categorias diferentes [^51]. Modelamos nossas observações como tentativas individuais de uma distribuição multinomial com *K* categorias [^51]. A probabilidade de que uma observação pertença à categoria *k* = 1, ..., *K* é $P(W_n = k) = p_k$, com cada $p_k \\in [0,1]$ e $\\sum_{k=1}^{K} p_k = 1$ [^51]. Os valores verdadeiros desconhecidos são agora as probabilidades $p_k$ [^51]. Nossa distribuição a priori é a generalização multivariada da distribuição beta, chamada distribuição de Dirichlet [^51].

### Conclusão
Os modelos para aprendizado de probabilidades, especialmente quando combinados com priors não-gaussianos, oferecem uma abordagem flexível e poderosa para estimar probabilidades de eventos [^49]. A escolha da distribuição a priori (beta, gama, etc.) deve ser feita com base nas características do problema em questão e no conhecimento prévio disponível [^49]. A atualização bayesiana permite que nossas crenças evoluam à medida que novas observações são feitas, refinando nossas estimativas e reduzindo a incerteza [^34].

### Referências
[^34]: Optimal Learning. By Warren B. Powell and Ilya O. Ryzhov. Copyright© 2018 John Wiley & Sons, Inc., p. 31-34.
[^49]: Optimal Learning. By Warren B. Powell and Ilya O. Ryzhov. Copyright© 2018 John Wiley & Sons, Inc., p. 49.
[^50]: Optimal Learning. By Warren B. Powell and Ilya O. Ryzhov. Copyright© 2018 John Wiley & Sons, Inc., p. 50.
[^51]: Optimal Learning. By Warren B. Powell and Ilya O. Ryzhov. Copyright© 2018 John Wiley & Sons, Inc., p. 51.
<!-- END -->