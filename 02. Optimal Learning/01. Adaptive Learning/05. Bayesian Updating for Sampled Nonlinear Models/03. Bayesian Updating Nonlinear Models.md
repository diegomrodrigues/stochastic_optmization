## 2.4.1 Bayesian Updating em Modelos Não Lineares Amostrados

### Introdução
Este capítulo estende a discussão sobre atualização Bayesiana para modelos onde a relação entre as entradas e saídas não é linear, um cenário comum em muitos problemas práticos [^41]. Anteriormente, focamos em modelos lineares e distribuições Gaussianas, mas agora abordaremos modelos onde a não linearidade requer uma abordagem diferente. Este cenário é especialmente relevante quando se trabalha com modelos de crença em aprendizado adaptativo, onde a capacidade de incorporar informações de experimentos é crucial para a tomada de decisões [^31].

### Conceitos Fundamentais

A atualização Bayesiana é uma técnica fundamental para incorporar novas informações em nossas crenças sobre um sistema. O processo envolve interpretar um evento como o evento em que o parâmetro é igual a um valor específico, e o novo evento é a nova informação obtida do experimento, condicionando na história dos experimentos [^41]. As equações de atualização para o vetor de probabilidade $p_r$ após executar um experimento com $x = x_n$ e observar uma resposta $y_{n+1}$ começam com o teorema de Bayes [^41]:
$$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$
onde $A$ é o evento em que $\theta = \theta_k$ e $B$ é a nova informação $y_{n+1}$ [^41].

Nos modelos não lineares, a relação entre as entradas e saídas é mais complexa, o que torna a inferência mais desafiadora [^41]. Para abordar isso, é introduzida uma técnica conhecida como *modelo de crença amostrado* [^41]. Assume-se que é dada uma função não linear $f(x|\theta)$, onde $x$ é a entrada e $\theta$ é o vetor de parâmetros. Observa-se uma resposta $Y$ e assume-se que $\theta$ é um dos conjuntos $\Theta = \{\theta_1, ..., \theta_K\}$, inicialmente com probabilidade $P[\theta = \theta_k] = p_k$ [^41]. Refere-se a $p^0 = (p_k), k = 1, ..., K$ como o *prior* [^41].

O próximo passo é projetar as equações de atualização para o vetor de probabilidade $p_r$ após executar um experimento com $x = x^n$ e observar uma resposta $y_{n+1}$ [^41]. Adaptando o teorema de Bayes para este cenário, tem-se:
$$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$
O evento $A$ é interpretado como o evento em que $\theta = \theta_k$, e $B$ como a nova informação $y_{n+1}$ [^42]. Seja $H^n$ o histórico dos experimentos, onde $H^n = (S^0, x^0, \hat{y}^1, x^1, \hat{y}^2, ..., x^{n-1}, \hat{y}^n)$ [^42]. As probabilidades de crença podem ser escritas como:
$$P_k^n = P[\theta = \theta_k|H^n]$$
O teorema de Bayes pode ser escrito onde todas as probabilidades são condicionadas em um terceiro evento $C$, como em [^42]:
$$P(A|B,C) = \frac{P(B|A,C)P(A|C)}{P(B|C)}$$
Neste contexto, o novo evento $C$ é o histórico $H^n$. Adaptando isso, obtemos:
$$P[\theta = \theta_k|y_{n+1} = y, H^n] = \frac{P[\hat{y}^{n+1} = y|\theta_k, H^n]P[\theta = \theta_k|H^n]}{P[\hat{y}^{n+1} = y|H^n]}$$
Seja $f_y(y=y|\theta)$ a distribuição da observação aleatória $\hat{y}$ dado $\theta$, ou
$$f_y(\hat{y} = y|\theta) = P[\hat{y} = y|\theta]$$
O condicionamento no histórico $H^n$ afeta a probabilidade de que $\theta$ tome um valor particular. Podemos reescrever a equação anterior como [^42]:
$$P_k^{n+1} = \frac{f_y(\hat{y}^{n+1} = y|\theta_k)P_k^n}{f_y(\hat{y}^{n+1} = y)}$$
onde
$$f_y(\hat{y}^{n+1} = y) = \sum_{k=1}^K f_y(\hat{y}^{n+1} = y|\theta_k)P_k^n$$
A distribuição de $\hat{y}^{n+1}$ depende apenas de $\theta$, então podemos remover a dependência de $H^n$ quando também estamos condicionando em $\theta$.

A atualização das probabilidades $P_k^n$ depende da distribuição $f_y(y^{n+1}|\theta_k)$, que é uma distribuição conhecida que pode ser facilmente computada a partir da estrutura do problema [^42]. Pode ser uma distribuição normal, de Poisson ou regressão logística, por exemplo [^42]. A equação (2.21) é fácil de computar (dado $f_y(y^{n+1}|\theta_k)$) quando se usa um modelo de crença amostrado [^42]. Sem o modelo de crença amostrado, a expectativa na equação (2.22) pode se tornar complexa (imagine o que acontece quando $\theta$ é um vetor) [^42]. Por outro lado, esta equação é fácil de computar para o modelo de crença amostrado, mesmo se $\theta$ for um vetor de alta dimensão [^42].

### Conclusão

Em resumo, a atualização Bayesiana para modelos não lineares amostrados envolve os seguintes passos [^42]:
1. Definir o conjunto de possíveis valores para o parâmetro $\theta$: $\{\theta_1, ..., \theta_K\}$ [^41].
2. Atribuir probabilidades *a priori* a cada valor de $\theta$: $P_k^0$ [^41].
3. Para cada nova observação $(x_{n+1}, y_{n+1})$:
   - Calcular a probabilidade condicional $f_y(y_{n+1}|\theta_k)$ para cada valor de $\theta_k$ [^42].
   - Atualizar as probabilidades *a posteriori* usando as equações (2.21) e (2.22) [^42].
4. Repetir o passo 3 para cada nova observação [^42].

Essa abordagem permite incorporar informações de experimentos em modelos não lineares de forma eficiente, mantendo a capacidade de quantificar a incerteza sobre os parâmetros do modelo. O uso de modelos de crença amostrados simplifica os cálculos, tornando a técnica aplicável a problemas de alta dimensão [^42].

### Referências
[^31]: Optimal Learning. By Warren B. Powell and Ilya O. Ryzhov
[^41]: BAYESIAN UPDATING FOR SAMPLED NONLINEAR MODELS 41
[^42]: ADAPTIVE LEARNING 42
<!-- END -->