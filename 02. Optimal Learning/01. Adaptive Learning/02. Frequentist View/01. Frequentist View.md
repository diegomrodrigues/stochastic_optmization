## A Visão Frequentista em Aprendizagem Adaptativa

### Introdução
A visão frequentista, um pilar da inferência estatística, oferece uma abordagem distinta para a formação de crenças e a estimação de parâmetros, especialmente em contextos de aprendizado adaptativo. Ao contrário da abordagem Bayesiana, que incorpora conhecimento prévio através de distribuições *a priori*, a visão frequentista se baseia exclusivamente nos resultados de experimentos repetidos para construir inferências [^31]. Este capítulo explora em profundidade os fundamentos, as técnicas e as aplicações da visão frequentista no contexto de modelos de crença, com foco em sua relevância para problemas onde o conhecimento prévio é escasso ou inexistente.

### Conceitos Fundamentais
Na visão frequentista, o objetivo é estimar um parâmetro desconhecido de um sistema ou função através da repetição de experimentos [^31]. Cada experimento produz uma observação, e o conjunto de observações é usado para formar uma **distribuição de frequência** do parâmetro estimado [^31]. É crucial notar que, nesta abordagem, o estimador do parâmetro é considerado uma **variável aleatória**, refletindo a variação inerente às observações experimentais [^31].

**Estimando a Média e a Variância**
Suponha que estamos tentando estimar a média $\\mu$ de uma variável aleatória $W$. Seja $W_n$ a *n*-ésima observação amostral. Podemos estimar $\\mu$ e a variância $\\sigma^2$ de $W$ utilizando as seguintes fórmulas [^33]:

**Estimador da Média:**
$$\\bar{\\mu}_n = \\frac{1}{n} \\sum_{m=1}^{n} W_m$$

**Estimador da Variância:**
$$\\hat{\\sigma}^2_n = \\frac{1}{n-1} \\sum_{m=1}^{n} (W_m - \\bar{\\mu}_n)^2$$

Onde $\\bar{\\mu}_n$ é a estimativa da média após *n* observações, e $\\hat{\\sigma}^2_n$ é a estimativa da variância após *n* observações.

**Expressões Recursivas**
Para fins de eficiência computacional e de atualização em tempo real, as estimativas da média e da variância podem ser expressas recursivamente [^34]:

**Média Recursiva:**
$$\\bar{\\mu}_n = \\bar{\\mu}_{n-1} + \\frac{1}{n}(W_n - \\bar{\\mu}_{n-1})$$

**Variância Recursiva:**
$$\\hat{\\sigma}^2_n = \\frac{n-2}{n-1}\\hat{\\sigma}^2_{n-1} + \\frac{1}{n}(W_n - \\bar{\\mu}_{n-1})^2, \\quad n \\geq 2$$

É importante notar que, à medida que o número de observações $n$ tende ao infinito, o estimador da variância $\\hat{\\sigma}^2_n$ converge para a variância verdadeira $\\sigma^2$ de $W$ [^33].

**Belief State Frequentista**
O estado de crença (belief state) na visão frequentista, denotado como $B^{freq,n}$, é definido como o conjunto de informações disponíveis após *n* observações [^34]:

$$B^{freq,n} = (\\bar{\\mu}_n, \\hat{\\sigma}^2_n, n)$$

Este estado de crença encapsula a estimativa da média, a estimativa da variância e o número de observações utilizadas para formar essas estimativas.

**Lei dos Grandes Números**
Um conceito fundamental que justifica o uso da visão frequentista é a **Lei dos Grandes Números**. Esta lei garante que, sob certas condições, a média amostral $\\bar{\\mu}_n$ converge para a média verdadeira $\\mu$ à medida que o tamanho da amostra $n$ aumenta [^34]. Formalmente,

$$ \\lim_{n \\to \\infty} P(|\\bar{\\mu}_n - \\mu| > \\epsilon) = 0, \\quad \\forall \\epsilon > 0$$

Além disso, o **Teorema do Limite Central (TLC)** estabelece que, para um número suficientemente grande de observações, a distribuição da média amostral se aproxima de uma distribuição normal [^34]. Isso permite que façamos inferências estatísticas sobre o parâmetro desconhecido, mesmo sem conhecer a distribuição subjacente da variável aleatória.

### Conclusão
A visão frequentista oferece uma abordagem robusta e amplamente aplicável para a estimação de parâmetros e a formação de crenças em cenários onde o conhecimento prévio é limitado [^31]. Através da repetição de experimentos e da análise das distribuições de frequência resultantes, é possível obter estimativas precisas e quantificar a incerteza associada a essas estimativas. As expressões recursivas para a média e a variância facilitam a atualização eficiente das crenças à medida que novas observações se tornam disponíveis. Embora a visão Bayesiana incorpore conhecimento *a priori*, a visão frequentista se destaca por sua objetividade e sua capacidade de fornecer inferências baseadas exclusivamente em dados experimentais.

### Referências
[^31]: Optimal Learning, By Warren B. Powell and Ilya O. Ryzhov, Copyright© 2018 John Wiley & Sons, Inc., page 31.
[^33]: Optimal Learning, By Warren B. Powell and Ilya O. Ryzhov, Copyright© 2018 John Wiley & Sons, Inc., page 33.
[^34]: Optimal Learning, By Warren B. Powell and Ilya O. Ryzhov, Copyright© 2018 John Wiley & Sons, Inc., page 34.
<!-- END -->