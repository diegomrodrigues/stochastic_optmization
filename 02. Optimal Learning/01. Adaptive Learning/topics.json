{
  "topics": [
    {
      "topic": "Belief Models",
      "sub_topics": [
        "Belief models are statistical models that capture the estimate of a function or system's response to a controllable input, along with the uncertainty in that estimate, representing a probability distribution over possible outcomes. This differs from point estimate statistical models by including a distribution over possible parameter values, which is crucial for decision-making under uncertainty. The function or system can be represented as f(x) = EF(x, W), where x is a controllable input (e.g., drug dosages, price) and W is a random variable representing uncontrollable inputs; the expectation E averages over all possible outcomes of W.",
        "Belief models can be categorized into three types: lookup tables, parametric models, and nonparametric models, each offering different trade-offs between complexity, flexibility, and the amount of data required for accurate estimation. The choice of belief model depends on the characteristics of the problem, such as the dimensionality of the input space, the availability of prior knowledge, and the computational resources available.",
        "Lookup tables are suitable for discrete sets of choices X = {x1, x2, ..., xM}, where an estimate \\u03bc\\u03b7 \\u2248 \\u03bc\\u03b1 is maintained for each x \\u2208 X, requiring the estimation of M different parameters. Parametric models are used when the set X is large or continuous, expressing the belief model as f(x0) \\u2248 EF(x, W) = \\u03a3(f\\u2208F) \\u03b8f$f(x), where $f(x) is a set of features and \\u03b8f are parameters to be estimated, reducing the number of parameters compared to lookup tables, often using linear or nonlinear models. Nonparametric models allow for creating estimates without assuming a specific functional form, using techniques like local averaging around a point x with weights inversely proportional to the distance ||x \\u2212 xn||, offering flexibility but potentially being harder to use."
      ]
    },
    {
      "topic": "Frequentist View",
      "sub_topics": [
        "The frequentist view is a statistical approach where beliefs are formed entirely from the results of experiments, without initial knowledge about parameters; estimates are obtained by repeating experiments and forming frequency distributions. In this approach, the estimate of a parameter is a random variable that reflects the variation in the observations, and the variance of the estimator can be estimated to quantify the uncertainty in the estimate. It is suitable for problems where there is no prior knowledge about the parameters, and data is readily available to form estimates through repeated experiments.",
        "The frequentist view estimates the mean of a random variable by averaging sample observations and estimates the variance using the sample variance formula. The sample mean \\u03bc\\u0304n is a random variable reflecting the variation in observations, and its variance provides a measure of the uncertainty in the estimate. The frequentist approach treats the estimate of the mean as a random variable due to its computation from random sample observations. Estimates of the mean (\\u03bc\\u0304n) and variance (\\u00f42,n) of a random variable W are calculated from sample observations W1, W2, ..., Wn using standard statistical formulas.",
        "Recursive formulas can efficiently update the estimates of the mean and variance as new data becomes available, reducing computational burden. Estimates of the mean \\u00b5 and variance of W are calculated using sample observations Wn, with the estimate of the mean given by \\u03bc\\u03b7 = (1/n) \\u03a3(m=1 to n) Wm and the estimate of the variance given by \\u00f42,n = (1/(n-1)) \\u03a3(m=1 to n) (Wm \\u2013 \\u03bc\\u03c0)2. Recursive expressions for updating the mean and variance can be written as \\u03bc\\u03b7 = (1 - 1/n) \\u03bc\\u03b7\\u22121 + (1/n) Wn and \\u00f42,n = ((n-2)/(n-1)) \\u00f42,n-1 + (1/n) (Wn \\u2013 \\u03bc\\u03b7\\u22121)2, which efficiently update the belief state with each new observation.",
        "The frequentist belief state is represented by the mean, variance, and sample size, communicating a probability distribution approximated by the normal distribution based on the law of large numbers. The belief state in the frequentist view is represented as Bfreq,n = (\\u03bc\\u03b7, \\u00f42,n, n), capturing the mean, variance, and number of observations used to estimate the parameters."
      ]
    },
    {
      "topic": "Bayesian View",
      "sub_topics": [
        "The Bayesian perspective leverages prior knowledge to inform the estimation process, using a prior distribution to represent initial beliefs about parameters. The Bayesian view treats the true parameter as a random variable with a distribution that changes as information is collected, guaranteeing a steady shrinkage of the variance. This approach is well-suited for information collection in settings where information is expensive or carries significant risk, incentivizing the use of prior knowledge to improve the accuracy of estimates.",
        "In the Bayesian view, the truth \\u03bc\\u03b1 is handled as a random variable with its own distribution, allowing for the incorporation of prior beliefs and the guarantee that the variance will steadily shrink as information is collected. Bayesian models handle the true parameter \\u03bc\\u03b1 as a random variable with an initial prior distribution (e.g., normal distribution with mean \\u03bc\\u03040 and variance \\u03c32,0), reflecting prior beliefs. As information is collected, the prior distribution is updated, guaranteeing a steady decrease in variance, which reflects increased certainty about the parameter's value.",
        "The updating equations for independent beliefs assume a normally distributed random variable and define the precision of an estimate as the inverse of its variance. Under the assumption that the random variable W is normally distributed, the precision of W (\\u03b2W) is defined as the inverse of its variance, capturing the certainty associated with observations. The updated mean and precision of the Bayesian estimate are given by combining the prior mean and precision with the information from new observations. The updated mean and precision of the estimate after observing Wn+1 are given by \\u03bc\\u03b7+1 = (\\u03b2\\u03b7\\u03bc\\u03b7 + \\u03b2WWn+1) / (\\u03b2\\u03b7 + \\u03b2W) and \\u03b2n+1 = \\u03b2\\u03b7 + \\u03b2W, where un is the estimate of the true mean \\u03bc after n observations and \\u03b2n is the precision of this estimate.",
        "The change in variance due to a single observation can be expressed through the parameter \\u1ee1\\u00b2, which is the variance of the updated mean given the previous information. The updating process can be expressed as \\u03bc\\u03b7+1 = \\u03bc\\u03b7 + \\u00f6n Z, where Z is a normally distributed random variable and \\u1ee1n is the change in the variance due to a single observation, illustrating how un evolves over the observations. The Bayesian belief state with normally distributed beliefs is given by the mean and precision, and if the prior belief about u is normally distributed, then our posterior belief after n + 1 observations is also normally distributed with mean \\u016bn+1 and precision \\u03b2\\u03b7+1. The belief state in the Bayesian view (with normally distributed beliefs) is given by BBayes,n = (\\u03bc\\u03b7, \\u03b2\\u03b7), representing the mean and precision of the belief about \\u03bc.",
        "Correlated beliefs allow the generalization of results from a single observation to other alternatives that have not been directly measured, using the covariance matrix to represent the relationships between beliefs about different choices. The Bayesian equation for updating beliefs in the presence of correlated beliefs involves the precision matrix and the Sherman-Morrison formula for inverting the covariance matrix."
      ]
    },
    {
      "topic": "Updating for Correlated Normal Priors",
      "sub_topics": [
        "Correlated beliefs are a powerful device in optimal learning, allowing generalization of a single observation's results to other alternatives that have not been directly measured, particularly useful in problems with multiple choices where beliefs about the choices are correlated. In problems with multiple choices, beliefs about different choices are often correlated, requiring consideration of the covariance between them.",
        "The covariance matrix \\u03a3n captures the covariance between beliefs about different alternatives, and the precision matrix Bn is defined as its inverse. The covariance matrix represents the covariance in our belief about \\u03bc\\u03b5 and \\u03bcy. The precision matrix Bn is defined as the inverse of the covariance matrix En.",
        "The Bayesian updating equation for correlated beliefs updates the vector of beliefs \\u03bcn using the precision matrix Bn and the observation Wn+1, incorporating the correlations between alternatives. The Bayesian equation for updating a belief vector in the presence of correlated beliefs is given by \\u03bc\\u03b7+1 = (Bn+1)\\u22121 (\\u0392\\u03b7\\u03bc\\u03b7 + \\u03b2WWn+1exn), where Bn is the precision matrix, ex is a column vector of zeroes with a 1 for element x, and Wn+1 is the scalar observation when alternative x is measured. The Bayesian equation for updating this vector in the presence of correlated beliefs is given by \\u03bc\\u03b7+1 = (Bn+1)\\u22121 (\\u0392\\u03b7\\u03bc\\u03b7 + \\u1e9eWWn+1exn),",
        "The Sherman-Morrison formula provides a way to perform these updates without explicitly inverting the covariance matrix, reducing computational complexity. It is possible to perform these updates without having to deal with the inverse of the covariance matrix, using a result known as the Sherman-Morrison formula. The Sherman-Morrison formula is [A + uuT]\\u22121 = A\\u22121 - (A-1uuT A-1) / (1+uTA-1u), used to perform updates without having to deal with the inverse of the covariance matrix, where A is an invertible matrix (such as En) and u is a column vector (such as ex). The updated precision matrix Bn+1 is given by Bn+1 = (Bn + BW exn (exn)T), where BW is a scalar giving the precision of the experimental outcome W, allowing for updates without dealing with the inverse of the covariance matrix using the Sherman-Morrison formula."
      ]
    },
    {
      "topic": "Bayesian Updating for Sampled Nonlinear Models",
      "sub_topics": [
        "Bayesian updating for sampled nonlinear models addresses instances where models are nonlinear in the parameter vector \\u03b8 by using a sampled belief model, where \\u03b8 is one of a set \\u0398 = {\\u03b81, ..., \\u03b8K} with initial probability P[\\u03b8 = \\u03b8k] = pk. Many models are nonlinear in the parameter vector \\u03b8, requiring specialized Bayesian updating techniques.",
        "Bayesian updating for sampled nonlinear models involves using Bayes' theorem to update the probability vector after running an experiment and observing a response, where the new event is the history of experiments. Bayes' theorem is used to design the updating equations for the probability vector p after running an experiment with input x = xn and observing a response yn+1. A sampled belief model assumes that \\u03b8 is one of a set of possible values \\u0398 = {\\u03b81, ..., \\u03b8K}, each with an associated probability P[\\u03b8 = \\u03b8k] = pk.",
        "The process involves interpreting the event as the event that the parameter equals a specific value, and the new event is the new information obtained from the experiment, conditioning on the history of experiments. The updating equations for the probability vector pr after running an experiment with x = xn and observing a response yn+1 start with Bayes' theorem: P(A/B) = (P(B|A)P(A)) / P(B), where A is the event that \\u03b8 = \\u03b8k and B is the new information yn+1.",
        "The new event C is our history Hn, and adapting this to our setting gives us P[\\u03b8 = \\u03b8k|yn+1 = y, Hn] = P[\\u0177n+1 = y|\\u03b8k, Hn]P[\\u03b8 = \\u03b8k|Hn] / P[\\u0177n+1 = y|Hn]. The belief probabilities can be written as P = P[\\u03b8 = \\u03b8k|Hn], where Hn is the history of experiments, and Bayes' theorem can be written as P(A/B, C) = (P(B|A, C)P(A/C)) / P(B/C), where C is our history Hn. The posterior probability P[\\u03b8 = \\u03b8k|yn+1 = y, Hn] is proportional to the product of the likelihood P[\\u0177n+1 = y|\\u03b8k, Hn] and the prior probability P[\\u03b8 = \\u03b8k|Hn], normalized by the marginal likelihood P[\\u0177n+1 = y|Hn]. The posterior probability P[\\u03b8 = \\u03b8k|yn+1 = y, Hn] is given by (P[\\u0177n+1 = y|\\u03b8k, Hn]P[\\u03b8 = \\u03b8k|Hn]) / P[\\u0177n+1 = y|Hn], where fy (y = y|0) is the distribution of the random observation \\u0177 given 0.",
        "The distribution of \\u0177n+1 depends only on 0, so the dependence on Hn can be dropped when conditioning on 0, simplifying the updating equations and making them easier to compute even when \\u03b8 is a high-dimensional vector."
      ]
    },
    {
      "topic": "Updating for Non-Gaussian Priors",
      "sub_topics": [
        "Updating for non-Gaussian priors is important when the normal distribution is not suitable for representing prior beliefs or sampling distributions, such as when dealing with positive or discrete values. The normal-normal model is not always suitable, particularly when observations are restricted to certain values (e.g., positive waiting times or discrete outcomes).",
        "The gamma-exponential model is used when observations are continuous and positive, assuming that the sampling distribution governing service times is exponential with parameter \\u5165, and \\u5165 comes from a gamma distribution with parameters a and b. The gamma-exponential model is used for continuous and positive observations, where the service rate is the unknown value to estimate. The gamma-exponential model is appropriate for continuous, positive observations, where the sampling distribution is exponential with parameter \\u03bb and the prior distribution for \\u03bb is gamma.",
        "The gamma-Poisson model is similar to the gamma-exponential model, but the observations are now assumed to be discrete. The gamma-Poisson model is suitable for discrete observations, where the sampling distribution is Poisson with rate \\u03bb and the prior distribution for \\u03bb is gamma.",
        "The Pareto-uniform model is used to estimate the maximum of a uniform distribution, where W is uniform on the interval [0, B] and B comes from a Pareto distribution with parameters b > 0 and a > 1. In the Pareto-uniform model, W is uniform on the interval [0, B], where B is unknown, and the problem is to estimate the maximum of a uniform distribution.",
        "Models for learning probabilities are used to learn the probability that a certain event will occur, where the success probability p is the unknown true value in this case. In models for learning probabilities, the objective is to learn the probability that a certain event will occur, and the success probability p is the unknown true value in this case.",
        "The beta-Bernoulli model is used, and the conjugacy property holds, and the parameters evolve according to the equations an+1 = an + Wn+1, \\u03b2n+1 = \\u03b2n + (1 \\u2212 Wn+1), The beta-Bernoulli model can be easily generalized to a multivariate setting, where each observation can be classified as belonging to one of K different categories. The Dirichlet distribution is a multivariate generalization of the beta distribution, used when observations can be classified into one of K different categories, with a vector of parameters a = (a1, ..., aK) satisfying ak \\u2265 0 for all k. Conjugacy property ensures that the posterior distribution is of the same type as the prior distribution, simplifying updating.",
        "In learning an unknown variance, both the true mean \\u00b5 and the precision BW are unknown, and both of these quantities are learned at the same time. The Normal-Gamma distribution is a joint prior distribution on (\\u03bc, \\u03b2W), where the marginal distribution of BW is Gamma(a, b) and the conditional distribution of \\u03bc given BW = r is N(\\u03b8, \\u03c4r), used when both the true mean \\u00b5 and the precision BW are unknown. With a normal-gamma prior, the posterior distribution of (\\u03bc, \\u03b2W) is normal-gamma with updated parameters, allowing for the learning of both the mean and variance from a single observation. The joint density of (\\u03bc, \\u03b2W) is written as f(x,r|\\u03b8, \\u03c4, \\u03b1, b) = 1/\\u221a2\\u03c0\\u03c4-1\\u03b3-1 b(br)a-le-br / \\u0393(\\u03b1) e-(x-\\u03b8)2 / 2\\u03c4-1\\u03b3-1."
      ]
    },
    {
      "topic": "Updating Equations for Independent Beliefs",
      "sub_topics": [
        "When updating beliefs, precision is used, which is the reciprocal of the variance and captures the noise in the ability to observe the true value, meaning smaller variance indicates more precise observations. Under the assumption that the random variable W is normally distributed, the precision of W (\\u03b2W) is defined as the inverse of its variance, capturing the certainty associated with observations.",
        "After observing new data, the updated mean and precision of the estimate are calculated by combining the prior mean and precision with the new observation and its precision, weighting each according to their respective precisions. Bayesian updating equations combine prior beliefs (\\u03bcn, \\u03b2n) with new observations (Wn+1) to update the mean (\\u03bcn+1) and precision (\\u03b2n+1) of the estimate, reflecting the new information. The updated mean (\\u03bcn+1) is a weighted average of the prior mean and the new observation, with weights determined by their respective precisions. The updated precision (\\u03b2n+1) is the sum of the prior precision and the precision of the new observation, indicating increased certainty after incorporating the new data.",
        "Bayesian updating provides a structured way to incorporate new information into existing beliefs, allowing for a more robust and adaptive decision-making process under uncertainty."
      ]
    },
    {
      "topic": "Expected Value of Information",
      "sub_topics": [
        "The expected value of information (EVI) quantifies the expected change in the mean and variance of a belief state after obtaining new information, which is useful for determining the value of collecting additional data. The expected value of information quantifies the expected change in the mean and variance of an estimate after considering all possible realizations of an observation.",
        "EVI is calculated by averaging over all possible realizations of the new information, taking into account the probability of each outcome and the resulting impact on the belief state.",
        "The expected value of the updated mean after an experiment is equal to the prior mean, indicating that on average, the estimate does not change. The expected value of the variance after an experiment is always smaller than the original variance, indicating that on average, uncertainty decreases.",
        "EVI provides a framework for making informed decisions about whether to invest in acquiring more information, balancing the cost of data collection with the potential improvement in decision-making accuracy. Recursive updating allows us to view the posterior mean as a new prior, restarting the problem with different parameters for the distribution of belief after each observation."
      ]
    },
    {
      "topic": "Monte Carlo Simulation",
      "sub_topics": [
        "Monte Carlo simulation involves taking sample realizations of random variables, and is widely used in stochastic programming and optimization.",
        "Computer languages include utilities for generating random numbers uniformly distributed between 0 and 1, which can be used to generate random variables with other distributions. Generating uniformly and exponentially distributed random variables using the inverse cumulative distribution method is an important type of process.",
        "To generate a random variable with a general distribution, compute the inverse cumulative distribution function and apply it to a uniformly distributed random variable. Excel and MATLAB, for example, have a function called NORMINV(p, \\u03bc, \\u03c3) where p is a probability, u is the mean of a normally distributed random variable with standard deviation \\u03c3.",
        "To generate a vector of correlated random variables, compute the Cholesky decomposition of the covariance matrix and apply it to a vector of independent, standard normal variables. Cholesky decomposition is used to compute random variables with correlated samples."
      ]
    }
  ]
}