## Categorização de Modelos de Crença: Lookup Tables, Paramétricos e Não-Paramétricos

### Introdução
No cerne de qualquer problema de aprendizado reside um **modelo de crença** (*belief model*), que essencialmente se traduz em um modelo estatístico que busca caracterizar o que conhecemos sobre o comportamento de um sistema [^1]. Ao contrário dos modelos estatísticos tradicionais, que fornecem apenas uma estimativa pontual, os modelos de crença incorporam uma representação explícita da **incerteza** associada ao modelo [^1]. Assim, a escolha do modelo de crença ( *belief model*) adequado depende de uma série de fatores, incluindo a dimensionalidade do espaço de entrada, a disponibilidade de conhecimento prévio e os recursos computacionais disponíveis. Este capítulo explora as diferentes categorias de modelos de crença, detalhando suas características, vantagens e desvantagens.

### Conceitos Fundamentais

Os modelos de crença podem ser amplamente categorizados em três tipos [^2]:

1.  **Lookup Tables (Tabelas de Consulta)**
2.  **Modelos Paramétricos**
3.  **Modelos Não-Paramétricos**

#### 1. Lookup Tables

As *lookup tables* são adequadas quando temos um conjunto discreto de escolhas para a entrada $x$ [^2]. Seja $X = \\{x_1, x_2, ..., x_M\\}$ o conjunto de escolhas discretas, definimos:

$$\
\mu_x = f(x) = E_w F(x, W)
$$

Onde $f(x)$ representa a função ou sistema que estamos modelando, $W$ é uma variável aleatória que abrange as entradas não controláveis, e $E_w$ denota a expectativa em relação a $W$ [^2]. Uma representação em *lookup table* consiste em estimar $\\mu_x$ para cada $x \\in X$. Assim, se tivermos $M$ escolhas, necessitamos estimar $M$ parâmetros diferentes [^2].

**Exemplo:** Se $M = 100$, precisamos estimar 100 parâmetros diferentes [^2].

#### 2. Modelos Paramétricos

Em cenários onde o conjunto de entradas $X$ é extenso (devido à alta dimensionalidade ou à natureza contínua de $x$), os modelos paramétricos se tornam mais apropriados [^2]. Nesses casos, podemos expressar nosso modelo de crença como:

$$\
f(x|\\theta) \\approx E[F(x, W)] = \\sum_{f \\in F} \\theta_f \\phi_f(x)
$$

Onde $\\phi_f(x), f \\in F$ é um conjunto de *features* (características) e $\\theta_f$ são os parâmetros associados a cada *feature* [^2]. Em vez de estimar um valor $\\mu_x$ para cada entrada $x$, estimamos um vetor de parâmetros $(\\theta_f), f \\in F$ para um conjunto presumivelmente menor de *features* [^2]. A equação acima ilustra um **modelo linear**, linear nos parâmetros $\\theta$, embora as features $\\phi_f(x)$ possam ser altamente não lineares em $x$ [^2].

**Exemplo:** Em vez de estimar uma crença $\\mu_x$ para cada filme $x$, estimamos um vetor de parâmetros $(\\theta_f)$ para um conjunto de *features* como gênero, atores, diretor, etc [^2].

Em algumas situações, pode ser necessário usar um modelo não linear [^2], como:

$$\
f(x|\\theta) =
\begin{cases}
1 & \text{se } x < \\theta_{min} \\\\
0 & \text{se } \\theta_{min} \\leq x \\leq \\theta_{max} \\\\
-1 & \text{se } x > \\theta_{max}
\end{cases}
$$

Outro exemplo é a função logística:

$$\
f(x|\\theta) = \\frac{e^{\\theta_0 + \\theta_1 x}}{1 + e^{\\theta_0 + \\theta_1 x}}
$$

#### 3. Modelos Não-Paramétricos

Os modelos não paramétricos oferecem a flexibilidade de criar estimativas sem a necessidade de assumir uma forma funcional específica, como o modelo linear mencionado anteriormente [^2]. No entanto, essa flexibilidade tem um custo [^2]. Imagine que temos um conjunto de observações $(x_n, f_n), n = 1, ..., N$. Podemos criar uma aproximação $\\hat{f}(x)$ usando uma média local em torno de $x$, ponderando os pontos $f_n$ inversamente proporcionais à distância $\\|x - x_n\\|$ [^2].

**Exemplo:** $\\hat{f}(x) = \\sum_{n=1}^{N} w_n(x) f_n$, onde $w_n(x)$ são pesos inversamente proporcionais a $\\|x - x_n\\|$.

Embora flexíveis, os modelos não paramétricos podem ser difíceis de usar e, portanto, não terão um papel central neste texto [^2].

### Conclusão

A escolha do modelo de crença adequado é crucial para o sucesso de qualquer sistema de aprendizado adaptativo [^1]. *Lookup tables* são simples, mas limitadas a espaços de entrada discretos e de baixa dimensionalidade [^2]. Modelos paramétricos oferecem uma representação mais compacta, mas requerem a escolha de uma forma funcional apropriada [^2]. Modelos não paramétricos fornecem flexibilidade máxima, mas podem ser computacionalmente caros e difíceis de otimizar [^2]. A compreensão das vantagens e desvantagens de cada tipo de modelo é essencial para tomar decisões informadas sobre qual abordagem é mais adequada para um determinado problema. Os capítulos subsequentes irão explorar métodos para atualizar modelos de crença com base em novas informações, com foco especial em *lookup tables* [^2].

### Referências
[^1]: Powell, Warren B., and Ilya O. Ryzhov. *Optimal Learning*. John Wiley & Sons, Inc., 2018, p. 31.
[^2]: Powell, Warren B., and Ilya O. Ryzhov. *Optimal Learning*. John Wiley & Sons, Inc., 2018, p. 32-33.
<!-- END -->